[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I’ve learnt how to import and perform data wrangling on geospatial data using appropriate R packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#getting-started",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#getting-started",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-geospatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\nThe following geospatial data will be imported in T by using st_read() of sf package.\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n3.1 Importing polygon feature data\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n3.2 Importing polyline feature data\n\ncyclingpath <- st_read(dsn = \"data/geospatial\", layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n3.3 Importing GIS data\n\npreschool <- st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "4 Checking the Content of A Simple Feature Data Frame",
    "text": "4 Checking the Content of A Simple Feature Data Frame\n\n4.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n4.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n4.3 Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#plotting-the-geospatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "5 Plotting the Geospatial Data",
    "text": "5 Plotting the Geospatial Data\nThe following plots are obtained to have a better visualization of the geospatial features.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe could also plot only the geometry as shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAs well as choosing only a specific attribute to be plotted as shown below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nUsing plot() for plotting geospatial objects offers a quick look. For high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#working-with-projection",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "6 Working with Projection",
    "text": "6 Working with Projection\nTo perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. Projection transformation allows a simple feature data frame to be projected from one coordinate system to another coordinate system.\n\n6.1 Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nData in geographic coordinate system is not appropriate when distance or/and area measurements are required. In the following, the geographic coordinate system is projected to another coordinate system mathematically.\n\npreschool3414 <- st_transform(preschool, crs = 3414)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-and-converting-an-aspatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "7 Importing and Converting An Aspatial Data",
    "text": "7 Importing and Converting An Aspatial Data\n\n7.1 Importing the aspatial data\nThe following listings is an aspatial data which captures the x- and y-coordinates of the data points. Aspatial data is unlike geospatial data which contains information about a specific location on the Earth’s surface.\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\n\n\n7.2 Creating a simple feature data frame from aspatial data frame\nIn the following, a simple feature data frame is created and the data is transformed into a svy21 projected coordinates system. In the resulting data frame, the longitude and latitude columns will be removed and a new column geometry is added.\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %>% \n    st_transform(crs = 3414)\n\n\nglimpse(listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#geoprocessing-with-sf-package",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "8 Geoprocessing with sf package",
    "text": "8 Geoprocessing with sf package\nIn this section, two commonly used geoprocessing functions, namely buffering and point in polygon count will be performed.\n\n8.1 Buffering\nThe following computes 5-meter buffers (extensions) around cycling paths by using st_buffer() and then computing the corresponding area of the buffers using st_area().\n\nbuffer_cycling <- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n773143.9 [m^2]\n\n\n\n\n8.2 Point-in-polygon count\nIn the following, we want to identify the number of pre-schools in each planning subzone. This is done by using st_intersects() to identify the pre-schools in each planning subzone and then followed by using length() to calculate the number of pre-schools in each planning subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))\n\nWe run the following to check the summary statistics of the newly derived PreSch Count field.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nThe following lists the planning subzone with the most number of pre-schools.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 46001.23 xmax: 25594.22 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      290          3 WOODLANDS EAST    WDSZ03      N  WOODLANDS         WD\n      REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64 46991.63\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\nNext, we want to calculate the density of pre-schools for each planning subzone. We will first derive the area of each planning subzone by using st_area() before computing the density.\n\nmpsz3414$Area <- mpsz3414 %>% \n    st_area()\n\n\nmpsz3414 <- mpsz3414 %>% \n    mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#exploratory-data-analysis",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#exploratory-data-analysis",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "9 Exploratory Data Analysis",
    "text": "9 Exploratory Data Analysis\nIn this section, we will use ggplot2 functions to create functional and statistical graphs for EDA.\nFirst, we will use a histogram to reveal the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nAs hist() does not provide much customization, we will use ggplot2 function instead.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n    geom_histogram(bins = 20,\n                   color = \"black\",\n                   fill = \"light blue\") +\n    labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n         subtitle = \"There are many planning subzones with a single pre-school. On the other hand, \\nthere are two planning subzones with at least 20 pre-schools.\",\n         x = \"Pre-school density (per km sq)\",\n         y = \"Frequency\")\n\n\n\n\nWe can also visualize the pre-school count against pre-school density by using a scatterplot.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`),\n           y = as.numeric(`PreSch Count`))) +\n    geom_point() +\n    labs( x = \"Pre-school density (per kem sq)\",\n          y = \"Pre-school count\") + \n    xlim(0, 40) +\n    ylim(0, 40)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this chapter, choropleth maps will be plotted in R. Choropleth map (also called a color theme) is a thematic map in which areas are colored or shaded accoring to the range in which the aggregated statistic of interest falls."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#getting-started",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#getting-started",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nThe key R package used in this exercise if tmap package in R. In addition, the following R packages are also used:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data, and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#importing-data-into-r",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#importing-data-into-r",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "3 Importing Data into R",
    "text": "3 Importing Data into R\n\n3.1 The Data\nTwo data sets will be used to create the choropleth map:\n\nMP14_SUBZONE_WEB_PL, consisting of geographical boundary of Singapore at the planning subzone level in ESRI shapefile format, and\nrespopagesextod2011to2020.csv, Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-202, aspatial data in csv format\n\n\n\n3.2 Importing Geospatial Data into R\nMP14_SUBZONE_WEB_PL is imported using st_read() as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1b\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe contents in mpsz are examined as follows.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n3.3 Importing Attribute Data into R\nrespopagsex2000to2018.csv will be imported using read_csv() as shown below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n3.4 Data Preparation\nA data table containing the following attributes from year 2020 is first prepared to be used for plotting the thematic map later.\n\nYOUNG: age group 0-4 until age group 20-24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.5 Data wrangling\n\npopdata2020 <- popdata %>% \n    filter(Time == 2020) %>% \n    group_by(PA, SZ, AG) %>% \n    summarise(`POP` = sum(`Pop`)) %>% \n    ungroup() %>% \n    pivot_wider(names_from = AG,\n                values_from = POP) %>% \n    mutate(`YOUNG` = rowSums(.[3:6]) + \n                     rowSums(.[12])) %>% \n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n                              rowSums(.[13:15])) %>% \n    mutate(`AGED` = rowSums(.[16:21])) %>% \n    mutate(`TOTAL` = rowSums(.[3:21])) %>% \n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %>% \n    select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, \n           `AGED`, `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n3.6 Joining the attribute data and geospatial data\nTo perform a georelational join, fields from mpsz and popdata2020 should align. Currently, the values in PA and SZ fields in mpsz and popdata2020 are in uppercase and lowercase respectively. As such, we will need to convert the values in popdata2020 to uppercase first.\n\npopdata2020 <- popdata2020 %>% \n    mutate_at(.vars = vars(PA, SZ),\n              .funs = list(toupper)) %>% \n    filter(`ECONOMY ACTIVE` > 0)\n\nTo keep the joined table as a simple features data frame, we will use a left_join() with mpsz which is simple features data frame as the left table. In the following, we used the planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "4 Choropleth Mapping Geospatial Data Using tmap\nThere are two approaches to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map is by using qtm(). It is concise and provides a good default visualisation in many cases. The following draw a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThe above produces a static map. For an interactive map, “view” option can be used instead of “plot”.\n\n\n4.2 Creating a choropleth map by using tmap’s elements\nAlthough qtm() draws a choropleth map quickly and easily, the aesthetics of the individual map layers is hard to control. This can be circumvented by using tmap’s drawing elements.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, the tmap functions that were used to plot these elements are discussed.\n\n4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons(). In the following, tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable to tm_polygons(). In the following, the variable assigned is DEPENDENCY.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in a subsequent section.\n\n\n4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nIn fact, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nBy using tm_fill() alone, no border is shown on the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders will be used as shown below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBesides the alpha argument, there are three other arguments for tm_borders():\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification to group together data observations.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nThe classification method is defined using the style argument of tm_fill() or tm_polygons().\n\n4.3.1 Plotting choropleth maps with built-in classification methods\nThe following uses a quantile data classification that involves 5 classes. The jenks style identifies groups of similar values in the data and maximises the differences between categories.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the following, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nComparing the two plots above, it can be noticed that the distribution of quantile data classification method is more evenly distributed than the equal data classification method.\nWe also explored 2 additional styles. The first is kmeans which uses the kmeans function to generate the breaks.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe other style explored is Pretty which rounds the breaks into whole numbers where possible and spaces them evenly. This is also the default style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nSimilar to the equal style, pretty style gives a less evenly distributed classification. Out of the 4 styles evaluated, kmeans seems to give the most evenly distributed classification for this data set.\nIn the following, we will explore different values of n using jenks style.\n\nw1 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw2 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 3,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw3 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw4 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE)  \n\ncurrent.mode <- tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(w1, w2, w3, w4)\n\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\ntmap_mode(current.mode)\n\ntmap mode set to plotting\n\n\nFrom the 4 plots above, it seems that using higher values of n, i.e. 10 and 20 gives a better visualisation in understanding the differences in dependencies across different subzones. It can also be observed that for all 4 plots, the last dependency is 1.33 to 19.00 and the lower dependencies comprise of 0.00 to 1.33. For n = 20, while it can be clear how the dependency in one region differs from another based on the colour and its intensity, the gap between the dependency can be insignificant since the dependency of range 0.00 to 1.33 is divided into 19 parts.\n\n\n4.3.2 Plotting choropleth map with custom break\nWe will first get some statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n4.4.1 Using ColourBrewer palette\nTo change the color from the default YlorRd as shown in earlier plots, we assign the preferred color to tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the plot above, the lighter colors represent lower dependency values. We can reverse the order by adding a “-” prefix to the color shading defined as shown below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n4.5 Map Layouts\nIn the earlier sections, we adjusted colour settings and data classification methods that relate to the palette and break-points are used to affect how the map looks. In this section, we will focus on map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\n\n4.5.1 Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n4.5.2 Map style\nThe following uses a classic map style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn thefollowing, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThe following can be run to reset to the default style.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n4.6.1 By assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n4.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n4.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, the selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, computation of Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package will be demonstrated. The objectives of this exercise is as follows:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-analytical-question",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-analytical-question",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, one of the main development objectives of the local government and planners is to ensure equal distribution of development in the province. In this exercise, we will apply appropriate spatial statistical methods to answer “Are developments evenly distributed geographically?”. If they are not, we will then answer “Is there sign of spatial clustering?”. And if yes, we will want to find out “Where are these clusters?”\nIn this case study, we will examine the spatial pattern of a selected development indicator, Gross Domestic Product per Capita (GDPPC) of Hunan Provice, People Republic of China."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-study-area-and-data",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-study-area-and-data",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#setting-the-analytical-tools",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#setting-the-analytical-tools",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.3 Setting the Analytical Tools",
    "text": "2.3 Setting the Analytical Tools\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will install the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-shapefile-into-r-environment",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into R environment",
    "text": "3.1 Import shapefile into R environment\nThe imported shapefile will be a simple features object of sf package.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-csv-file-into-r-environment",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into R environment",
    "text": "3.2 Import csv file into R environment\nThe following yields an output in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#performing-relational-join",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#performing-relational-join",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe following code chunk updates the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan <- left_join(hunan,hunan2012)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#visualising-regional-development-indicator",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.4 Visualising Regional Development Indicator",
    "text": "3.4 Visualising Regional Development Indicator\nUsing qtm() from tmap package, we prepare a basemap and a choropleth map showing the distribution of GDPPC 2012.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-contiguity-spatial-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\nWe will first compute a spatial weights of the geographical units (i.e. county) in the study area. The spatial weights is used to define the neighbourhood relationship between the geographical units.\nIn the following code chunk, poly2nb()from spdep package is used to compute the contiguity weight matrices for the study area. By default, this function builds a list of neighbours based on regions with contiguous boundaries, using the Queen criteria. This based on the argument Queen set to True by default. Setting to False will enable Rook criteria.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#row-standardised-weights-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (using nb2listw() argument style=“W”). This is accomplished by assigning the fraction 1/(number of neighbours) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values. One drawback of this approach is that polygons along the edges of the study area will base their lagged values on fewer polygons and this can potentially over- or under-estimate the true spatial autocorrelation in the data. For simplicity, we will use the style=“W” option for our example. There are other more robust options available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding (given weight of 0 or 1 and only 1 is recorded).\nW is row standardised (sums over all links to n).\nC is globally standardised (sums over all links to n),\nU is equal to C divided by the number of neighbours (sums over all links to unity), and\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible approach."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-morans-i",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.3 Global Spatial Autocorrelation: Moran’s I",
    "text": "4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, we will demonstrate how to perform Moran’s I statistics testing by using moran.test() of spdep. Moran’s I is a test for spatial autocorrelation. It measures the overall spatial autocorrelation of the data, i.e. overall, how one object is similar or dissimilar to others surrounding it, evaluating whether the observation (in our case, GDPPC) is clustered, dispersed, or random.\nThe values of Moran’s I range from +1 meaning strong positive spatial autocorrelation (clustering) to 0 meaning a random pattern to -1 indicating strong negative spatial autocorrelation (dispersion).\n\n4.3.1 Moran’s I test\nThe null hypothesis we are testing states that “The GDPPC values are randomly distributed across counties, following a completely random process”. The alternative hypothesis is”The GDPPC value is not randomly dispersed, i.e. it is clustered in noticeable patterns”.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Moran I statistic (0.30075) is positive, we reject the null hypothesis and conclude that the GDPPC is spatially clustered.\n\n\n4.3.2 Computing Monte Carlo Moran’s I\nThe Moran’s I analysis benefits from being fast. But it may be sensitive to irregularly distributed polygons. A safer approach to hypothesis testing is to run a Monte Carlo simulation using the moran.mc() function. The moran.mc function takes an extra argument n, the number of simulations.\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, GDPPC is spatially clustered.\n\n\n4.3.3 Computing Monte Carlo Maron’s I\nTo examine the simulated Moran’s I test statistics in greater detail, we can plot the distribution of the statistical values as a histogram by using the following code chunk.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\",\n     main = \"Histogram of Monte Carlo Simulation of Moran's I\")\nabline(v=0, \n       col=\"red\") \nabline(v=0.30075, \n       col=\"blue\") \ntext(0.27, 120, \"Moran's I value = 0.30\", cex = 0.8, col='blue')\n\n\n\n\nThe Moran’s I value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates a statistically significant relationship. [1]\nWe can also plot the histogram using ggplot2 package as demonstrated in the following code chunk.\n\nggplot(data=data.frame(bperm$res), aes(x=bperm$res)) + \n  geom_histogram(binwidth=0.019,\n                 colour = \"black\",\n                 lwd = 0.75) +\n    ylim(0,120) +\n    ggtitle(\"Histogram of Monte Carlo Simulated Moran's I\") +\n    xlab(\"Simulated Moran's I\") +\n    ylab(\"Frequency\") +\n    geom_vline(xintercept = 0, color = \"red\") +\n    geom_vline(xintercept = 0.3, color = \"blue\") +\n    geom_label(x=0.26, y=120, label = \"Actual Moran's I = 0.30\", size = 3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-gearys-c",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.4 Global spatial autocorrelation: Geary’s C",
    "text": "4.4 Global spatial autocorrelation: Geary’s C\nGeary’s C is a measure of spatial autocorrelation or an attempt to determine if adjacent observations of the same phenomenon are correlated. How this differs from Moran’s I is that in general, Moran’s I is a measure of global spatial autocorrelation, while Geary’s C is more sensitive to local spatial autocorrelation. Geary’s C is also known as Geary’s contiguity ratio or simply Geary’s ratio.\nA Geary’s C statistic close to 1 indicates that there is no significant autocorrelation between observation i and its neighbors, where Geary’s C statistic < 1 indicates that the observation has neighbors which are significantly similar to it (positive spatial autocorrelation). Likewise, Geary’s C statistic > 1, demonstrates that the observation is among neighbors which differ significantly from it (negative spatial autocorrelation). [2]\n\n4.4.1 Geary’s C test\nIn Geary’s C test, we define the null hypothesis “There is no association between the GDPPC observed at a location and values observed at nearby sites”. The alternative hypothesis is “Nearby sites have either similar or dissimilar GDPPC values”. The code chunk below perform Geary’s C test for spatial autocorrelation by using geary.test() from spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nSince p-value is < 0.05 (statistically significant) and Geary’s C statistic (0.69072) is less than 1, we reject the null hypothesis and conclude that counties have GDPPC that are positively spatially autocorrelated with that of their neighbours.\n\n\n4.4.2 Computing Monte Carlo Geary’s C\nSimilarly, we can also run a Monte Carlo simulation for Geary’s C. The code chunk below performs permutation test for Geary’s C statistic by using geary.mc() from spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nSimilarly, we observe that p-value is < 0.05 (statistically significant) and Geary’s C statistic (0.69072) is less than 1. We reject the null hypothesis and conclude that counties have GDPPC that are positively spatially autocorrelated with that of their neighbours.\n\n\n4.4.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary's C\",\n     main = \"Histogram of Monte Carlo Simulation of Geary's C\")\nabline(v=1, col=\"red\")\nabline(v=0.69, \n       col=\"blue\") \ntext(0.73, 180, \"Geary's C value = 0.69\", cex = 0.8, col='blue')"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-morans-i-correlogram",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "5.1 Compute Moran’s I correlogram",
    "text": "5.1 Compute Moran’s I correlogram\nIn the following code chunk, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nIn addition to plotting the output, we need to understand which autocorrelation values are statistically significant to allow for a complete analysis. Hence, we will need to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the following, we calculate the mean distance of the lag orders 1 to 6. We use nblag() function which creates higher order neighbour lists, where higher order neighbours are only lags links from each other on the graph described by the input neighbours list. [3]\n\nnb6 <- nblag(wm_q, 6)\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\ncorrelogram_bins <- sapply(nb6, function(x) mean(unlist(nbdists(x,coords, longlat = TRUE))))\ncorrelogram_bins\n\n[1]  55.87022 106.63386 162.68268 219.05977 271.93585 323.41649\n\n\nFrom the correlogram and the analysis report, we can see for lag 1 and lag 2 (counties within distances of 55.87km and 106.63km apart respectively), the Moran’s I values is positive and p-value is < 0.05 (statistically significant). This indicate that the GDPPC are spatially clustered for lag 1 and lag2.\nFor lags 3 and 4 (counties within distances of 162.68 km to 219.06 km respectively), while the Moran’s I values are positive, the p-values are both > 0.05 (not statistically significant). Hence we cannot reject the null hypothesis. It is possible that the spatial distribution of the GDPPC values is the result of random spatial processes.\nFor lags 5 and 6 (counties within distances of 217.94 km and 323.42 km), the Moran’s I values are negative, the p-values are both < 0.05 (statistically significant). Hence, we can reject the null hypothesis and the spatial distribution of the GDPPC is more spatially dispersed than would be expected if the underlying spatial processes are random."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-gearys-c-correlogram-and-plot",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "5.2 Compute Geary’s C correlogram and plot",
    "text": "5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor lags 1 to 5, the results obtained from Geary’s C yield the same conclusion as that from Moran’s I. For lag 6: Moran’s I concluded that for counties that are lag 6 apart, the spatial distribution of the GDPPC is spatially dispersed. On the other hand, in Geary’s C results for lag 6, the p-value is > 0.05 (not statistically significant), so we cannot reject the null hypothesis and there is a possibility that the spatial distribution of the GDPPC is random."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-local-morans-i",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-local-morans-i",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "6.1 Computing local Moran’s I",
    "text": "6.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n6.1.1 Mapping the local Moran’s I values\nBefore mapping the local Moran’s I map, we will append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n6.1.2 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n6.1.3 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5) +\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2) \n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nFrom the plots above, there are 11 counties with p-values < 0.05 (statistically significant). In the next section, we will further analyse the type of spatial distribution for GDPPC values for these counties."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.1 Plotting Moran scatterplot",
    "text": "7.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nWe can observe that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the high levels of GDPPC. This are the high-high locations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.2 Plotting Moran scatterplot with standardised variable",
    "text": "7.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#preparing-lisa-map-classes",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.3 Preparing LISA map classes",
    "text": "7.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I <- localMI[,1] - mean(localMI[,1])     \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05  \n\nThese four command lines define the high-high, low-low, low-high and high-low categories.\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4   \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-lisa-map",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-lisa-map",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.4 Plotting LISA map",
    "text": "7.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc <- qtm(hunan, \"GDPPC\")+\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)+\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\")\n\ntmap_arrange(gdppc, LISAmap, asp=1, ncol=2)\n\n\n\n\nIn the plots above, we observe 11 counties with local Moran’s I values that have p-values < 0.05 (statistically significant). These counties are classified as below:\n\nhigh-high quadrant: counties Miluo, Wangcheng, Changsha, Liuyang, Zhuzhuo, and Liling are counties that have high GDPPC values and are surrounded by other counties with high GDPPC.\nlow-low quandrant: counties Longhui and Wugang are counties that have low GDPPC values and are surrounded by other counties with low GDPPC.\nlow-high quadrant: counties Taojiang, Pingjiang, and Xiangtan are “spatial outliers” whereby these counties have low GDPPC values but are surrounded by other counties with high GDPPC."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#getis-and-ords-g-statistics",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.1 Getis and Ord’s G-Statistics",
    "text": "8.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#deriving-distance-based-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#deriving-distance-based-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.2 Deriving distance-based matrix",
    "text": "8.2 Deriving distance-based matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n8.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\n\n\n8.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n8.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-adaptive-distance-weight-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.3 Computing adaptive distance weight matrix",
    "text": "8.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-fixed-distance",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.1 Gi statistics using fixed distance",
    "text": "9.1 Gi statistics using fixed distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below. It performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-fixed-distance-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.2 Mapping Gi values with fixed distance weights",
    "text": "9.2 Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc <- qtm(hunan.gi, \"GDPPC\")+\n    tm_shape(hunan.gi %>% filter(gstat_fixed > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_fixed < -1)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)+\n    tm_shape(hunan.gi %>% filter(gstat_fixed > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_fixed < -1)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nA high positive local Gi score indicates a hotspot. The higher the local Gi score, the more intense the spatial clustering. The counties Wangcheng, Chengsha, and Xiangyin have the highest local Gi score of 4-6, indicating that these counties have the most intense clustering where they have high GDPPC values and are surrounded by counties with high GDPPC.\nA low negative local Gi score indicates a coldspot. The lower the score, the more intense the clustering. 17 of the counties are identified to have coldspot with local Gi values of lower than -1 and are annotated in the above plot in red."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-adaptive-distance",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.3 Gi statistics using adaptive distance",
    "text": "9.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.4 Mapping Gi values with adaptive distance weights",
    "text": "9.4 Mapping Gi values with adaptive distance weights\nWe can then visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc<- qtm(hunan.gi, \"GDPPC\")+\n    tm_shape(hunan.gi %>% filter(gstat_adaptive > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_adaptive < -2)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)+\n    tm_shape(hunan.gi %>% filter(gstat_adaptive > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_adaptive < -2)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUsing adaptive distance weights, the most intense hotspots are identified to be Xiangyin, Pingjiang, Liuyang, Zhuzhuo, and Wangcheng with local Gi values of above 4. These counties have the most intense clustering where they have high GDPPC values and are surrounded by counties with high GDPPC.\nThe most intense coldspots are identified to be Xinning, Suining, and Wugang with local Gi values lower than -2. These counties have the most intense clustering where they have low GDPPC values and are surrounded by counties with low GDPPC."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey for geospatial analytics."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html",
    "href": "in_class_ex/ex1/in-class-ex1.html",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, I will demonstrate computing spatial weights using R. The following steps are included in this exercise:\n\nimporting geospatial data using appropriate function(s) from sf package,\nimporting csv file using appropriate function from readr package,\nperforming relational join using appropriate join function from dplyr package,\ncomputing spatial weights using appropriate functions from spdep package, and\ncalculating spatially lagged variables using appropriate functions from spdep package."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#getting-started",
    "href": "in_class_ex/ex1/in-class-ex1.html#getting-started",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#import-shapefile-into-r-environment",
    "href": "in_class_ex/ex1/in-class-ex1.html#import-shapefile-into-r-environment",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe following code chunk imports the Hunan shapefile into R. The imported shapefile is a simple features object of sf package.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\lohsiying\\ISSS624\\in_class_ex\\ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#import-csv-file-into-r-environment",
    "href": "in_class_ex/ex1/in-class-ex1.html#import-csv-file-into-r-environment",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.2 Import csv file into R environment",
    "text": "3.2 Import csv file into R environment\nIn the following code chunk, imports a csv file using read_csv() of readr package to give an output in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#performing-relational-join",
    "href": "in_class_ex/ex1/in-class-ex1.html#performing-relational-join",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe code chunk updates the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() from dplyr package.\n\nhunan <- left_join(hunan,hunan2012)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-queen-contiguity-based-neighbours",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-queen-contiguity-based-neighbours",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.1 Computing (QUEEN) contiguity based neighbours",
    "text": "5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute the Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, in the following code chunk we can see the neighbors for the first polygon:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the following code chunk can be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nTo display the complete weight matrix, str() can be used.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#creating-rook-contiguity-based-neighbours",
    "href": "in_class_ex/ex1/in-class-ex1.html#creating-rook-contiguity-based-neighbours",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.2 Creating (ROOK) contiguity based neighbours",
    "text": "5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. Using the Rook’s method, the most connect area unit has 10 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#visualising-contiguity-weights",
    "href": "in_class_ex/ex1/in-class-ex1.html#visualising-contiguity-weights",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.3 Visualising contiguity weights",
    "text": "5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. Now the data is in polygon format, so we will need to get points in order to make our connectivity graphs. The most typical method for this will be to use polygon centroids by specifying their Latitude and Longitude. We will calculate these in the sf package before moving onto the graphs.\nWe need the Latitude and Longitude coordinates in a separate data frame for this. To do this we will use a mapping function to apply a given function to each element of a vector and return a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value of each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\n\n5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2), mar = c(0, 0, 2, 3) + 0.1)\nplot(hunan$geometry, border=\"lightgrey\", main = 'Queen Contiguity')\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main = 'Rook Contiguity')\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#determine-the-cut-off-distance",
    "href": "in_class_ex/ex1/in-class-ex1.html#determine-the-cut-off-distance",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.1 Determine the cut-off distance",
    "text": "6.1 Determine the cut-off distance\nWe will first determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper bound gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-fixed-distance-weight-matrix",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-fixed-distance-weight-matrix",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.2 Computing fixed distance weight matrix",
    "text": "6.2 Computing fixed distance weight matrix\nNext, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe output above shows that on average, each region has 3.68 neighbours.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() from spdep package.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$n\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2), mar = c(0, 0, 2, 3) + 0.1)\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08, main=\"1st nearest neighbours\")\ntitle(main = '1st nearest neighbours')\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-adaptive-distance-weight-matrix",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-adaptive-distance-weight-matrix",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nIn this way, each county has the same number of neighbours at exactly six neighbours!\n\n6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "7.1 Spatial lag with row-standardized weights",
    "text": "7.1 Spatial lag with row-standardized weights\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (using nb2listw() argument style=“W”). This is accomplished by assigning the fraction 1/(number of neighbours) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values. One drawback of this approach is that polygons along the edges of the study area will base their lagged values on fewer polygons and this can potentially over- or under-estimate the true spatial autocorrelation in the data. For simplicity, we will use the style=“W” option for our example. There are other more robust options available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s neighbors type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nEach neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights-1",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights-1",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.1 Spatial lag with row-standardized weights",
    "text": "8.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWith reference to the following code chunk where we retrieve the GDPPC of the five neighbouring counties of the first county in our data, Anxiang:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nsum(nb1) / 5\n\n[1] 24847.2\n\n\nWe can see that Spatial lag with row-standardized weights gives each neighbour equal weight.\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.2 Spatial lag as a sum of neighboring values",
    "text": "8.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply().\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nsum(nb1)\n\n[1] 124236\n\n\nWe can see that Spatial lag as a sum of neighboring values simply sums the GDPPC values of all its neighbours.\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nNow, we can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-window-average",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-window-average",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.3 Spatial window average",
    "text": "8.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element - this means besides taking into consideration of its neighbours, this method also considers the county itself. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights. To begin we assign this to a new variable because we will directly alter its structure to add the diagonal elements.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we can use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNow we obtain weights using nb2listw()\n\nwm_q1 <- nb2listw(wm_q1)\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nLastly, we need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc <- lag.listw(wm_q1, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"NAME_3\"\n\n\nLastly, qtm() from tmap package is used to plot the GDPPC and lag_window_avg GDPPC map next to each other for quick comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-window-sum",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-window-sum",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.4 Spatial window sum",
    "text": "8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights. To do this we assign binary weights to the neighbor structure that includes the diagonal element.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nwm_q1\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights <- lapply(wm_q1, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 <- nb2listw(wm_q1, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nThe second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"NAME_3\"\n\n\nLastly, qtm() of tmap package is used to plot the GDPPC and lag_sum GDPPC map next to each other for quick comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html",
    "href": "in_class_ex/ex2/in-class-ex2.html",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Access to safe water, sanitation and hygiene is the most basic human need for health and well-being. Despite efforts in raising the access to these basic services, according to the Sustainable Development Goals Report 2022 issued by the United Nations, by 2030, 1.6 billion people will lack safely managed drinking water, 2.8 billion people will lack safely managed sanitation, and 1.9 billion people will lack basic hand hygiene facilities.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas which then allows governments and their partners to make use of the data to improve decisions on a regular basis."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#aspatial-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#aspatial-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "3.1 Aspatial Data",
    "text": "3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,08 unique water point records."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#geospatial-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#geospatial-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#getting-started---setting-up-the-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#getting-started---setting-up-the-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.1 Getting Started - Setting up the environment",
    "text": "4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nsf,\ntidyverse,\ntmap,\nspdep, and\nfunModeling\n\n\npacman::p_load(sf, tmap, tidyverse, spdep, funModeling)"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#import-nigeria-lga-boundary-data-into-r-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#import-nigeria-lga-boundary-data-into-r-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.2 Import Nigeria LGA boundary data into R environment",
    "text": "4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\n\nThe above printout shows the data is in wgs84 geographic coordinate system. This is the required format as we will be using st_intersects() later which requires the data to be in wg84 coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga, \n          \"geodata/nga.rds\")"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#import-csv-file-into-r-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#import-csv-file-into-r-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.3 Import csv file into R environment",
    "text": "4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwpd <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. We will then convert wpd data frame into a simple feature data frame by using the following code chunk and ensuring the data has the same wgs84 geographic coordinate system by specifying .\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwpd_sf <- st_as_sf(wpd,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geopatial folder.\n\nwrite_rds(wpd_sf, \n          \"geodata/wpd_nga.rds\")"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#data-wrangling-for-water-point-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#data-wrangling-for-water-point-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.4 Data Wrangling for Water Point Data",
    "text": "4.4 Data Wrangling for Water Point Data\n\n4.4.1 Recoding NA values into string\nWe will then load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp_nga <- read_rds(\"geodata/wpd_nga.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n4.4.2 EDA\n\nfreq(data = wp_nga,\n     input = 'status_clean')\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. We will create 2 separate dataframes each containing either type of functional water points."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#extracting-water-point-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#extracting-water-point-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.5 Extracting Water Point Data",
    "text": "4.5 Extracting Water Point Data\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_nga %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.4.2.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\nThe output shows that filtering was performed successfully."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#performing-point-in-polygon-count",
    "href": "in_class_ex/ex2/in-class-ex2.html#performing-point-in-polygon-count",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.6 Performing Point-in-Polygon Count",
    "text": "4.6 Performing Point-in-Polygon Count\nNext, we want to find the number of functional water points in each LGA as well as the number of total, functional, non-functional, and unknown water points in each LGA. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nnga_wp <- nga %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nga, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nga, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nga, wp_unknown)))"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#saving-the-analytical-data-table",
    "href": "in_class_ex/ex2/in-class-ex2.html#saving-the-analytical-data-table",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.7 Saving the Analytical Data Table",
    "text": "4.7 Saving the Analytical Data Table\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional\n\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_non_functional = wp_nonfunctional/total_wp)\n\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html",
    "href": "take_home_ex/ex1/take-home-ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Access to safe water, sanitation and hygiene is the most basic human need for health and well-being. Despite efforts in raising the access to these basic services, according to the Sustainable Development Goals Report 2022 issued by the United Nations, by 2030, 1.6 billion people will lack safely managed drinking water, 2.8 billion people will lack safely managed sanitation, and 1.9 billion people will lack basic hand hygiene facilities.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas which then allows governments and their partners to make use of the data to improve decisions on a regular basis."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#objectives",
    "href": "take_home_ex/ex1/take-home-ex1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2 Objectives",
    "text": "2 Objectives\nGeospatial analytics offers a tremendous potential to solving societal problems. One such analytics is spatial autocorrelation which helps understand the degree to which one object is similar to its surrounding objects.\nThe objectives of this take-home exercise are as outlined in the following:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Any one of the three Projected Coordinate Systems of Nigeria, EPSG: 26391, 26392, and 26303 can be used.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nPerforming outliers/clusters analysis by using appropriate local measures of spatial association methods.\nPerforming hotspot areas analysis by using appropriate local measures of spatial association methods."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#the-data",
    "href": "take_home_ex/ex1/take-home-ex1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "3 The Data",
    "text": "3 The Data\nIn this exercise, we will analyse the data from Nigeria. There are 2 datasets used, as outlined in sections 3.1 and 3.2.\n\n3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,08 unique water point records.\n\n\n3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#getting-the-data-into-r-environment",
    "href": "take_home_ex/ex1/take-home-ex1.html#getting-the-data-into-r-environment",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4 Getting the Data Into R Environment",
    "text": "4 Getting the Data Into R Environment\n\n4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nsf,\ntidyverse,\ntmap,\nspdep, and\nfunModeling\n\n\npacman::p_load(sf, tmap, tidyverse, spdep, funModeling)\n\n\n\n4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\nnga\n\nThe above printout shows the data is in wgs84 geographic coordinate system. This is the required format as we will be using st_intersects() later which requires the data to be in wg84 coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga, \n          \"geodata/nga.rds\")\n\n\n\n4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwpd <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. We will then convert wpd data frame into a simple feature data frame by using the following code chunk and ensuring the data has the same wgs84 geographic coordinate system by specifying .\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwpd_sf <- st_as_sf(wpd,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \nwpd_sf\n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geopatial folder.\n\nwrite_rds(wpd_sf, \n          \"geodata/wpd_nga.rds\")\n\n\n\n4.4 Data Wrangling for Water Point Data\n\n4.4.1 Recoding NA values into string\nWe will then load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp_nga <- read_rds(\"geodata/wpd_nga.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n4.4.2 EDA\n\nfreq(data = wp_nga,\n     input = 'status_clean')\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. We will create 2 separate dataframes each containing either type of functional water points.\n\n\n\n4.5 Extracting Water Point Data\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_nga %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.4.2.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\nThe output shows that filtering was performed successfully.\n\n\n4.6 Performing Point-in-Polygon Count\nNext, we want to find the number of functional water points in each LGA as well as the number of total, functional, non-functional, and unknown water points in each LGA. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nnga_wp <- nga %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nga, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nga, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nga, wp_unknown)))\n\n\n\n4.7 Saving the Analytical Data Table\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional\n\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_non_functional = wp_nonfunctional/total_wp)\n\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#visualising-the-spatial-distribution-of-waterpoints",
    "href": "take_home_ex/ex1/take-home-ex1.html#visualising-the-spatial-distribution-of-waterpoints",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5 Visualising the Spatial Distribution of Waterpoints",
    "text": "5 Visualising the Spatial Distribution of Waterpoints\nWe will visualise the spatial distribution of function and non-functional water points using a choropleth. This is performed using the code chunk below.\n\nnga_wp <- read_rds(\"geodata/nga_wp.rds\")\ntotal <- qtm(nga_wp, \"total_wp\")\nwp_functional <- qtm(nga_wp, \"wp_functional\")\nwp_nonfunctional <- qtm(nga_wp, \"wp_nonfunctional\")\nunknown <- qtm(nga_wp, \"wp_unknown\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#global-spatial-autocorrelation",
    "href": "take_home_ex/ex1/take-home-ex1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "6 Global Spatial Autocorrelation",
    "text": "6 Global Spatial Autocorrelation\nIn this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation. Global spatial autocorrelation describes the presence of systematic spatial variation in a variable (in this case, proportion of functional water points and proportion of non-functional water points) in the study area (i.e. Nigeria) as a whole. We will evaluate two global spatial autocorrelation statistics - Moran’s I and Geary’s C.\n\n6.1 Computing Contiguity Spatial Weights\nWe will first identify the spatial weights which is used to define the neighbourhood relationship between the geographical units.\nThere are 2 main approaches to compute the spatial weights, namely, the contiguity approach and the distance approach. In the contiguity approach, neighbours are identified to be geographical areas that share a common boundary. In the Rook’s criteria, areas need to have perfect shared boundary in order to be considered as neighbours, whereas for Queen’s criteria, areas that have either perfect shared boundary or diagonal shared boundary are considered as neighbours. However, in the case for Nigeria, we can observe that the LGAs are not approximately uniform. Using the contiguity approach may result in some LGAs to have more neighbours and some LGAs to have less neighbours - resulting in underestimating and overestimating the contributions of their neighbours respectively. As such, the contiguity approach is not suitable.\nIn the distance method, there are 2 approaches - (1) fixed distance approach where areas are identified to be neighbours if the distance between their centroids are within the fixed distance and (2) adaptive weighting scheme where shorter bandwidths (or distances) are used when data is dense and longer bandwidths for data that is sparse. One advantage of the adaptive distance weight scheme is that we can control the number of neighbours by using k-nearest neighbours. To use fixed distance, the regions should be of similar size so that the centroid represent each region well. Since the LGAs in Nigeria do not have similar sizes, fixed distance approach is not suitable. Another area where fixed distance works well is when there are very large polygons at the edge of the study area and very small polygons at the center, which again, is not observed for Nigeria. As such, we will use th adaptive weighting scheme.\n\n6.1.1 Retrieving longitude and latutide of polygon centroids\nWe will first need to associate each polygon with a point in order to determine the nearest neighbours. The most typical method for this is the polygon centroids which gives us the longitude and the latitude of each LGA.\nIn the following code chunk, we use map_dbl() to transform the geometry of each LGA (represented by nga_wp$geometry) by applying the function st_centroid() to each LGA. We then access the longitude using [[1]].\n\nlongitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])\n\nLikewise, we perform the following to access the latitude of the LGAs, this time using [[2]] to access the latitude.\n\nlatitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude  latitude\n[1,]  7.372450  5.113107\n[2,]  7.352131  5.083219\n[3,] 13.322900 13.428835\n[4,]  6.847325  8.825812\n[5,]  7.771541  5.022061\n[6,]  8.219654  6.259845\n\n\n\n\n6.1.2 Computing adaptive distance weight matrix\nIn the following code chunk, we define k = 8 to find the k-nearest neighbours using knearineigh() and knn2nb() to return a list of integer vectors containing neighbour region number ids.\n\nknn8 <- knn2nb(knearneigh(coords, k = 8))\nknn8\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nThe following code chunk allows us to display the content of the mstrix using str().\n\nstr(knn8)\n\nList of 774\n $ : int [1:8] 2 321 364 548 597 624 721 725\n $ : int [1:8] 1 321 548 597 624 721 725 726\n $ : int [1:8] 250 261 447 477 492 507 509 526\n $ : int [1:8] 12 20 257 263 446 454 466 690\n $ : int [1:8] 203 208 286 288 331 334 539 738\n $ : int [1:8] 170 217 218 337 379 553 577 601\n $ : int [1:8] 8 176 214 281 283 306 544 555\n $ : int [1:8] 7 214 281 306 327 544 555 651\n $ : int [1:8] 18 19 218 337 574 576 601 757\n $ : int [1:8] 25 216 325 364 365 528 552 632\n $ : int [1:8] 26 27 43 68 191 524 565 762\n $ : int [1:8] 135 263 417 429 446 454 690 695\n $ : int [1:8] 31 37 211 320 393 570 583 584\n $ : int [1:8] 170 363 379 546 563 577 581 589\n $ : int [1:8] 22 49 82 177 297 306 580 623\n $ : int [1:8] 30 187 188 296 328 357 360 635\n $ : int [1:8] 35 275 295 378 460 591 638 639\n $ : int [1:8] 9 19 218 376 574 576 601 757\n $ : int [1:8] 9 18 56 103 376 574 576 601\n $ : int [1:8] 4 106 125 239 263 419 454 466\n $ : int [1:8] 60 61 162 269 520 578 596 626\n $ : int [1:8] 49 297 326 443 515 623 682 693\n $ : int [1:8] 54 291 292 536 537 614 618 619\n $ : int [1:8] 84 123 437 476 527 652 673 761\n $ : int [1:8] 10 181 216 314 325 366 552 730\n $ : int [1:8] 11 27 68 191 336 439 562 762\n $ : int [1:8] 11 26 191 439 562 565 663 762\n $ : int [1:8] 29 178 299 300 301 358 369 598\n $ : int [1:8] 172 173 178 182 358 378 460 591\n $ : int [1:8] 16 39 41 186 192 329 357 360\n $ : int [1:8] 13 37 211 289 561 570 583 584\n $ : int [1:8] 51 62 461 462 515 623 682 693\n $ : int [1:8] 47 166 227 238 242 655 743 750\n $ : int [1:8] 42 104 136 137 213 553 559 757\n $ : int [1:8] 17 275 276 277 278 279 295 460\n $ : int [1:8] 50 107 247 408 432 455 681 759\n $ : int [1:8] 38 40 211 212 570 583 584 629\n $ : int [1:8] 30 39 40 41 186 192 320 570\n $ : int [1:8] 30 38 40 41 186 192 320 329\n $ : int [1:8] 37 38 39 41 186 192 320 570\n $ : int [1:8] 30 38 39 40 186 192 360 634\n $ : int [1:8] 86 136 137 499 587 613 718 734\n $ : int [1:8] 11 68 157 524 549 565 590 645\n $ : int [1:8] 16 45 192 290 303 328 360 634\n $ : int [1:8] 44 187 290 303 328 341 360 599\n $ : int [1:8] 387 417 429 438 459 521 668 742\n $ : int [1:8] 33 111 166 234 238 691 698 750\n $ : int [1:8] 65 113 265 386 407 428 482 701\n $ : int [1:8] 22 32 297 326 515 623 682 693\n $ : int [1:8] 36 98 107 247 409 416 432 681\n $ : int [1:8] 32 62 461 462 515 580 623 693\n $ : int [1:8] 53 78 165 293 532 602 603 636\n $ : int [1:8] 52 78 80 165 280 602 621 636\n $ : int [1:8] 23 79 293 294 532 536 537 618\n $ : int [1:8] 122 169 246 333 430 571 605 697\n $ : int [1:8] 77 368 376 533 534 576 601 728\n $ : int [1:8] 53 58 199 312 322 323 621 622\n $ : int [1:8] 57 322 323 564 602 603 621 622\n $ : int [1:8] 88 128 129 259 493 700 714 748\n $ : int [1:8] 61 158 563 578 589 592 596 626\n $ : int [1:8] 21 60 269 578 589 592 596 626\n $ : int [1:8] 32 51 461 462 515 623 682 693\n $ : int [1:8] 90 237 384 416 467 497 765 772\n $ : int [1:8] 48 65 74 113 131 265 386 407\n $ : int [1:8] 48 64 74 113 265 407 683 701\n $ : int [1:8] 19 103 104 288 331 338 351 574\n $ : int [1:8] 347 348 560 566 567 609 640 694\n $ : int [1:8] 11 43 157 190 191 549 590 645\n $ : int [1:8] 140 146 248 274 473 500 512 513\n $ : int [1:8] 71 298 299 301 341 343 344 610\n $ : int [1:8] 70 172 173 298 299 343 344 625\n $ : int [1:8] 17 361 566 567 568 609 638 639\n $ : int [1:8] 72 361 374 377 404 607 665 666\n $ : int [1:8] 65 109 113 251 265 683 741 754\n $ : int [1:8] 110 272 398 422 433 485 501 768\n $ : int [1:8] 254 287 427 459 470 547 647 677\n $ : int [1:8] 56 195 533 534 579 618 619 728\n $ : int [1:8] 52 54 79 80 165 215 532 636\n $ : int [1:8] 54 78 165 293 532 579 618 636\n $ : int [1:8] 52 53 78 165 215 280 636 739\n $ : int [1:8] 99 145 227 233 426 483 689 760\n $ : int [1:8] 15 32 49 51 177 352 580 623\n $ : int [1:8] 132 258 383 414 433 529 767 768\n $ : int [1:8] 24 131 148 386 437 482 673 692\n $ : int [1:8] 105 156 267 394 654 675 707 712\n $ : int [1:8] 42 136 137 499 587 613 718 734\n $ : int [1:8] 149 151 221 226 399 410 486 657\n $ : int [1:8] 59 116 128 150 489 648 700 714\n $ : int [1:8] 260 408 463 542 674 676 681 759\n $ : int [1:8] 63 163 236 237 384 452 710 765\n $ : int [1:8] 160 271 388 406 473 475 492 525\n $ : int [1:8] 95 119 390 391 392 423 487 656\n $ : int [1:8] 73 354 374 402 594 607 665 666\n $ : int [1:8] 13 31 60 158 436 561 596 709\n $ : int [1:8] 92 390 391 392 405 423 469 656\n $ : int [1:8] 97 139 389 403 420 451 488 653\n $ : int [1:8] 96 168 389 420 451 653 662 773\n $ : int [1:8] 50 117 153 231 409 432 696 708\n $ : int [1:8] 81 145 426 483 667 689 760 769\n  [list output truncated]\n - attr(*, \"region.id\")= chr [1:774] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 8)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 8\n - attr(*, \"class\")= chr \"nb\"\n\n\nWe can visualise the weight matrix using the code chunk below.\n\nplot(nga_wp$geometry, border = \"lightgrey\")\nplot(knn8, coords, pch = 10, cex = 0.5, add = TRUE, col = \"red\")\n\n\n\n\n\n\n6.1.3 Binary weights matrix\nNext, we will assign weights to each neighboring polygon by using the basic binary coding.\nIn the following code chunk, the input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nWe defined style = “B” which is binary coding assignment where neighbours are given a value of 1 and non-neighbours are given a value of 0.\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list.\n\n\nbwm <- nb2listw(knn8,\n                style = \"B\",\n                zero.policy = TRUE)\nbwm\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\nWeights style: B \nWeights constants summary:\n    n     nn   S0    S1     S2\nB 774 599076 6192 11152 201942\n\n\n\n\n\n6.2 Global Spatial Autocorrelation: Moran’s I\nIn this section, we will demonstrate how to perform Moran’s I statistics testing by using moran.test() of spdep. Moran’s I is a test for spatial autocorrelation. It measures the overall spatial autocorrelation of the data, i.e. overall, how one object is similar or dissimilar to others surrounding it, evaluating whether the observation (in our case, values for the proportion of non-functional water points) is clustered, dispersed, or random.\nThe values of Moran’s I range from +1 meaning strong positive spatial autocorrelation (clustering) to 0 meaning a random pattern to -1 indicating strong negative spatial autocorrelation (dispersion).\n\n6.2.1 Moran’s I test\nThe null hypothesis we are testing states that “The values for the proportion of non-functional water points are randomly distributed across counties, following a completely random process”. The alternative hypothesis is”The values for the proportion of non-functional water points is not randomly dispersed, i.e. it is clustered in noticeable patterns”.\nThe following code chunk performs Moran’s I statistic test using moran.test() of spdep.\n\nmoran.test(nga_wp$pct_non_functional, \n           listw = bwm, \n           zero.policy = TRUE, \n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp$pct_non_functional  \nweights: bwm \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526   \n\nMoran I statistic standard deviate = 25.691, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.4397713487     -0.0013157895      0.0002947791 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Moran I statistic (0.43977) is positive, we reject the null hypothesis and conclude that the values for the proportion of non-functional water points is spatially clustered.\n\n\n6.2.2 Computing Monte Carlo Moran’s I\nThe Moran’s I analysis benefits from being fast. But it may be sensitive to irregularly distributed polygons. A safer approach to hypothesis testing is to run a Monte Carlo simulation using the moran.mc() function. The moran.mc function takes an extra argument n, the number of simulations.\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm = moran.mc(nga_wp$pct_non_functional, \n                listw = bwm, \n                nsim = 999, \n                zero.policy = TRUE, \n                na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  nga_wp$pct_non_functional \nweights: bwm \nomitted: 3, 86, 241, 250, 252, 261, 400, 406, 447, 473, 492, 507, 526 \nnumber of simulations + 1: 1000 \n\nstatistic = 0.43977, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, the values for the proportion of non-functional water points is spatially clustered.\n\n\n6.2.3 Visualising Monte Carlo Moran’s I\nTo examine the simulated Moran’s I test statistics in greater detail, we can plot the distribution of the statistical values as a histogram by using the following code chunk.\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 50, \n     xlab = \"Simulated Moran's I\",\n     main = \"Histogram of Monte Carlo Simulation of Moran's I\")\nabline(v=0, \n       col=\"red\") \nabline(v=0.44, \n       col=\"blue\") \ntext(0.37, 180, \"Moran's I value = 0.44\", cex = 0.8, col='blue')\n\n\n\n\nThe Moran’s I value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates a statistically significant relationship. [1]\n\n\n\n6.3 Global Spatial Autocorrealtion: Geary’s C\nGeary’s C is a measure of spatial autocorrelation or an attempt to determine if adjacent observations of the same phenomenon are correlated. How this differs from Moran’s I is that in general, Moran’s I is a measure of global spatial autocorrelation, while Geary’s C is more sensitive to local spatial autocorrelation. Geary’s C is also known as Geary’s contiguity ratio or simply Geary’s ratio.\nA Geary’s C statistic close to 1 indicates that there is no significant autocorrelation between observation i and its neighbors, where Geary’s C statistic < 1 indicates that the observation has neighbors which are significantly similar to it (positive spatial autocorrelation). Likewise, Geary’s C statistic > 1, demonstrates that the observation is among neighbors which differ significantly from it (negative spatial autocorrelation). [2]\n\n6.3.1 Geary’s C test\nIn Geary’s C test, we define the null hypothesis “There is no association between the values for the proportion of non-functional water points observed at a location and values observed at nearby LGAs”. The alternative hypothesis is “Nearby sites have either similar or dissimilar values for the proportion of non-functional water points”. The code chunk below perform Geary’s C test for spatial autocorrelation by using geary.test() from spdep.\n\ngeary.test(nga_wp$pct_non_functional, \n           listw = bwm, \n           zero.policy = TRUE)\n\n\n\n6.3.2 Computing Monte Carlo Geary’s C\n\n\n6.3.3 Visualising the Monte Carlo Geary’s C\n\n\n\n6.4 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in the data or model residuals. They show how correlated are pairs of spatial observations as the distance (lag) between them increases - they are plots of some index of autocorrelation (Moran’s I) against distance. Spatial correlograms serve as very useful exploratory and descriptive tool.\n\n6.4.1 Compute Moran’s I correlogram\nIn the following code chunk, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(knn8, \n                          nga_wp$pct_non_functional, \n                          order = 6, \n                          method = \"I\", \n                          style = \"B\")\nplot(MI_corr)"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#local-spatial-autocorrelation",
    "href": "take_home_ex/ex1/take-home-ex1.html#local-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "7 Local Spatial Autocorrelation",
    "text": "7 Local Spatial Autocorrelation\nThe Cluster and Outlier Analysis (Anselin Local Moran’s I) tool identifies concentrations of high values, concentrations of low values, and spatial outliers. [3] It can help to answer questions such as:\n\nWhere are the sharpest boundaries between LGA with high proportion of non-functional water points and LGA with low proportion of non-functional water points?\nAre there locations where there is a high number of LGAs with high proportion of non-functional water points?\n\nA positive value for I indicates that a feature has neighboring features with similarly high or low attribute values; this feature is part of a cluster. A negative value for I indicates that a feature has neighboring features with dissimilar values; this feature is an outlier. In either instance, the p-value for the feature must be small enough for the cluster or outlier to be considered statistically significant.\n\n7.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of values for proportion of non-functional water points at the LGA level.\n\nfips <- order(nga_wp$shapeName)\nlocalMI <- localmoran(nga_wp$pct_non_functional, bwm)\nhead(localMI)\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)\n\nReference:\n[3] Understanding Anselin Local Moran’s I"
  }
]