[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I’ve learnt how to import and perform data wrangling on geospatial data using appropriate R packages."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#getting-started",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#getting-started",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-geospatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\nThe following geospatial data will be imported in T by using st_read() of sf package.\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n3.1 Importing polygon feature data\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n3.2 Importing polyline feature data\n\ncyclingpath <- st_read(dsn = \"data/geospatial\", layer = \"CyclingPath\")\n\nReading layer `CyclingPath' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n3.3 Importing GIS data\n\npreschool <- st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "4 Checking the Content of A Simple Feature Data Frame",
    "text": "4 Checking the Content of A Simple Feature Data Frame\n\n4.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n4.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n4.3 Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#plotting-the-geospatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "5 Plotting the Geospatial Data",
    "text": "5 Plotting the Geospatial Data\nThe following plots are obtained to have a better visualization of the geospatial features.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe could also plot only the geometry as shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAs well as choosing only a specific attribute to be plotted as shown below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nUsing plot() for plotting geospatial objects offers a quick look. For high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#working-with-projection",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "6 Working with Projection",
    "text": "6 Working with Projection\nTo perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. Projection transformation allows a simple feature data frame to be projected from one coordinate system to another coordinate system.\n\n6.1 Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nData in geographic coordinate system is not appropriate when distance or/and area measurements are required. In the following, the geographic coordinate system is projected to another coordinate system mathematically.\n\npreschool3414 <- st_transform(preschool, crs = 3414)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-and-converting-an-aspatial-data",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "7 Importing and Converting An Aspatial Data",
    "text": "7 Importing and Converting An Aspatial Data\n\n7.1 Importing the aspatial data\nThe following listings is an aspatial data which captures the x- and y-coordinates of the data points. Aspatial data is unlike geospatial data which contains information about a specific location on the Earth’s surface.\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\n\n\n7.2 Creating a simple feature data frame from aspatial data frame\nIn the following, a simple feature data frame is created and the data is transformed into a svy21 projected coordinates system. In the resulting data frame, the longitude and latitude columns will be removed and a new column geometry is added.\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) %>% \n    st_transform(crs = 3414)\n\n\nglimpse(listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#geoprocessing-with-sf-package",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "8 Geoprocessing with sf package",
    "text": "8 Geoprocessing with sf package\nIn this section, two commonly used geoprocessing functions, namely buffering and point in polygon count will be performed.\n\n8.1 Buffering\nThe following computes 5-meter buffers (extensions) around cycling paths by using st_buffer() and then computing the corresponding area of the buffers using st_area().\n\nbuffer_cycling <- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n773143.9 [m^2]\n\n\n\n\n8.2 Point-in-polygon count\nIn the following, we want to identify the number of pre-schools in each planning subzone. This is done by using st_intersects() to identify the pre-schools in each planning subzone and then followed by using length() to calculate the number of pre-schools in each planning subzone.\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))\n\nWe run the following to check the summary statistics of the newly derived PreSch Count field.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nThe following lists the planning subzone with the most number of pre-schools.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 46001.23 xmax: 25594.22 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      290          3 WOODLANDS EAST    WDSZ03      N  WOODLANDS         WD\n      REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64 46991.63\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\nNext, we want to calculate the density of pre-schools for each planning subzone. We will first derive the area of each planning subzone by using st_area() before computing the density.\n\nmpsz3414$Area <- mpsz3414 %>% \n    st_area()\n\n\nmpsz3414 <- mpsz3414 %>% \n    mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#exploratory-data-analysis",
    "href": "hands_on_ex/hands_on_ex1/hands-on_ex1.html#exploratory-data-analysis",
    "title": "Hands-on Exercise 1A: Geospatial Data Wrangling with R",
    "section": "9 Exploratory Data Analysis",
    "text": "9 Exploratory Data Analysis\nIn this section, we will use ggplot2 functions to create functional and statistical graphs for EDA.\nFirst, we will use a histogram to reveal the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nAs hist() does not provide much customization, we will use ggplot2 function instead.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`))) +\n    geom_histogram(bins = 20,\n                   color = \"black\",\n                   fill = \"light blue\") +\n    labs(title = \"Are pre-schools evenly distributed in Singapore?\",\n         subtitle = \"There are many planning subzones with a single pre-school. On the other hand, \\nthere are two planning subzones with at least 20 pre-schools.\",\n         x = \"Pre-school density (per km sq)\",\n         y = \"Frequency\")\n\n\n\n\nWe can also visualize the pre-school count against pre-school density by using a scatterplot.\n\nggplot(data = mpsz3414,\n       aes(x = as.numeric(`PreSch Density`),\n           y = as.numeric(`PreSch Count`))) +\n    geom_point() +\n    labs( x = \"Pre-school density (per kem sq)\",\n          y = \"Pre-school count\") + \n    xlim(0, 40) +\n    ylim(0, 40)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "",
    "text": "In this chapter, choropleth maps will be plotted in R. Choropleth map (also called a color theme) is a thematic map in which areas are colored or shaded accoring to the range in which the aggregated statistic of interest falls."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#getting-started",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#getting-started",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nThe key R package used in this exercise if tmap package in R. In addition, the following R packages are also used:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data, and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#importing-data-into-r",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#importing-data-into-r",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "3 Importing Data into R",
    "text": "3 Importing Data into R\n\n3.1 The Data\nTwo data sets will be used to create the choropleth map:\n\nMP14_SUBZONE_WEB_PL, consisting of geographical boundary of Singapore at the planning subzone level in ESRI shapefile format, and\nrespopagesextod2011to2020.csv, Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-202, aspatial data in csv format\n\n\n\n3.2 Importing Geospatial Data into R\nMP14_SUBZONE_WEB_PL is imported using st_read() as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex1b\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe contents in mpsz are examined as follows.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n3.3 Importing Attribute Data into R\nrespopagsex2000to2018.csv will be imported using read_csv() as shown below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n3.4 Data Preparation\nA data table containing the following attributes from year 2020 is first prepared to be used for plotting the thematic map later.\n\nYOUNG: age group 0-4 until age group 20-24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.5 Data wrangling\n\npopdata2020 <- popdata %>% \n    filter(Time == 2020) %>% \n    group_by(PA, SZ, AG) %>% \n    summarise(`POP` = sum(`Pop`)) %>% \n    ungroup() %>% \n    pivot_wider(names_from = AG,\n                values_from = POP) %>% \n    mutate(`YOUNG` = rowSums(.[3:6]) + \n                     rowSums(.[12])) %>% \n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n                              rowSums(.[13:15])) %>% \n    mutate(`AGED` = rowSums(.[16:21])) %>% \n    mutate(`TOTAL` = rowSums(.[3:21])) %>% \n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %>% \n    select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, \n           `AGED`, `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n3.6 Joining the attribute data and geospatial data\nTo perform a georelational join, fields from mpsz and popdata2020 should align. Currently, the values in PA and SZ fields in mpsz and popdata2020 are in uppercase and lowercase respectively. As such, we will need to convert the values in popdata2020 to uppercase first.\n\npopdata2020 <- popdata2020 %>% \n    mutate_at(.vars = vars(PA, SZ),\n              .funs = list(toupper)) %>% \n    filter(`ECONOMY ACTIVE` > 0)\n\nTo keep the joined table as a simple features data frame, we will use a left_join() with mpsz which is simple features data frame as the left table. In the following, we used the planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands_on_ex/hands_on_ex1b/hands_on_ex1b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1B: Choropleth Mapping with R",
    "section": "4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "4 Choropleth Mapping Geospatial Data Using tmap\nThere are two approaches to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map is by using qtm(). It is concise and provides a good default visualisation in many cases. The following draw a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThe above produces a static map. For an interactive map, “view” option can be used instead of “plot”.\n\n\n4.2 Creating a choropleth map by using tmap’s elements\nAlthough qtm() draws a choropleth map quickly and easily, the aesthetics of the individual map layers is hard to control. This can be circumvented by using tmap’s drawing elements.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, the tmap functions that were used to plot these elements are discussed.\n\n4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons(). In the following, tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable to tm_polygons(). In the following, the variable assigned is DEPENDENCY.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in a subsequent section.\n\n\n4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nIn fact, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nBy using tm_fill() alone, no border is shown on the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders will be used as shown below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBesides the alpha argument, there are three other arguments for tm_borders():\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification to group together data observations.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nThe classification method is defined using the style argument of tm_fill() or tm_polygons().\n\n4.3.1 Plotting choropleth maps with built-in classification methods\nThe following uses a quantile data classification that involves 5 classes. The jenks style identifies groups of similar values in the data and maximises the differences between categories.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the following, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nComparing the two plots above, it can be noticed that the distribution of quantile data classification method is more evenly distributed than the equal data classification method.\nWe also explored 2 additional styles. The first is kmeans which uses the kmeans function to generate the breaks.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe other style explored is Pretty which rounds the breaks into whole numbers where possible and spaces them evenly. This is also the default style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nSimilar to the equal style, pretty style gives a less evenly distributed classification. Out of the 4 styles evaluated, kmeans seems to give the most evenly distributed classification for this data set.\nIn the following, we will explore different values of n using jenks style.\n\nw1 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw2 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 3,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw3 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE) \n\nw4 <- tm_shape(mpsz_pop2020)+\n      tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n      tm_borders(alpha = 0.5)+\n  tm_layout(legend.outside = TRUE)  \n\ncurrent.mode <- tmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(w1, w2, w3, w4)\n\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\nSome legend labels were too wide. These labels have been resized to 0.64. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\ntmap_mode(current.mode)\n\ntmap mode set to plotting\n\n\nFrom the 4 plots above, it seems that using higher values of n, i.e. 10 and 20 gives a better visualisation in understanding the differences in dependencies across different subzones. It can also be observed that for all 4 plots, the last dependency is 1.33 to 19.00 and the lower dependencies comprise of 0.00 to 1.33. For n = 20, while it can be clear how the dependency in one region differs from another based on the colour and its intensity, the gap between the dependency can be insignificant since the dependency of range 0.00 to 1.33 is divided into 19 parts.\n\n\n4.3.2 Plotting choropleth map with custom break\nWe will first get some statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n4.4.1 Using ColourBrewer palette\nTo change the color from the default YlorRd as shown in earlier plots, we assign the preferred color to tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the plot above, the lighter colors represent lower dependency values. We can reverse the order by adding a “-” prefix to the color shading defined as shown below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n4.5 Map Layouts\nIn the earlier sections, we adjusted colour settings and data classification methods that relate to the palette and break-points are used to affect how the map looks. In this section, we will focus on map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\n\n4.5.1 Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n4.5.2 Map style\nThe following uses a classic map style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn thefollowing, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThe following can be run to reset to the default style.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n4.6.1 By assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n4.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n4.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, the selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, computation of Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package will be demonstrated. The objectives of this exercise is as follows:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-analytical-question",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-analytical-question",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, one of the main development objectives of the local government and planners is to ensure equal distribution of development in the province. In this exercise, we will apply appropriate spatial statistical methods to answer “Are developments evenly distributed geographically?”. If they are not, we will then answer “Is there sign of spatial clustering?”. And if yes, we will want to find out “Where are these clusters?”\nIn this case study, we will examine the spatial pattern of a selected development indicator, Gross Domestic Product per Capita (GDPPC) of Hunan Provice, People Republic of China."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-study-area-and-data",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#the-study-area-and-data",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#setting-the-analytical-tools",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#setting-the-analytical-tools",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "2.3 Setting the Analytical Tools",
    "text": "2.3 Setting the Analytical Tools\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will install the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-shapefile-into-r-environment",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into R environment",
    "text": "3.1 Import shapefile into R environment\nThe imported shapefile will be a simple features object of sf package.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-csv-file-into-r-environment",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into R environment",
    "text": "3.2 Import csv file into R environment\nThe following yields an output in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#performing-relational-join",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#performing-relational-join",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe following code chunk updates the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan <- left_join(hunan,hunan2012)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#visualising-regional-development-indicator",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "3.4 Visualising Regional Development Indicator",
    "text": "3.4 Visualising Regional Development Indicator\nUsing qtm() from tmap package, we prepare a basemap and a choropleth map showing the distribution of GDPPC 2012.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-contiguity-spatial-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\nWe will first compute a spatial weights of the geographical units (i.e. county) in the study area. The spatial weights is used to define the neighbourhood relationship between the geographical units.\nIn the following code chunk, poly2nb()from spdep package is used to compute the contiguity weight matrices for the study area. By default, this function builds a list of neighbours based on regions with contiguous boundaries, using the Queen criteria. This based on the argument Queen set to True by default. Setting to False will enable Rook criteria.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#row-standardised-weights-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (using nb2listw() argument style=“W”). This is accomplished by assigning the fraction 1/(number of neighbours) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values. One drawback of this approach is that polygons along the edges of the study area will base their lagged values on fewer polygons and this can potentially over- or under-estimate the true spatial autocorrelation in the data. For simplicity, we will use the style=“W” option for our example. There are other more robust options available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”.\n\nB is the basic binary coding (given weight of 0 or 1 and only 1 is recorded).\nW is row standardised (sums over all links to n).\nC is globally standardised (sums over all links to n),\nU is equal to C divided by the number of neighbours (sums over all links to unity), and\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible approach."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-morans-i",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.3 Global Spatial Autocorrelation: Moran’s I",
    "text": "4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, we will demonstrate how to perform Moran’s I statistics testing by using moran.test() of spdep. Moran’s I is a test for spatial autocorrelation. It measures the overall spatial autocorrelation of the data, i.e. overall, how one object is similar or dissimilar to others surrounding it, evaluating whether the observation (in our case, GDPPC) is clustered, dispersed, or random.\nThe values of Moran’s I range from +1 meaning strong positive spatial autocorrelation (clustering) to 0 meaning a random pattern to -1 indicating strong negative spatial autocorrelation (dispersion).\n\n4.3.1 Moran’s I test\nThe null hypothesis we are testing states that “The GDPPC values are randomly distributed across counties, following a completely random process”. The alternative hypothesis is”The GDPPC value is not randomly dispersed, i.e. it is clustered in noticeable patterns”.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Moran I statistic (0.30075) is positive, we reject the null hypothesis and conclude that the GDPPC is spatially clustered.\n\n\n4.3.2 Computing Monte Carlo Moran’s I\nThe Moran’s I analysis benefits from being fast. But it may be sensitive to irregularly distributed polygons. A safer approach to hypothesis testing is to run a Monte Carlo simulation using the moran.mc() function. The moran.mc function takes an extra argument n, the number of simulations.\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, GDPPC is spatially clustered.\n\n\n4.3.3 Computing Monte Carlo Maron’s I\nTo examine the simulated Moran’s I test statistics in greater detail, we can plot the distribution of the statistical values as a histogram by using the following code chunk.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\",\n     main = \"Histogram of Monte Carlo Simulation of Moran's I\")\nabline(v=0, \n       col=\"red\") \nabline(v=0.30075, \n       col=\"blue\") \ntext(0.27, 120, \"Moran's I value = 0.30\", cex = 0.8, col='blue')\n\n\n\n\nThe Moran’s I value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates a statistically significant relationship. [1]\nWe can also plot the histogram using ggplot2 package as demonstrated in the following code chunk.\n\nggplot(data=data.frame(bperm$res), aes(x=bperm$res)) + \n  geom_histogram(binwidth=0.019,\n                 colour = \"black\",\n                 lwd = 0.75) +\n    ylim(0,120) +\n    ggtitle(\"Histogram of Monte Carlo Simulated Moran's I\") +\n    xlab(\"Simulated Moran's I\") +\n    ylab(\"Frequency\") +\n    geom_vline(xintercept = 0, color = \"red\") +\n    geom_vline(xintercept = 0.3, color = \"blue\") +\n    geom_label(x=0.26, y=120, label = \"Actual Moran's I = 0.30\", size = 3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-gearys-c",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#global-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "4.4 Global spatial autocorrelation: Geary’s C",
    "text": "4.4 Global spatial autocorrelation: Geary’s C\nGeary’s C is a measure of spatial autocorrelation or an attempt to determine if adjacent observations of the same phenomenon are correlated. How this differs from Moran’s I is that in general, Moran’s I is a measure of global spatial autocorrelation, while Geary’s C is more sensitive to local spatial autocorrelation. Geary’s C is also known as Geary’s contiguity ratio or simply Geary’s ratio.\nA Geary’s C statistic close to 1 indicates that there is no significant autocorrelation between observation i and its neighbors, where Geary’s C statistic < 1 indicates that the observation has neighbors which are significantly similar to it (positive spatial autocorrelation). Likewise, Geary’s C statistic > 1, demonstrates that the observation is among neighbors which differ significantly from it (negative spatial autocorrelation). [2]\n\n4.4.1 Geary’s C test\nIn Geary’s C test, we define the null hypothesis “There is no association between the GDPPC observed at a location and values observed at nearby sites”. The alternative hypothesis is “Nearby sites have either similar or dissimilar GDPPC values”. The code chunk below perform Geary’s C test for spatial autocorrelation by using geary.test() from spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nSince p-value is < 0.05 (statistically significant) and Geary’s C statistic (0.69072) is less than 1, we reject the null hypothesis and conclude that counties have GDPPC that are positively spatially autocorrelated with that of their neighbours.\n\n\n4.4.2 Computing Monte Carlo Geary’s C\nSimilarly, we can also run a Monte Carlo simulation for Geary’s C. The code chunk below performs permutation test for Geary’s C statistic by using geary.mc() from spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nSimilarly, we observe that p-value is < 0.05 (statistically significant) and Geary’s C statistic (0.69072) is less than 1. We reject the null hypothesis and conclude that counties have GDPPC that are positively spatially autocorrelated with that of their neighbours.\n\n\n4.4.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary's C\",\n     main = \"Histogram of Monte Carlo Simulation of Geary's C\")\nabline(v=1, col=\"red\")\nabline(v=0.69, \n       col=\"blue\") \ntext(0.73, 180, \"Geary's C value = 0.69\", cex = 0.8, col='blue')"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-morans-i-correlogram",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "5.1 Compute Moran’s I correlogram",
    "text": "5.1 Compute Moran’s I correlogram\nIn the following code chunk, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nIn addition to plotting the output, we need to understand which autocorrelation values are statistically significant to allow for a complete analysis. Hence, we will need to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the following, we calculate the mean distance of the lag orders 1 to 6. We use nblag() function which creates higher order neighbour lists, where higher order neighbours are only lags links from each other on the graph described by the input neighbours list. [3]\n\nnb6 <- nblag(wm_q, 6)\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords <- cbind(longitude, latitude)\ncorrelogram_bins <- sapply(nb6, function(x) mean(unlist(nbdists(x,coords, longlat = TRUE))))\ncorrelogram_bins\n\n[1]  55.87022 106.63386 162.68268 219.05977 271.93585 323.41649\n\n\nFrom the correlogram and the analysis report, we can see for lag 1 and lag 2 (counties within distances of 55.87km and 106.63km apart respectively), the Moran’s I values is positive and p-value is < 0.05 (statistically significant). This indicate that the GDPPC are spatially clustered for lag 1 and lag2.\nFor lags 3 and 4 (counties within distances of 162.68 km to 219.06 km respectively), while the Moran’s I values are positive, the p-values are both > 0.05 (not statistically significant). Hence we cannot reject the null hypothesis. It is possible that the spatial distribution of the GDPPC values is the result of random spatial processes.\nFor lags 5 and 6 (counties within distances of 217.94 km and 323.42 km), the Moran’s I values are negative, the p-values are both < 0.05 (statistically significant). Hence, we can reject the null hypothesis and the spatial distribution of the GDPPC is more spatially dispersed than would be expected if the underlying spatial processes are random."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-gearys-c-correlogram-and-plot",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "5.2 Compute Geary’s C correlogram and plot",
    "text": "5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFor lags 1 to 5, the results obtained from Geary’s C yield the same conclusion as that from Moran’s I. For lag 6: Moran’s I concluded that for counties that are lag 6 apart, the spatial distribution of the GDPPC is spatially dispersed. On the other hand, in Geary’s C results for lag 6, the p-value is > 0.05 (not statistically significant), so we cannot reject the null hypothesis and there is a possibility that the spatial distribution of the GDPPC is random."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-local-morans-i",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-local-morans-i",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "6.1 Computing local Moran’s I",
    "text": "6.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n6.1.1 Mapping the local Moran’s I values\nBefore mapping the local Moran’s I map, we will append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n6.1.2 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n6.1.3 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5) +\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2) \n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nFrom the plots above, there are 11 counties with p-values < 0.05 (statistically significant). In the next section, we will further analyse the type of spatial distribution for GDPPC values for these counties."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.1 Plotting Moran scatterplot",
    "text": "7.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nWe can observe that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the high levels of GDPPC. This are the high-high locations."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.2 Plotting Moran scatterplot with standardised variable",
    "text": "7.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\nHowever, the Moran scatterplot has one drawback in that it does not indicate whether the LGAs identified are significant or not. As such, we will work on the LISA cluster map."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#preparing-lisa-map-classes",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.3 Preparing LISA map classes",
    "text": "7.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, we derive the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I <- localMI[,1] - mean(localMI[,1])     \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05  \n\nThese four command lines define the high-high, low-low, low-high and high-low categories.\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4   \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-lisa-map",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#plotting-lisa-map",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "7.4 Plotting LISA map",
    "text": "7.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc <- qtm(hunan, \"GDPPC\")+\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)+\n    tm_shape(hunan.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\")\n\ntmap_arrange(gdppc, LISAmap, asp=1, ncol=2)\n\n\n\n\nIn the plots above, we observe 11 counties with local Moran’s I values that have p-values < 0.05 (statistically significant). These counties are classified as below:\n\nhigh-high quadrant: counties Miluo, Wangcheng, Changsha, Liuyang, Zhuzhuo, and Liling are counties that have high GDPPC values and are surrounded by other counties with high GDPPC.\nlow-low quandrant: counties Longhui and Wugang are counties that have low GDPPC values and are surrounded by other counties with low GDPPC.\nlow-high quadrant: counties Taojiang, Pingjiang, and Xiangtan are “spatial outliers” whereby these counties have low GDPPC values but are surrounded by other counties with high GDPPC."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#getis-and-ords-g-statistics",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.1 Getis and Ord’s G-Statistics",
    "text": "8.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#deriving-distance-based-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#deriving-distance-based-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.2 Deriving distance-based matrix",
    "text": "8.2 Deriving distance-based matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n8.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\n\n\n8.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n8.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-adaptive-distance-weight-matrix",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "8.3 Computing adaptive distance weight matrix",
    "text": "8.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-fixed-distance",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.1 Gi statistics using fixed distance",
    "text": "9.1 Gi statistics using fixed distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below. It performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-fixed-distance-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.2 Mapping Gi values with fixed distance weights",
    "text": "9.2 Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc <- qtm(hunan.gi, \"GDPPC\")+\n    tm_shape(hunan.gi %>% filter(gstat_fixed > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_fixed < -1)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)+\n    tm_shape(hunan.gi %>% filter(gstat_fixed > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_fixed < -1)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nA high positive local Gi score indicates a hotspot. The higher the local Gi score, the more intense the spatial clustering. The counties Wangcheng, Chengsha, and Xiangyin have the highest local Gi score of 4-6, indicating that these counties have the most intense clustering where they have high GDPPC values and are surrounded by counties with high GDPPC.\nA low negative local Gi score indicates a coldspot. The lower the score, the more intense the clustering. 17 of the counties are identified to have coldspot with local Gi values of lower than -1 and are annotated in the above plot in red."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-adaptive-distance",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.3 Gi statistics using adaptive distance",
    "text": "9.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "hands_on_ex/hands_on_ex2/hands_on_ex2.html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.4 Mapping Gi values with adaptive distance weights",
    "text": "9.4 Mapping Gi values with adaptive distance weights\nWe can then visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc<- qtm(hunan.gi, \"GDPPC\")+\n    tm_shape(hunan.gi %>% filter(gstat_adaptive > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_adaptive < -2)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\") \n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)+\n    tm_shape(hunan.gi %>% filter(gstat_adaptive > 4)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"black\") +\n    tm_shape(hunan.gi %>% filter(gstat_adaptive < -2)) +\n    tm_text(\"NAME_3\", size=0.3, col = \"red\")\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nUsing adaptive distance weights, the most intense hotspots are identified to be Xiangyin, Pingjiang, Liuyang, Zhuzhuo, and Wangcheng with local Gi values of above 4. These counties have the most intense clustering where they have high GDPPC values and are surrounded by counties with high GDPPC.\nThe most intense coldspots are identified to be Xinning, Suining, and Wugang with local Gi values lower than -2. These counties have the most intense clustering where they have low GDPPC values and are surrounded by counties with low GDPPC."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two main analysis, namely:\n\nhierarchical cluster analysis, and\nspatially constrained cluster analysis\n\n\n\nBy the end of this hands-on exercise, the following can be achieved:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#getting-started",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#getting-started",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using the penetration of multiple Information and Communication Technology (ICT) measures, namely: Radio, Television, Landl line ohone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#the-data",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#the-data",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3 The Data",
    "text": "3 The Data\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries): This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth datasets are downloaded from Myanmar Information Management Unit (MIMU)\n\n3.1 Installing and loading R packages\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment. The R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse (which contains readr, ggplot2 and dplyr)\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(rgdal, spdep, tmap, sf, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#data-import-and-preparation",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#data-import-and-preparation",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4 Data Import and Preparation",
    "text": "4 Data Import and Preparation\n\n4.1 Importing geospatial data into R environment\nIn this section, we will import Myanmar Township Boundary GIS data and its associated attribute table into R environment.\nThe Myanmar Township Boundary GIS data is in ERSI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf <- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %>%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\"))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID           ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1       163 Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2       203 Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3       240 Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4       106 Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5        72 Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6        40 Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7       194 Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8       159 Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9        61 Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10      124 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                 ST_2            LABEL2 SELF_ADMIN ST_RG T_NAME_WIN T_NAME_M3\n1  Shan State (North)    Mongmit\\n61072       <NA> State   rdk;rdwf      မိုးမိတ်\n2  Shan State (South)    Pindaya\\n77769       Danu State     yif;w,     ပင်းတယ\n3  Shan State (South)    Ywangan\\n76933       Danu State      &GmiH       ရွာငံ\n4  Shan State (South)  Pinlaung\\n162537       Pa-O State  yifavmif;   ပင်လောင်း\n5  Shan State (North)     Mabein\\n35718       <NA> State     rbdrf;      မဘိမ်း\n6  Shan State (South)     Kalaw\\n163138       <NA> State       uavm      ကလော\n7  Shan State (South)      Pekon\\n94226       <NA> State     z,fcHk       ဖယ်ခုံ\n8  Shan State (South)          Lawksawk       <NA> State   &yfapmuf    ရပ်စောက်\n9  Shan State (North) Nawnghkio\\n128357       <NA> State  aemifcsdK    နောင်ချို\n10 Shan State (North)   Kyaukme\\n172874       <NA> State   ausmufrJ    ကျောက်မဲ\n       AREA                       geometry\n1  2703.611 MULTIPOLYGON (((96.96001 23...\n2   629.025 MULTIPOLYGON (((96.7731 21....\n3  2984.377 MULTIPOLYGON (((96.78483 21...\n4  3396.963 MULTIPOLYGON (((96.49518 20...\n5  5034.413 MULTIPOLYGON (((96.66306 24...\n6  1456.624 MULTIPOLYGON (((96.49518 20...\n7  2073.513 MULTIPOLYGON (((97.14738 19...\n8  5145.659 MULTIPOLYGON (((96.94981 22...\n9  3271.537 MULTIPOLYGON (((96.75648 22...\n10 3920.869 MULTIPOLYGON (((96.95498 22...\n\n\nSince sf.data.frame conforms to the tidy framework, we can use glimpse()` to reveal the data type in each field in shan_sf.\n\n\n4.2 Importing aspatial data into R environment\nThe csv file will be imported using read_csv frunction of readr package as shown in the following code chunk:\n\nict <- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s tibble data.frame format.\nThe code chunk below shows the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nWe can see that there a total of eleven fields and 55 observations in the tibble data.frame.\n\n\n4.3 Deriving new variables uing dplyr package\nThe data in ict provides the count of the number of households. Such units of measurement is directly biased by the underlying total number of households in the town. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV etc.\nIn order to overcome this issue, we will derive the penetration rate for each ICT by using the code chunk below.\n\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*100) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*100) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*100) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*100) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*100) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*100) %>%\n  rename(`DT_PCODE` =`District Pcode`,\n         `DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, \n         `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, \n         `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, \n         `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, \n         `INTERNET`=`Internet at home`) \n\nWe can review the summary statistics of the newly derived variables using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 2.105  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:13.895  \n Median : 3559   Median : 244.0   Median : 316.0   Median :21.095  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :21.568  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:26.807  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :48.452  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :11.60   Min.   : 0.278   Min.   : 3.642   Min.   :0.3278  \n 1st Qu.:45.02   1st Qu.: 2.284   1st Qu.:19.014   1st Qu.:1.1832  \n Median :51.72   Median : 3.759   Median :30.527   Median :1.8970  \n Mean   :50.95   Mean   : 5.109   Mean   :31.405   Mean   :2.4393  \n 3rd Qu.:60.64   3rd Qu.: 6.972   3rd Qu.:42.843   3rd Qu.:2.9897  \n Max.   :84.25   Max.   :18.149   Max.   :73.543   Max.   :9.2402  \n  INTERNET_PR     \n Min.   : 0.1041  \n 1st Qu.: 0.8617  \n Median : 2.2829  \n Mean   : 3.0644  \n 3rd Qu.: 4.1281  \n Max.   :11.7985"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#exploratory-data-analysis-eda",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5 Exploratory Data Analysis (EDA)",
    "text": "5 Exploratory Data Analysis (EDA)\n\n5.1 EDA using statistical graphs\nWe can plot the overall distribution of the variables by using a histogram. Using a histogram allows us to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).\nIn the following code chunk, we derive the histogram plot for the number of radios.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nTo identify outliers, boxplots can be used.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nNext, we will plot the distribution of the newly derived variables. In the following code chunk, we plot the histogram for the radio penetration rate.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nFrom the histogram, we can observe a slight right skew in the distribution of the radio penetration rate - there is more lower radio pentration rates compared to higher radio penetration rates.\nLikewise, we will generate the boxplot for the radio pentration rate.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nFrom the boxplot, we can see that the median radio pentration rate is slightly over 20%. It can also be observed that there is an outlier township that with significantly high radio penetration rate of about 49%. The range of radio pentration rate across the townships also vary widely, from about 2% to 49% penetration rates.\nWe can also plot multiple histograms together in the same plot to reveal the distribution of various variables. We can do this by first creating the individual histograms and then using ggarange() function from ggpubr package is used to group these histograms together.\n\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n5.2 EDA using choropleth map\n\n5.2.1 Joining geospatial data with aspatial data\nIn order to plot the choropleth map, we need to combine the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived). This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf <- left_join(shan_sf, \n                     ict_derived, \n                     by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n\n\n\n5.2.2 Plotting a choropleth map\nWe will have a look at the distribution of Radio penetration rate of Shan State at township level by plotting a choropleth map. The code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nHowever, the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships. To demonstrate this, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nThe choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\nHere, we can see that larger townships do not necessarily have higher radio penetration. By using the radio penetration rate, we are able to correctly reflect which township has higher proportion of their residents having radios."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#correlation-analysis",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#correlation-analysis",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6 Correlation Analysis",
    "text": "6 Correlation Analysis\nIt is important for us to ensure that cluster variables are not highly correlated when we perform cluster analysis. This is because we do not want to give extra weight to these highly correlated variables.\nWe will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation between the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#hierarchical-cluster-analysis",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#hierarchical-cluster-analysis",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7 Hierarchical Cluster Analysis",
    "text": "7 Hierarchical Cluster Analysis\nIn this section, we will perform hierarchical cluster analysis.\n\n7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into a data.frame. We will exclude the variables INTERNET_PR and keep only the COMPUTER_PR.\n\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 28.61852 55.41313   3.530618  26.06944    1.215939\n2    Pindaya 41.74647 50.51300   1.983584  16.23917    1.288190\n3    Ywangan 48.45215 26.05734   1.193591  12.02856    0.441465\n4   Pinlaung 23.16499 54.17189   2.854454  24.94903    1.376255\n5     Mabein 44.94903 70.86423   7.275255  39.26089    1.645042\n6      Kalaw 28.07624 61.16204   4.206478  40.87951    2.963160\n7      Pekon 31.86118 53.58494   3.983270  21.48476    1.897032\n8   Lawksawk 38.71017 63.00035   3.151366  32.05686    2.176677\n9  Nawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\n10   Kyaukme 21.09548 60.11773   3.958267  37.24930    3.094709\n\n\nNext, we will use the township name as the row names instead of using row number.\n\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 28.61852 55.41313   3.530618  26.06944    1.215939\nPindaya     Pindaya 41.74647 50.51300   1.983584  16.23917    1.288190\nYwangan     Ywangan 48.45215 26.05734   1.193591  12.02856    0.441465\nPinlaung   Pinlaung 23.16499 54.17189   2.854454  24.94903    1.376255\nMabein       Mabein 44.94903 70.86423   7.275255  39.26089    1.645042\nKalaw         Kalaw 28.07624 61.16204   4.206478  40.87951    2.963160\nPekon         Pekon 31.86118 53.58494   3.983270  21.48476    1.897032\nLawksawk   Lawksawk 38.71017 63.00035   3.151366  32.05686    2.176677\nNawnghkio Nawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\nKyaukme     Kyaukme 21.09548 60.11773   3.958267  37.24930    3.094709\n\n\nWe can then delete the TS.x field (column for township names).\n\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   28.61852 55.41313   3.530618  26.06944    1.215939\nPindaya   41.74647 50.51300   1.983584  16.23917    1.288190\nYwangan   48.45215 26.05734   1.193591  12.02856    0.441465\nPinlaung  23.16499 54.17189   2.854454  24.94903    1.376255\nMabein    44.94903 70.86423   7.275255  39.26089    1.645042\nKalaw     28.07624 61.16204   4.206478  40.87951    2.963160\nPekon     31.86118 53.58494   3.983270  21.48476    1.897032\nLawksawk  38.71017 63.00035   3.151366  32.05686    2.176677\nNawnghkio 34.93359 54.79456   3.844960  32.30201    1.576465\nKyaukme   21.09548 60.11773   3.958267  37.24930    3.094709\n\n\n\n\n7.2 Data Standardisation\nNext, we will perform data standardisation. It is not unusual that value ranges of differnet variables can differ significantly. As we want to avoid the cluster analysis from being biased towards clustering variables that have larger values.\n\n7.2.1 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nWe can observe that the value range for each variable is now between 0 and 1 after min0max standardisation is performed.\n\n\n7.2.2 Z-score standardisation\nZ-score standardisation can be performed by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method. In here, we will use describe() from psych package to to review the results instead of summary() of Base R because the describe() provides standard deviation.\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nWe can observe that the mean and standard deviation of the Z-score standardised variable are now 0 and 1 respectively. However, we will also need to wary that Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n7.2.3 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plots the scaled Radio_PR field.\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\nWe can observe that the overall distribution of the clustering variable changes after data standardisation is performed. Hence, it is not advisable to perform data standardisation if the value ranges of the clustering variables are not very large.\n\n\n\n7.3 Computing proximity matrix\nIn R, there are many packages that provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is the euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat <- dist(shan_ict, method = 'euclidean')\n\n\n\n7.4 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used. There are eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the dendrogram produced by the clustering process.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the dendrogram by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n7.5 Selecting the optimal clustering algorithm\nOne of the challenges in performing hierarchical clustering is to identify the strongest clustering structures. The issue can be solved by using agnes() function from cluster package. It functions like hclus(), however, with the agnes() function we can also get the agglomerative coefficient, which measures the amount of clustering structure found. The closer the coefficient is to 1, the stronger the clustering structure.\nThe code chunk below will be used to compute the agglomerative coefficients of 4 hierarchical clustering algorithm: “average”, “single”, “complete”, and “ward”.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWe can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n7.6 Determining the optimal number of clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\nHere, we will explore the gap statistic method.\n\n7.6.1 Gap statistic method\nThe gap statistic compares the total intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be the value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is furthest away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 6.104544 6.378209 0.2736651 0.04460994\n [2,] 5.827444 6.048127 0.2206824 0.03880130\n [3,] 5.689680 5.899965 0.2102844 0.03362652\n [4,] 5.559639 5.778070 0.2184311 0.03784781\n [5,] 5.453876 5.675437 0.2215615 0.03897071\n [6,] 5.363009 5.585192 0.2221833 0.03973087\n [7,] 5.288334 5.503748 0.2154145 0.04054939\n [8,] 5.224095 5.429034 0.2049390 0.04198644\n [9,] 5.155439 5.358210 0.2027705 0.04421874\n[10,] 5.074827 5.291273 0.2164465 0.04540947\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the next largest gap statistic and should be the next best cluster to pick.\n\n\n\n7.7 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nWe use the height of the fusion, provided on the vertical axis, to tell the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Such conclusions on proximity of two observations can only be drawn based on the height where the branches containing those two observations first are fused.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n7.8 Visually-driven hierarchical clustering analysis\nIn this section, we will perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.8.1 Transforming the data frame into a matrix\nThe data has to be a data matrix to make a heatmap using the heatmaply package.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat <- data.matrix(shan_ict)\n\n\n\n7.8.2 Plotting the interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n7.9 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups which is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below performs the following three steps:\n\nthe groups list object will be converted into a matrix using as.matrix();\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map to show the 6 clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nHowever, we can see that the clustered formed are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#spatially-constrained-clustering---skater-approach",
    "href": "hands_on_ex/hands_on_ex3/hands_on_ex3.html#spatially-constrained-clustering---skater-approach",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8 Spatially Constrained Clustering - SKATER Approach",
    "text": "8 Spatially Constrained Clustering - SKATER Approach\nIn this section, we will derive spatially constrained cluster by using skater() from spdep package.\n\n8.1 Converting data into SpatialPolygonsDataFrame\nFirst, we will need to convert shan_sf into a SpatialPolygonsDataFrame. This is because SKATER function only supports sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp <- as_Spatial(shan_sf)\n\n\n\n8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb <- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe will plot the neighbours list on shan_sp by using the code chunk below. We will first plot the community area boundaries. It is important to first plot the area boundaries as the they extend further than the network graph. If done otherwise, some of the boundaries will be clipped. We then plot the neighbour list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n8.3 Computing minimum spanning tree\nIn this section, we will compute the minimum spanning tree. The minimum spanning tree is the one whose cumulative edge weights have the smallest value. We can think of this as the least cost path that goes through the entire graph and touches very node.\n\n8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts <- nbcosts(shan.nb, shan_ict)\n\nFor each observation, lcosts this gives the pairwise dissimilarity between its values on the five variables and that of each of its neighbours. This forms the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object, i.e., we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nWe specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1      S2\nB 55 3025 7626.765 582607.8 5220160\n\n\n\n\n8.3.2 Computing minimum spanning tree\nNext, we will calculate the minimum spanning tree. The minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst <- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunks below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nWe can observe that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   31   25 22.944658\n[2,]   25   10 16.395741\n[3,]   10    1 14.402475\n[4,]   10    9 15.704230\n[5,]    9    8  9.082891\n[6,]    8    6 14.001101\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n8.4 Computing spatially constrained clusters using SKATER method\nThe code chunk below computes the spatially constrained cluster using skater() of spdep package.\n\nclust6 <- skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments:\n\nedges: the first two columns of the MST matrix (i.e. excluding the cost)\ndata: the data matrix (to update the costs as units are being grouped), and\nncuts: the number of cuts. Note: It is set to one less than the number of clusters.\n\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 31 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 31 13 13 ...\n  .. ..$ ssw : num 342\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 376\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 146\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 9.5\n  .. ..$ ssw : num 9.5\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 1261\n $ ssw         : num [1:6] 1261 1098 996 954 912 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label is arbitary). This is followed by a detailed summary for each of the clusters, provided in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the code chunk below.\n\nccs6 <- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations there are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 22 (given by $ node: num [1:22]), which is also the number of observations in the first cluster ()which aligns with the results from the code chunk below).\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n8.5 Visualising the clusters in a choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat <- as.matrix(clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it is better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map <- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\n\n\n\nComparing these 2 maps, it is clear that the spatially constrained clustering gives a better clustering where clusters are constrained together and not fragmented, unlike in the map given by hierarchical clustering."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey for geospatial analytics."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html",
    "href": "in_class_ex/ex1/in-class-ex1.html",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, I will demonstrate computing spatial weights using R. The following steps are included in this exercise:\n\nimporting geospatial data using appropriate function(s) from sf package,\nimporting csv file using appropriate function from readr package,\nperforming relational join using appropriate join function from dplyr package,\ncomputing spatial weights using appropriate functions from spdep package, and\ncalculating spatially lagged variables using appropriate functions from spdep package."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#getting-started",
    "href": "in_class_ex/ex1/in-class-ex1.html#getting-started",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#import-shapefile-into-r-environment",
    "href": "in_class_ex/ex1/in-class-ex1.html#import-shapefile-into-r-environment",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe following code chunk imports the Hunan shapefile into R. The imported shapefile is a simple features object of sf package.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\lohsiying\\ISSS624\\in_class_ex\\ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#import-csv-file-into-r-environment",
    "href": "in_class_ex/ex1/in-class-ex1.html#import-csv-file-into-r-environment",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.2 Import csv file into R environment",
    "text": "3.2 Import csv file into R environment\nIn the following code chunk, imports a csv file using read_csv() of readr package to give an output in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#performing-relational-join",
    "href": "in_class_ex/ex1/in-class-ex1.html#performing-relational-join",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "3.3 Performing relational join",
    "text": "3.3 Performing relational join\nThe code chunk updates the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() from dplyr package.\n\nhunan <- left_join(hunan,hunan2012)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-queen-contiguity-based-neighbours",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-queen-contiguity-based-neighbours",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.1 Computing (QUEEN) contiguity based neighbours",
    "text": "5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute the Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, in the following code chunk we can see the neighbors for the first polygon:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the following code chunk can be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five counties by using the code chunk below.\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nTo display the complete weight matrix, str() can be used.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#creating-rook-contiguity-based-neighbours",
    "href": "in_class_ex/ex1/in-class-ex1.html#creating-rook-contiguity-based-neighbours",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.2 Creating (ROOK) contiguity based neighbours",
    "text": "5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. Using the Rook’s method, the most connect area unit has 10 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#visualising-contiguity-weights",
    "href": "in_class_ex/ex1/in-class-ex1.html#visualising-contiguity-weights",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "5.3 Visualising contiguity weights",
    "text": "5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. Now the data is in polygon format, so we will need to get points in order to make our connectivity graphs. The most typical method for this will be to use polygon centroids by specifying their Latitude and Longitude. We will calculate these in the sf package before moving onto the graphs.\nWe need the Latitude and Longitude coordinates in a separate data frame for this. To do this we will use a mapping function to apply a given function to each element of a vector and return a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value of each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\n\n5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n5.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2), mar = c(0, 0, 2, 3) + 0.1)\nplot(hunan$geometry, border=\"lightgrey\", main = 'Queen Contiguity')\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main = 'Rook Contiguity')\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#determine-the-cut-off-distance",
    "href": "in_class_ex/ex1/in-class-ex1.html#determine-the-cut-off-distance",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.1 Determine the cut-off distance",
    "text": "6.1 Determine the cut-off distance\nWe will first determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper bound gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-fixed-distance-weight-matrix",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-fixed-distance-weight-matrix",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.2 Computing fixed distance weight matrix",
    "text": "6.2 Computing fixed distance weight matrix\nNext, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe output above shows that on average, each region has 3.68 neighbours.\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() from spdep package.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$n\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2), mar = c(0, 0, 2, 3) + 0.1)\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08, main=\"1st nearest neighbours\")\ntitle(main = '1st nearest neighbours')\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#computing-adaptive-distance-weight-matrix",
    "href": "in_class_ex/ex1/in-class-ex1.html#computing-adaptive-distance-weight-matrix",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nIn this way, each county has the same number of neighbours at exactly six neighbours!\n\n6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "7.1 Spatial lag with row-standardized weights",
    "text": "7.1 Spatial lag with row-standardized weights\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (using nb2listw() argument style=“W”). This is accomplished by assigning the fraction 1/(number of neighbours) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values. One drawback of this approach is that polygons along the edges of the study area will base their lagged values on fewer polygons and this can potentially over- or under-estimate the true spatial autocorrelation in the data. For simplicity, we will use the style=“W” option for our example. There are other more robust options available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s neighbors type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nEach neighbor is assigned a 0.2 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights-1",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-with-row-standardized-weights-1",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.1 Spatial lag with row-standardized weights",
    "text": "8.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWith reference to the following code chunk where we retrieve the GDPPC of the five neighbouring counties of the first county in our data, Anxiang:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nsum(nb1) / 5\n\n[1] 24847.2\n\n\nWe can see that Spatial lag with row-standardized weights gives each neighbour equal weight.\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.2 Spatial lag as a sum of neighboring values",
    "text": "8.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply().\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nsum(nb1)\n\n[1] 124236\n\n\nWe can see that Spatial lag as a sum of neighboring values simply sums the GDPPC values of all its neighbours.\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan <- left_join(hunan, lag.res)\n\nJoining, by = \"NAME_3\"\n\n\nNow, we can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-window-average",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-window-average",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.3 Spatial window average",
    "text": "8.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element - this means besides taking into consideration of its neighbours, this method also considers the county itself. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights. To begin we assign this to a new variable because we will directly alter its structure to add the diagonal elements.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we can use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNow we obtain weights using nb2listw()\n\nwm_q1 <- nb2listw(wm_q1)\nwm_q1\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nLastly, we need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc <- lag.listw(wm_q1, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, lag_wm_q1.res)\n\nJoining, by = \"NAME_3\"\n\n\nLastly, qtm() from tmap package is used to plot the GDPPC and lag_window_avg GDPPC map next to each other for quick comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex1/in-class-ex1.html#spatial-window-sum",
    "href": "in_class_ex/ex1/in-class-ex1.html#spatial-window-sum",
    "title": "In-Class Exercise 1: Spatial Weights and Applications",
    "section": "8.4 Spatial window sum",
    "text": "8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights. To do this we assign binary weights to the neighbor structure that includes the diagonal element.\n\nwm_q1 <- wm_q\n\nTo add the diagonal element to the neighbour list, we use include.self() from spdep.\n\ninclude.self(wm_q1)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nwm_q1\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights <- lapply(wm_q1, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 <- nb2listw(wm_q1, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nThe second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"NAME_3\"\n\n\nLastly, qtm() of tmap package is used to plot the GDPPC and lag_sum GDPPC map next to each other for quick comparison.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html",
    "href": "in_class_ex/ex2/in-class-ex2.html",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Access to safe water, sanitation and hygiene is the most basic human need for health and well-being. Despite efforts in raising the access to these basic services, according to the Sustainable Development Goals Report 2022 issued by the United Nations, by 2030, 1.6 billion people will lack safely managed drinking water, 2.8 billion people will lack safely managed sanitation, and 1.9 billion people will lack basic hand hygiene facilities.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas which then allows governments and their partners to make use of the data to improve decisions on a regular basis."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#aspatial-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#aspatial-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "3.1 Aspatial Data",
    "text": "3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,08 unique water point records."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#geospatial-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#geospatial-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#getting-started---setting-up-the-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#getting-started---setting-up-the-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.1 Getting Started - Setting up the environment",
    "text": "4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nsf,\ntidyverse,\ntmap,\nspdep, and\nfunModeling\n\n\npacman::p_load(sf, tmap, tidyverse, spdep, funModeling)"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#import-nigeria-lga-boundary-data-into-r-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#import-nigeria-lga-boundary-data-into-r-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.2 Import Nigeria LGA boundary data into R environment",
    "text": "4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\n\nThe above printout shows the data is in wgs84 geographic coordinate system. This is the required format as we will be using st_intersects() later which requires the data to be in wg84 coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga, \n          \"geodata/nga.rds\")"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#import-csv-file-into-r-environment",
    "href": "in_class_ex/ex2/in-class-ex2.html#import-csv-file-into-r-environment",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.3 Import csv file into R environment",
    "text": "4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwpd <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. We will then convert wpd data frame into a simple feature data frame by using the following code chunk and ensuring the data has the same wgs84 geographic coordinate system by specifying .\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwpd_sf <- st_as_sf(wpd,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geopatial folder.\n\nwrite_rds(wpd_sf, \n          \"geodata/wpd_nga.rds\")"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#data-wrangling-for-water-point-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#data-wrangling-for-water-point-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.4 Data Wrangling for Water Point Data",
    "text": "4.4 Data Wrangling for Water Point Data\n\n4.4.1 Recoding NA values into string\nWe will then load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp_nga <- read_rds(\"geodata/wpd_nga.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n4.4.2 EDA\n\nfreq(data = wp_nga,\n     input = 'status_clean')\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. We will create 2 separate dataframes each containing either type of functional water points."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#extracting-water-point-data",
    "href": "in_class_ex/ex2/in-class-ex2.html#extracting-water-point-data",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.5 Extracting Water Point Data",
    "text": "4.5 Extracting Water Point Data\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_nga %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.4.2.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\nThe output shows that filtering was performed successfully."
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#performing-point-in-polygon-count",
    "href": "in_class_ex/ex2/in-class-ex2.html#performing-point-in-polygon-count",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.6 Performing Point-in-Polygon Count",
    "text": "4.6 Performing Point-in-Polygon Count\nNext, we want to find the number of functional water points in each LGA as well as the number of total, functional, non-functional, and unknown water points in each LGA. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nnga_wp <- nga %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nga, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nga, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nga, wp_unknown)))"
  },
  {
    "objectID": "in_class_ex/ex2/in-class-ex2.html#saving-the-analytical-data-table",
    "href": "in_class_ex/ex2/in-class-ex2.html#saving-the-analytical-data-table",
    "title": "In-Class Exercise 2: Geospatial Analytics for Social Good",
    "section": "4.7 Saving the Analytical Data Table",
    "text": "4.7 Saving the Analytical Data Table\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional\n\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_non_functional = wp_nonfunctional/total_wp)\n\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html",
    "href": "take_home_ex/ex1/take-home-ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "Access to safe water, sanitation and hygiene is the most basic human need for health and well-being. Despite efforts in raising the access to these basic needs, according to the Sustainable Development Goals Report 2022 issued by the United Nations, by 2030, 1.6 billion people will lack safely managed drinking water, 2.8 billion people will lack safely managed sanitation, and 1.9 billion people will lack basic hand hygiene facilities.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas which then allows governments and their partners to make use of the data to improve decisions on a regular basis."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#objectives",
    "href": "take_home_ex/ex1/take-home-ex1.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "2 Objectives",
    "text": "2 Objectives\nGeospatial analytics offers a tremendous potential to solving societal problems. One such analytics is spatial autocorrelation which helps understand the degree to which one object is similar to its surrounding objects.\nThe objectives of this take-home exercise are as outlined in the following:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Any one of the three Projected Coordinate Systems of Nigeria, EPSG: 26391, 26392, and 26303 can be used.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nPerforming outliers/clusters analysis by using appropriate local measures of spatial association methods.\nPerforming hotspot areas analysis by using appropriate local measures of spatial association methods."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#the-data",
    "href": "take_home_ex/ex1/take-home-ex1.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "3 The Data",
    "text": "3 The Data\nIn this exercise, we will analyse the data from Nigeria. There are 2 datasets used, as outlined in sections 3.1 and 3.2.\n\n3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,008 unique water point records.\n\n\n3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#getting-the-data-into-r-environment",
    "href": "take_home_ex/ex1/take-home-ex1.html#getting-the-data-into-r-environment",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "4 Getting the Data Into R Environment",
    "text": "4 Getting the Data Into R Environment\n\n4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nsf for importing, managing, and processing geospatial data,\ntidyverse for performing data science tasks such as importing, wrangling and visualising data,\ntmap for creating thematic maps,\nspdep for handling geospatial data, and\nfunModeling for Exploratory Data Analysis and Data Preparation.\n\n\npacman::p_load(sf, tmap, tidyverse, spdep, funModeling)\n\n\n\n4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\nnga\n\nThe above printout shows the data is in wgs84 geographic coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga, \n          \"geodata/nga.rds\")\n\n\n\n4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwpd <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwpd_sf <- st_as_sf(wpd,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \nwpd_sf\n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geopatial folder.\n\nwrite_rds(wpd_sf, \n          \"geodata/wpd_nga.rds\")\n\n\n\n4.4 Data Wrangling for Water Point Data\n\n4.4.1 Recoding NA values into string\nWe will then load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp_nga <- read_rds(\"geodata/wpd_nga.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n4.4.2 EDA\nIn the following code chunk, we use freq() to determine the number of records in each classification for the status of the water points.\n\nfreq(data = wp_nga,\n     input = 'status_clean')\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. We will create 2 separate dataframes each containing either type of functional water points.\n\n\n\n4.5 Extracting Water Point Data\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_nga %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_nga %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.4.2.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\nThe output shows that filtering was performed successfully.\n\n\n4.6 Performing Point-in-Polygon Count\nNext, we want to find the number of functional water points in each LGA as well as the number of total, functional, non-functional, and unknown water points in each LGA. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nnga_wp <- nga %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nga, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nga, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nga, wp_unknown)))\n\nIn the following code chunk, we check whether there is any name of LGAs that are duplicated. duplicated() returns True for rows whether the shapeName is not unique. subset() returns only rows that fufill the criteria of duplicated rows = True.\n\nsubset(nga_wp, duplicated(nga_wp$shapeName))$shapeName\n\nFrom the above, we can see that there are 6 LGA names that have been repeated, namely ‘Bassa’, ‘Ifelodun’, ‘Irepodun’, ‘Nasarawa’, ‘Obi’, and ‘Surulere’.\nWe will add 2 columns for longitude and latitude which we will use to check the LGA names for the duplicated rows using latlong.net. The following code chunk adds columns for longitude and latitude.\n\nnga_wp$longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])\nnga_wp$latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])\n\nFor easier manipulation and renaming of LGAs, we will add a column for ID so that each LGA is assigned a unique ID. This is performed by the following code chunk, using row_number() from dplyr package.\n\nnga_wp <- dplyr::mutate(nga_wp, ID = row_number())\n\nWe will first look at the rows with “Bassa” name by filtering. grepl() from dplyr package returns True when a pattern (in this case, ‘Bassa’) is found in the corresponding character string.\n\nnga_wp %>% filter(grepl(\"Bassa\",shapeName))\n\nBased on the longitudes and latitudes,\n\nBassa (ID 94) can be renamed to Bassa (Kogi) and\nBassa (ID 95) can be renamed to Bassa (Pleateau).\n\n\nnga_wp$shapeName[nga_wp$ID==94] <- 'Bassa (Kogi)'\nnga_wp$shapeName[nga_wp$ID==95] <- 'Bassa (Pleateau)'\n\nLikewise, we repeated for the other shape names.\n\nnga_wp %>% filter(grepl(\"Ifelodun|Irepodun|Nasarawa\",shapeName))\n\nBased on the longitudes and latitudes:\n\nIfelodun (ID 304) can be renamed to Ifelodun (Kwara)\nIfelodun (ID 305) can be renamed to Ifelodun (Osun)\nIrepodun (ID 355) can be renamed to Irepodun (Kwara)\nIrepodun (ID 356) can be renamed to Irepodun (Osun)\nNasarawa (ID 519) can be renamed to Nassarawa\n\n\nnga_wp$shapeName[nga_wp$ID==304] <- 'Ifelodun (Kwara)'\nnga_wp$shapeName[nga_wp$ID==305] <- 'Ifelodun (Osun)'\nnga_wp$shapeName[nga_wp$ID==355] <- 'Irepodun (Kwara)'\nnga_wp$shapeName[nga_wp$ID==356] <- 'Irepodun (Osun)'\nnga_wp$shapeName[nga_wp$ID==519] <- 'Nassarawa'\n\nLastly, we repeat for the reamining shapeNames.\n\nnga_wp %>% filter(grepl(\"Obi|Surulere\",shapeName))\n\nBased on the longitudes and latitudes:\n\nObi (ID 546) can be renamed to Obi (Benue)\nObi (ID 547) can be renamed to Obi (Nasarawa)\nSurulere (ID 693) can be renamed to Surulere (Lagos)\nSurulere (ID 694) can be renamed to Surulere (Oyo)\n\n\nnga_wp$shapeName[nga_wp$ID==546] <- 'Obi (Benue)'\nnga_wp$shapeName[nga_wp$ID==547] <- 'Obi (Nasarawa)'\nnga_wp$shapeName[nga_wp$ID==693] <- 'Surulere (Lagos)'\nnga_wp$shapeName[nga_wp$ID==694] <- 'Surulere (Oyo)'\n\nWe then remove the columns we have just created to assist us in renaming the LGAs using the following code chunk.\n\nnga_wp <- nga_wp[-c(11:13)]\n\n\n\n4.7 Transforming the projection from wgs84 to EPSG: 26391\nIn this section, we will transform the geographic coordinate system to the projected coordinate system. This is because in the subsequent section, we will be performing adaptive distance weighting and geographic coordinate system is not appropriate for such steps.\nIn the following code chunk, we use st_transform() of sf package to perform the projection transformation.\n\nnga_wp <- st_transform(nga_wp,\n                       crs = 26391)\n\n\n\n4.8 Saving the Analytical Data Table\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")\n\n\n\n4.9 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nnga_wp <- read_rds(\"geodata/nga_wp.rds\")\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\nAs we performed a division in the previous step, we will want to check if there is any NA values in the columns for pct_functional and pct_nonfunctional.\n\nif (any(is.na(nga_wp$pct_functional))){print(\"NA values in pct_functional\")}\n\n[1] \"NA values in pct_functional\"\n\nif (any(is.na(nga_wp$pct_nonfunctional))){print(\"NA values in pct_nonfunctional\")}\n\n[1] \"NA values in pct_nonfunctional\"\n\n\nFrom the printout, we are able to tell that there are NA values in both pct_functional and pct_nonfunctional columns.\nThis is likely due to 0 total water points in these LGAs. If we impute 0 into the pct_nonfunctional column for these LGAs with 0 water points, we may incorrectly regard these LGAs to have very low proportion of non-functional water points and lead to an incorrect analysis when performing spatial distribution analysis. As such, we will exclude LGAs with 0 water points from our analysis.\nIn the following code chunk, we retrieve only rows with non-zero total number of water points by using subset().\n\nnga_wp_filter <- subset(nga_wp, total_wp != 0)\n\nWe will run the following code chunk again to verify if there are any NA values remaining in the pct_functional and pct_nonfunctional columns.\n\nif (any(is.na(nga_wp_filter$pct_functional))){print(\"NA values in pct_functional\")}\nif (any(is.na(nga_wp_filter$pct_nonfunctional))){print(\"NA values in pct_nonfunctional\")}\n\nSince no printout is generated, there are no more NA values and all LGAs with 0 water points have been excluded.\nIn the following code chunk, we want to calculate the number of LGAs with no water points. This is done by using nrow() to calculate the total number of LGAs in nga_wp and in nga_wp_filter.\n\nnrow(nga_wp) - nrow(nga_wp_filter)\n\n[1] 13\n\n\nFrom the printout, we can see that there are 13 LGAs will 0 water points."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#visualising-the-spatial-distribution-of-waterpoints-and-further-data-wrangling",
    "href": "take_home_ex/ex1/take-home-ex1.html#visualising-the-spatial-distribution-of-waterpoints-and-further-data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "5 Visualising the Spatial Distribution of Waterpoints and Further Data Wrangling",
    "text": "5 Visualising the Spatial Distribution of Waterpoints and Further Data Wrangling\nWe will visualise the spatial distribution of function and non-functional water points using a choropleth. This is performed using the code chunk below.\nFor better visualisation, we have also included the LGAs with 0 water points to understand their distribution in Nigeria. These LGAs with 0 water points are shaded in light grey.\n\ntotal <- qtm(nga_wp, \n             \"total_wp\", \n             title = \"Total number of water points\") +\n    tm_shape(nga_wp %>% filter(total_wp == 0)) +\n    tm_fill(col = \"lightgrey\") +\n    tm_borders(alpha = 0.5)\n\nwp_functional <- qtm(nga_wp, \n                     \"wp_functional\",\n                     title = \"Number of functional water points\") +\n    tm_shape(nga_wp %>% filter(total_wp == 0)) +\n    tm_fill(col = \"lightgrey\") +\n    tm_borders(alpha = 0.5)\n\nwp_nonfunctional <- qtm(nga_wp, \n                        \"wp_nonfunctional\",\n                        title = \"Number of non-functional water points\") +\n    tm_shape(nga_wp %>% filter(total_wp == 0)) +\n    tm_fill(col = \"lightgrey\") +\n    tm_borders(alpha = 0.5)\n\nunknown <- qtm(nga_wp, \n               \"wp_unknown\",\n               title = \"Number of unknown water points\") +\n    tm_shape(nga_wp %>% filter(total_wp == 0)) +\n    tm_fill(col = \"lightgrey\") +\n    tm_borders(alpha = 0.5) +\n    tmap_mode(\"plot\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)\n\n\n\n\nNext, we visualise the spatial distribution of the proportion of functional water points and proportion of non-functional water points on the map using the following code chunk.\n\nnfunc <- qtm(nga_wp, \n            \"pct_nonfunctional\", \n            title = \"Proportion of non-functional water points\") +\n            tm_shape(nga_wp %>% filter(total_wp == 0)) +\n            tm_fill(col = \"lightgrey\") +\n            tm_borders(alpha = 0.5) \nfunc <- qtm(nga_wp, \n            \"pct_functional\", \n            title = \"Proportion of functional water points\") +\n            tm_shape(nga_wp %>% filter(total_wp == 0)) +\n            tm_fill(col = \"lightgrey\") +\n            tm_borders(alpha = 0.5) \ntmap_arrange(nfunc, func, asp=1, ncol=2)"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#global-spatial-autocorrelation",
    "href": "take_home_ex/ex1/take-home-ex1.html#global-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "6 Global Spatial Autocorrelation",
    "text": "6 Global Spatial Autocorrelation\nIn this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation. Global spatial autocorrelation describes the presence of systematic spatial variation in a variable (in this case, proportion of functional water points and proportion of non-functional water points) in the study area (i.e. Nigeria) as a whole. We will evaluate two global spatial autocorrelation statistics - Moran’s I and Geary’s C.\n\n6.1 Computing Contiguity Spatial Weights\nWe will first identify the spatial weights which is used to define the neighbourhood relationship between the geographical units.\nThere are 2 main approaches to compute the spatial weights, namely, the contiguity approach and the distance approach. In the contiguity approach, neighbours are identified to be geographical areas that share a common boundary. In the Rook’s criteria, areas need to have perfect shared boundary in order to be considered as neighbours, whereas for Queen’s criteria, areas that have either perfect shared boundary or diagonal shared boundary are considered as neighbours. However, in the case for Nigeria, we can observe that the LGAs are not approximately uniform. Using the contiguity approach may result in some LGAs to have more neighbours and some LGAs to have less neighbours - resulting in underestimating and overestimating the contributions of their neighbours respectively. As such, the contiguity approach is not suitable.\nIn the distance method, there are 2 approaches - (1) fixed distance approach where areas are identified to be neighbours if the distance between their centroids are within the fixed distance and (2) adaptive weighting scheme where shorter bandwidths (or distances) are used when data is dense and longer bandwidths for data that is sparse. One advantage of the adaptive distance weight scheme is that we can control the number of neighbours by using k-nearest neighbours. To use fixed distance, the regions should be of similar size so that the centroid represent each region well. Since the LGAs in Nigeria do not have similar sizes, fixed distance approach is not suitable. Another area where fixed distance works well is when there are very large polygons at the edge of the study area and very small polygons at the center, which again, is not observed for Nigeria. As such, we will use th adaptive weighting scheme.\n\n6.1.1 Retrieving longitude and latutide of polygon centroids\nWe will first need to associate each polygon with a point in order to determine the nearest neighbours. The most typical method for this is the polygon centroids which gives us the longitude and the latitude of each LGA.\nIn the following code chunk, we use map_dbl() to transform the geometry of each LGA (represented by nga_wp_filter$geometry) by applying the function st_centroid() to each LGA. We then access the longitude using [[1]].\n\nlongitude <- map_dbl(nga_wp_filter$geometry, ~st_centroid(.x)[[1]])\n\nLikewise, we perform the following to access the latitude of the LGAs, this time using [[2]] to access the latitude.\n\nlatitude <- map_dbl(nga_wp_filter$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,] 549364.04 123694.9\n[2,] 547123.41 120376.5\n[3,] 489057.42 534262.6\n[4,] 593718.21 113824.1\n[5,] 642618.69 251222.3\n[6,]  84389.95 356433.0\n\n\n\n\n6.1.2 Computing adaptive distance weight matrix\nIn the following code chunk, we define k = 8 to find the k-nearest neighbours using knearineigh() and knn2nb() to return a list of integer vectors containing neighbour number ids.\n\nknn8 <- knn2nb(knearneigh(coords, k = 8))\nknn8\n\nNeighbour list object:\nNumber of regions: 761 \nNumber of nonzero links: 6088 \nPercentage nonzero weights: 1.051248 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nThe following code chunk allows us to display the content of the matrix using str().\n\nstr(knn8)\n\nList of 761\n $ : int [1:8] 2 315 358 535 584 611 708 712\n $ : int [1:8] 1 315 535 584 611 708 712 713\n $ : int [1:8] 11 19 252 257 438 445 457 677\n $ : int [1:8] 201 206 280 282 325 328 526 725\n $ : int [1:8] 168 215 216 331 373 540 564 588\n $ : int [1:8] 7 174 212 275 277 300 531 542\n $ : int [1:8] 6 212 275 300 321 531 542 638\n $ : int [1:8] 17 18 216 331 561 563 588 744\n $ : int [1:8] 24 214 319 358 359 515 539 619\n $ : int [1:8] 25 26 42 67 189 512 552 749\n $ : int [1:8] 133 257 409 421 438 445 677 682\n $ : int [1:8] 30 36 209 314 387 557 570 571\n $ : int [1:8] 168 357 373 533 550 564 568 576\n $ : int [1:8] 21 48 81 175 291 300 567 610\n $ : int [1:8] 29 185 186 290 322 351 354 622\n $ : int [1:8] 34 269 289 372 451 578 625 626\n $ : int [1:8] 8 18 216 370 561 563 588 744\n $ : int [1:8] 8 17 55 101 370 561 563 588\n $ : int [1:8] 3 104 123 237 257 411 445 457\n $ : int [1:8] 59 60 160 263 508 565 583 613\n $ : int [1:8] 48 291 320 435 503 610 669 680\n $ : int [1:8] 53 285 286 523 524 601 605 606\n $ : int [1:8] 83 121 429 466 514 639 660 748\n $ : int [1:8] 9 179 214 308 319 360 539 717\n $ : int [1:8] 10 26 67 189 330 431 549 749\n $ : int [1:8] 10 25 189 431 549 552 650 749\n $ : int [1:8] 28 176 293 294 295 352 363 585\n $ : int [1:8] 170 171 176 180 352 372 451 578\n $ : int [1:8] 15 38 40 184 190 323 351 354\n $ : int [1:8] 12 36 209 283 548 557 570 571\n $ : int [1:8] 50 61 452 453 503 610 669 680\n $ : int [1:8] 46 164 225 236 239 642 730 737\n $ : int [1:8] 41 102 134 135 211 540 546 744\n $ : int [1:8] 16 269 270 271 272 273 289 451\n $ : int [1:8] 49 105 244 400 424 446 668 746\n $ : int [1:8] 37 39 209 210 557 570 571 616\n $ : int [1:8] 29 38 39 40 184 190 314 557\n $ : int [1:8] 29 37 39 40 184 190 314 323\n $ : int [1:8] 36 37 38 40 184 190 314 557\n $ : int [1:8] 29 37 38 39 184 190 354 621\n $ : int [1:8] 134 135 488 546 574 600 705 721\n $ : int [1:8] 10 67 155 512 536 552 577 632\n $ : int [1:8] 15 44 190 284 297 322 354 621\n $ : int [1:8] 43 185 284 297 322 335 354 586\n $ : int [1:8] 381 409 421 430 450 509 655 729\n $ : int [1:8] 32 109 164 232 236 678 685 737\n $ : int [1:8] 64 111 259 380 399 420 472 688\n $ : int [1:8] 21 31 291 320 503 610 669 680\n $ : int [1:8] 35 96 105 244 401 408 424 668\n $ : int [1:8] 31 61 452 453 503 567 610 680\n $ : int [1:8] 52 77 163 287 519 589 590 623\n $ : int [1:8] 51 77 79 163 274 589 608 623\n $ : int [1:8] 22 78 287 288 519 523 524 605\n $ : int [1:8] 120 167 243 327 422 558 592 684\n $ : int [1:8] 76 362 370 520 521 563 588 715\n $ : int [1:8] 52 57 197 306 316 317 608 609\n $ : int [1:8] 56 316 317 551 589 590 608 609\n $ : int [1:8] 86 126 127 254 482 687 701 735\n $ : int [1:8] 60 156 550 565 576 579 583 613\n $ : int [1:8] 20 59 263 565 576 579 583 613\n $ : int [1:8] 31 50 452 453 503 610 669 680\n $ : int [1:8] 88 235 378 408 458 486 752 759\n $ : int [1:8] 47 64 73 111 129 259 380 399\n $ : int [1:8] 47 63 73 111 259 399 670 688\n $ : int [1:8] 18 101 102 282 325 332 345 561\n $ : int [1:8] 341 342 547 553 554 596 627 681\n $ : int [1:8] 10 42 155 188 189 536 577 632\n $ : int [1:8] 138 144 245 267 268 489 500 501\n $ : int [1:8] 70 292 293 295 335 337 338 597\n $ : int [1:8] 69 170 171 292 293 337 338 612\n $ : int [1:8] 16 355 553 554 555 596 625 626\n $ : int [1:8] 71 355 368 371 397 594 652 653\n $ : int [1:8] 64 107 111 247 259 670 728 741\n $ : int [1:8] 108 266 392 414 425 475 490 755\n $ : int [1:8] 249 281 419 450 461 534 634 664\n $ : int [1:8] 55 193 520 521 566 605 606 715\n $ : int [1:8] 51 53 78 79 163 213 519 623\n $ : int [1:8] 53 77 163 287 519 566 605 623\n $ : int [1:8] 51 52 77 163 213 274 623 726\n $ : int [1:8] 97 143 225 231 418 473 676 747\n $ : int [1:8] 14 31 48 50 175 346 567 610\n $ : int [1:8] 130 253 377 406 425 516 754 755\n $ : int [1:8] 23 129 146 380 429 472 660 679\n $ : int [1:8] 103 154 261 388 641 662 694 699\n $ : int [1:8] 147 149 219 224 393 402 476 644\n $ : int [1:8] 58 114 126 148 479 635 687 701\n $ : int [1:8] 255 400 454 529 661 663 668 746\n $ : int [1:8] 62 161 234 235 378 443 697 752\n $ : int [1:8] 158 265 382 432 465 469 497 513\n $ : int [1:8] 93 117 384 385 386 415 477 643\n $ : int [1:8] 72 348 368 395 581 594 652 653\n $ : int [1:8] 12 30 59 156 428 548 583 696\n $ : int [1:8] 90 384 385 386 398 415 460 643\n $ : int [1:8] 95 137 383 396 412 442 478 640\n $ : int [1:8] 94 166 383 412 442 640 649 760\n $ : int [1:8] 49 115 151 229 401 424 683 695\n $ : int [1:8] 80 143 418 473 654 676 747 756\n $ : int [1:8] 113 222 244 248 446 449 661 746\n $ : int [1:8] 128 233 318 423 426 441 464 637\n  [list output truncated]\n - attr(*, \"region.id\")= chr [1:761] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 8)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 8\n - attr(*, \"class\")= chr \"nb\"\n\n\nWe can visualise the connectivity between the neighbours using the code chunk below.\n\nplot(nga_wp$geometry, border = \"lightgrey\")\nplot(knn8, coords, pch = 10, cex = 0.5, add = TRUE, col = \"red\")\n\n\n\n\nThe borders of the LGAs with 0 water points are included in the plot above for complete view of the Nigeria map even though there are no neighbours identified for them.\n\n\n6.1.3 Binary weight assignment\nNext, we will assign weights to each neighboring polygon by using binary assignment. This is achieved in the following code chunk, where the input of nb2listw() must be an object of class nb. The following syntax of the function has the following arguments.\n\nThe argument specifies the neighbours. We will specify the neighbours we identified in knn8 here.\nWe defined style = “B” which is binary coding assignment where neighbours are given a value of 1 and non-neighbours are given a value of 0.\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list.\n\n\nwm <- nb2listw(knn8,\n                style = \"W\",\n                zero.policy = TRUE)\n\n\n\n\n6.2 Global Spatial Autocorrelation: Moran’s I for Non-Functional Water Points\nIn this section, we will demonstrate how to perform Moran’s I statistics testing by using moran.test() of spdep. Moran’s I is a test for spatial autocorrelation. It measures the overall spatial autocorrelation of the data, i.e. overall, how one object is similar or dissimilar to others surrounding it, evaluating whether the observation (in our case, values for the proportion of non-functional water points) is clustered, dispersed, or random.\nThe values of Moran’s I range from +1 meaning strong positive spatial autocorrelation (clustering) to 0 meaning no autocorrelation (a random pattern) to -1 indicating strong negative spatial autocorrelation (dispersion).\n\n6.2.1 Moran’s I test\nThe null hypothesis we are testing states that “The values for the proportion of non-functional water points are randomly distributed across LGAs, following a completely random process”. The alternative hypothesis is”The values for the proportion of non-functional water points is not randomly dispersed”.\nThe following code chunk performs Moran’s I statistic test using moran.test() of spdep.\n\nmoran.test(nga_wp_filter$pct_nonfunctional, \n           listw = wm, \n           zero.policy = TRUE, \n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_filter$pct_nonfunctional  \nweights: wm    \n\nMoran I statistic standard deviate = 26.388, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.4496039329     -0.0013157895      0.0002919996 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Moran I statistic (0.45) is positive, we reject the null hypothesis and conclude that the values for the proportion of non-functional water points is spatially clustered.\n\n\n6.2.2 Computing Monte Carlo Moran’s I\nThe Moran’s I analysis benefits from being fast. But it may be sensitive to irregularly distributed polygons. A safer approach to hypothesis testing is to run a Monte Carlo simulation using the moran.mc() function. The moran.mc function takes an extra argument n, the number of simulations.\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm = moran.mc(nga_wp_filter$pct_nonfunctional, \n                listw = wm, \n                nsim = 999, \n                zero.policy = TRUE, \n                na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  nga_wp_filter$pct_nonfunctional \nweights: wm  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.4496, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, the values for the proportion of non-functional water points is spatially clustered (since positive Moran’s I value of 0.45 is obtained).\n\n\n6.2.3 Visualising Monte Carlo Moran’s I\nTo examine the simulated Moran’s I test statistics in greater detail, we can plot the distribution of the statistical values as a histogram by using the following code chunk and also analyse the summary of the results.\n\nmean(bperm$res[1:999])\n\n[1] -0.001530328\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.0002819978\n\n\n\nsummary(bperm$res[1:999])\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.063038 -0.012756 -0.002604 -0.001530  0.009944  0.048967 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 50, \n     xlab = \"Simulated Moran's I\",\n     main = \"Monte Carlo Simulation of Moran's I for Non-Functional WP\",\n     xlim = c(-0.2,0.5))\nabline(v=0, \n       col=\"red\") \nabline(v=0.45, \n       col=\"blue\") \ntext(0.35, 130, \"Moran's I value = 0.45\", cex = 0.8, col='blue')\n\n\n\n\nThe Moran’s I value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates that the Moran’s I value determined for the proportion of non-functional water point is statistically significant. [1] This implies that there is statistically significant positive spatial autocorrelation (clustering) in the study area for the proportion of non-functional water point.\n\n\n\n6.3 Global Spatial Autocorrelation: Moran’s I for Functional Water Points\nIn this section, we will repeat the same analysis for functional water points.\n\n6.3.1 Moran’s I test\nThe null hypothesis we are testing states that “The values for the proportion of functional water points are randomly distributed across LGAs, following a completely random process”. The alternative hypothesis is”The values for the proportion of functional water points is not randomly dispersed”.\nThe following code chunk performs Moran’s I statistic test using moran.test() of spdep.\n\nmoran.test(nga_wp_filter$pct_functional, \n           listw = wm, \n           zero.policy = TRUE, \n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_filter$pct_functional  \nweights: wm    \n\nMoran I statistic standard deviate = 30.692, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.523237285      -0.001315789       0.000292099 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Moran I statistic (0.52) is positive, we reject the null hypothesis and conclude that the values for the proportion of functional water points is spatially clustered.\n\n\n6.3.2 Computing Monte Carlo Moran’s I\nIn here, we will also repeat the Monte Carlo simulation to perform permutation test for Moran’s I statistic for functional water points.\n\nset.seed(1234)\nbpermfunc = moran.mc(nga_wp_filter$pct_functional, \n                listw = wm, \n                nsim = 999, \n                zero.policy = TRUE, \n                na.action = na.omit)\nbpermfunc\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  nga_wp_filter$pct_functional \nweights: wm  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.52324, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, the values for the proportion of functional water points is spatially clustered.\n\n\n6.3.3 Visualising Monte Carlo Moran’s I\nTo examine the simulated Moran’s I test statistics in greater detail, we can plot the distribution of the statistical values as a histogram by using the following code chunk and also analyse the summary of the results.\n\nmean(bpermfunc$res[1:999])\n\n[1] -0.001873807\n\n\n\nvar(bpermfunc$res[1:999])\n\n[1] 0.0003131082\n\n\n\nsummary(bpermfunc$res[1:999])\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.061225 -0.013476 -0.002950 -0.001874  0.010085  0.064805 \n\n\n\nhist(bpermfunc$res, \n     freq = TRUE, \n     breaks = 50, \n     xlab = \"Simulated Moran's I\",\n     main = \"Monte Carlo Simulation of Moran's I for Functional WP\",\n     xlim = c(-0.2,0.6))\nabline(v=0, \n       col=\"red\") \nabline(v=0.52, \n       col=\"blue\") \ntext(0.41, 130, \"Moran's I value = 0.52\", cex = 0.8, col='blue')\n\n\n\n\nThe Moran’s I value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates that the Moran’s I statistic obtained for the proportion of functional water points is statistically significant, implying statistically significant positive spatial autocorrelation (clustering) in the study area for the proportion of functional water point.\n\n\n\n6.4 Global Spatial Autocorrelation: Geary’s C for Non-Functional WP\nGeary’s C is a measure of spatial autocorrelation or an attempt to determine if adjacent observations of the same phenomenon are correlated. How this differs from Moran’s I is that in general, Moran’s I is a measure of global spatial autocorrelation, while Geary’s C is more sensitive to local spatial autocorrelation. Geary’s C is also known as Geary’s contiguity ratio or simply Geary’s ratio.\nA Geary’s C statistic ranges from 0 to some unspecified value greater than 1. A Geary’s C statistic close to 1 indicates that there is no significant autocorrelation between observation i and its neighbors, where Geary’s C statistic < 1 indicates that the observation has neighbors which are significantly similar to it (positive spatial autocorrelation). On the other hand, Geary’s C statistic > 1, demonstrates that the observation is among neighbors which differ significantly from it (negative spatial autocorrelation). [2]\n\n6.4.1 Geary’s C test\nIn Geary’s C test, we define the null hypothesis “There is no association between the values for the proportion of non-functional water points observed at a location and values observed at nearby LGAs”. The alternative hypothesis is “Nearby sites have either similar or dissimilar values for the proportion of non-functional water points”. The code chunk below perform Geary’s C test for spatial autocorrelation by using geary.test() from spdep.\n\ngeary.test(nga_wp_filter$pct_nonfunctional, \n           listw = wm, \n           zero.policy = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  nga_wp_filter$pct_nonfunctional \nweights: wm \n\nGeary C statistic standard deviate = 25.29, p-value < 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n     0.5393883718      1.0000000000      0.0003317272 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Geary’s C statistic (0.54) is less than 1, we reject the null hypothesis and conclude that the values for the proportion of non-functional water points is spatially clustered (i.e. positive spatial autocorrelation).\n\n\n6.4.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs the permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(nga_wp_filter$pct_nonfunctional, \n               listw=wm, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  nga_wp_filter$pct_nonfunctional \nweights: wm \nnumber of simulations + 1: 1000 \n\nstatistic = 0.53939, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, the values for the proportion of non-functional water points is spatially clustered in the study area.\n\n\n6.4.3 Visualising Monte Carlo Geary’s C\nLikewise, we can examine the simulated Geary’s C test statistics in greater detail, we can plot the distribution of the statistical values as a histogram and analyse the results using the following code chunk.\n\nmean(bperm$res[1:999])\n\n[1] 1.000241\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.0003072163\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9366  0.9887  1.0007  1.0002  1.0122  1.0567 \n\n\n\nhist(bperm$res, \n     freq = TRUE, \n     breaks = 50, \n     xlab = \"Simulated Geary's C\",\n     main = \"Monte Carlo Simulation of Geary's C for Non-Functional WP\",\n     xlim = c(0.5,1.2))\nabline(v=1, \n       col=\"red\") \nabline(v=0.54, \n       col=\"blue\") \ntext(0.63, 130, \"Geary's C value = 0.54\", cex = 0.8, col='blue')\n\n\n\n\nThe Geary’s C value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates a statistically significant relationship. As such, the Geary’s C results obtained agree with Moran’s I that there is a statistically significant positive spatial autocorrelation (clustering) for the values of proportion of non-functional water points.\n\n\n\n6.5 Global Spatial Autocorrelation: Geary’s C for Functional WP\n\n6.5.1 Geary’s C test\nIn Geary’s C test, we define the null hypothesis “There is no association between the values for the proportion of functional water points observed at a location and values observed at nearby LGAs”. The alternative hypothesis is “Nearby sites have either similar or dissimilar values for the proportion of functional water points”. The code chunk below perform Geary’s C test for spatial autocorrelation by using geary.test() from spdep.\n\ngeary.test(nga_wp_filter$pct_functional, \n           listw = wm, \n           zero.policy = TRUE)\n\n\n    Geary C test under randomisation\n\ndata:  nga_wp_filter$pct_functional \nweights: wm \n\nGeary C statistic standard deviate = 29.377, p-value < 2.2e-16\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.470163795       1.000000000       0.000325287 \n\n\nSince p-value is very small, < 0.05 (statistically significant) and the Geary’s C statistic (0.47) is less than 1, we reject the null hypothesis and conclude that the values for the proportion of functional water points is spatially clustered (i.e. positive spatial autocorrelation).\n\n\n6.5.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs the permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbpermfunc=geary.mc(nga_wp_filter$pct_functional, \n               listw=wm, \n               nsim=999)\nbpermfunc\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  nga_wp_filter$pct_functional \nweights: wm \nnumber of simulations + 1: 1000 \n\nstatistic = 0.47016, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nThe Monte Carlo simulation generates a very small p-value, i.e. < 0.05 (thus statistically significant). Again, we can reject the null hypothesis and conclude that overall, the values for the proportion of functional water points is spatially clustered in the study area.\n\n\n6.5.3 Visualising Monte Carlo Geary’s C\nLikewise, we can examine the simulated Geary’s C test statistics in greater detail, we can plot the distribution of the statistical values as a histogram and analyse the results using the following code chunk.\n\nmean(bpermfunc$res[1:999])\n\n[1] 1.000408\n\n\n\nvar(bpermfunc$res[1:999])\n\n[1] 0.0003486355\n\n\n\nsummary(bpermfunc$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9413  0.9876  1.0011  1.0004  1.0129  1.0573 \n\n\n\nhist(bpermfunc$res, \n     freq = TRUE, \n     breaks = 50, \n     xlab = \"Simulated Geary's C\",\n     main = \"Monte Carlo Simulation of Geary's C for Functional WP\",\n     xlim = c(0.4,1.1))\nabline(v=1, \n       col=\"red\") \nabline(v=0.47, \n       col=\"blue\") \ntext(0.53, 130, \"Geary's C value = 0.47\", cex = 0.8, col='blue')\n\n\n\n\nThe Geary’s C value (represented by the blue vertical line) is far outside the simulated data (grey shaded region) which indicates a statistically significant Geary’s C is obtained. As such, the Geary’s C results obtained agree with Moran’s I that there is a statistically significant positive spatial autocorrelation (clustering) for the values of proportion of functional water points."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#spatial-correlogram",
    "href": "take_home_ex/ex1/take-home-ex1.html#spatial-correlogram",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "7 Spatial Correlogram",
    "text": "7 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in the data or model residuals. They serve as an alternative measure of global spatial autocorrelation that does not rely on the specification of a spatial weights matrix. Instead, a local regression is fit to the correlations computed for all pairs of observations as a function of the distance between them. [1] They are plots of an index of autocorrelation (e.g. Moran’I or Geary’s C) against distance, allowing us to observe how correlated are pairs of spatial observations when you increase the distance (lag) between them.\n\n7.1 Non-Functional Water Points\n\n7.1.1 Compute Moran’s I correlogram and plot\nIn the following code chunk, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram for the proportion of non-functional water points. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(knn8, \n                          nga_wp_filter$pct_nonfunctional, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nIn addition to plotting the output, we need to understand which autocorrelation values are statistically significant to allow for a complete analysis. Hence, we will need to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for nga_wp_filter$pct_nonfunctional \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (761)  4.4960e-01 -1.3158e-03  2.9200e-04          26.3881       < 2.2e-16\n2 (761)  3.1842e-01 -1.3158e-03  1.4777e-04          26.3026       < 2.2e-16\n3 (761)  2.3165e-01 -1.3158e-03  1.0112e-04          23.1671       < 2.2e-16\n4 (761)  1.5268e-01 -1.3158e-03  7.5000e-05          17.7818       < 2.2e-16\n5 (761)  7.5056e-02 -1.3158e-03  5.8701e-05           9.9681       < 2.2e-16\n6 (761)  3.9018e-02 -1.3158e-03  4.8719e-05           5.7786       7.532e-09\n           \n1 (761) ***\n2 (761) ***\n3 (761) ***\n4 (761) ***\n5 (761) ***\n6 (761) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the following, we calculate the mean distance of the lag orders 1 to 6. We use nblag() function which creates higher order neighbour lists, where higher order neighbours are only lags links from each other on the graph described by the input neighbours list.\n\nnb6 <- nblag(knn8, 6)\ncorrelogram_bins <- sapply(nb6, function(x) mean(unlist(nbdists(x,coords))))\ncorrelogram_bins\n\n[1]  37386.50  73925.69 112081.23 152528.12 194617.08 238153.84\n\n\nFrom the correlogram and the analysis report, we can see for lags 1 to 6 (LGAs within distances of 37.3 km to within distances of 238 km), the Moran’s I values are positive and p-value is < 0.05 (statistically significant). As such, we can reject the null hypothesis and conclude that the proportion of non-functional water points are spatially clustered for lags 1 to 6. These wide range of distances in lags 1 to 6 likely indicate that there are some LGAs that are spatially clustered with nearby neighbours (short lags, and hence short distances) as well as some LGAs that are spatially clustered with neighbours that are further by distance (higher lags, such as lag 6 - where the centroids of LGAs are up to 238 km apart).\n\n\n7.1.2 Compute Geary’s C correlogram and plot\nLikewise in the following code chunk, we sp.correlogram() of spdep package to compute a 6-lag spatial correlogram for the proportion of non-functional water points using Geary’s C.\n\nGC_corr <- sp.correlogram(knn8, \n                          nga_wp_filter$pct_nonfunctional, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for nga_wp_filter$pct_nonfunctional \nmethod: Geary's C\n          estimate expectation   variance standard deviate Pr(I) two sided    \n1 (761) 0.53938837  1.00000000 0.00033173         -25.2897       < 2.2e-16 ***\n2 (761) 0.67620379  1.00000000 0.00020058         -22.8630       < 2.2e-16 ***\n3 (761) 0.74920671  1.00000000 0.00016899         -19.2922       < 2.2e-16 ***\n4 (761) 0.82171931  1.00000000 0.00013480         -15.3552       < 2.2e-16 ***\n5 (761) 0.89720975  1.00000000 0.00011759          -9.4791       < 2.2e-16 ***\n6 (761) 0.92911305  1.00000000 0.00010771          -6.8302       8.479e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFrom the correlogram and the analysis report, we can see for lags 1 to 6, the Geary’s C values are less than 1 and p-value is < 0.05 (statistically significant). As such, we can reject the null hypothesis and conclude that the proportion of non-functional water points are spatially clustered for lags 1 to 6. This yields the same conclusion as the spatial correlogram obtained using Moran’s I.\n\n\n\n7.2 Functional Water Points\n\n7.2.1 Compute Moran’s I correlogram and plot\nLikewise, we repeat the analysis for functional water points.\n\nMI_corrfunc <- sp.correlogram(knn8, \n                          nga_wp_filter$pct_functional, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corrfunc)\n\n\n\n\nIn addition to plotting the output, we need to understand which autocorrelation values are statistically significant to allow for a complete analysis. Hence, we will need to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corrfunc)\n\nSpatial correlogram for nga_wp_filter$pct_functional \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (761)  5.2324e-01 -1.3158e-03  2.9210e-04           30.692       < 2.2e-16\n2 (761)  4.3338e-01 -1.3158e-03  1.4782e-04           35.754       < 2.2e-16\n3 (761)  3.6793e-01 -1.3158e-03  1.0116e-04           36.713       < 2.2e-16\n4 (761)  3.2705e-01 -1.3158e-03  7.5025e-05           37.910       < 2.2e-16\n5 (761)  2.8922e-01 -1.3158e-03  5.8720e-05           37.914       < 2.2e-16\n6 (761)  2.4635e-01 -1.3158e-03  4.8735e-05           35.478       < 2.2e-16\n           \n1 (761) ***\n2 (761) ***\n3 (761) ***\n4 (761) ***\n5 (761) ***\n6 (761) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the following, we calculate the mean distance of the lag orders 1 to 6. The distances obtained should be the same as calculated before.\n\nnb6 <- nblag(knn8, 6)\ncorrelogram_bins <- sapply(nb6, function(x) mean(unlist(nbdists(x,coords))))\ncorrelogram_bins\n\n[1]  37386.50  73925.69 112081.23 152528.12 194617.08 238153.84\n\n\nFrom the correlogram and the analysis report, we can see for lags 1 to 6 (LGAs within distances of 37.3 km to within distances of 238 km), the Moran’s I values are positive and p-value is < 0.05 (statistically significant). As such, we can reject the null hypothesis and conclude that the proportion of functional water points are spatially clustered for lags 1 to 6. These wide range of distances in lags 1 to 6 likely indicate that there are some LGAs that are spatially clustered with nearby neighbours (short lags, and hence short distances) as well as some LGAs that are spatially clustered with neighbours that are further by distance (higher lags, such as lag 6 - where the centroids of LGAs are up to 238 km apart).\n\n\n7.2.2 Compute Geary’s C correlogram and plot\n\nGC_corrfunc <- sp.correlogram(knn8, \n                          nga_wp_filter$pct_functional, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corrfunc)\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corrfunc)\n\nSpatial correlogram for nga_wp_filter$pct_functional \nmethod: Geary's C\n          estimate expectation   variance standard deviate Pr(I) two sided    \n1 (761) 4.7016e-01  1.0000e+00 3.2529e-04          -29.377       < 2.2e-16 ***\n2 (761) 5.7163e-01  1.0000e+00 1.9203e-04          -30.912       < 2.2e-16 ***\n3 (761) 6.3944e-01  1.0000e+00 1.5802e-04          -28.682       < 2.2e-16 ***\n4 (761) 6.7225e-01  1.0000e+00 1.2514e-04          -29.299       < 2.2e-16 ***\n5 (761) 7.1004e-01  1.0000e+00 1.0807e-04          -27.891       < 2.2e-16 ***\n6 (761) 7.3684e-01  1.0000e+00 9.8181e-05          -26.558       < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFrom the correlogram and the analysis report, we can see for lags 1 to 6, the Geary’s C values are less than 1 and p-value is < 0.05 (statistically significant). As such, we can reject the null hypothesis and conclude that the proportion of functional water points are spatially clustered for lags 1 to 6. This yields the same conclusion as that of the spatial correlogram obtained using Moran’s I."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#local-spatial-autocorrelation",
    "href": "take_home_ex/ex1/take-home-ex1.html#local-spatial-autocorrelation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "8 Local Spatial Autocorrelation",
    "text": "8 Local Spatial Autocorrelation\nThe Cluster and Outlier Analysis (Anselin Local Moran’s I) tool identifies concentrations of high values, concentrations of low values, and spatial outliers. [2] The difference with global spatial autorcorrelation is that the global statistic provides information on whether the variable tends to cluster or not on the map, but does not provide information on where they cluster. On the other hands, local spatial autocorrelation is able to identify the location of these clusters, as well as spatial outliers.\n\n8.1 Non-Functional Water Points\nIn this section, we will focus on non-functional water points.\n\n8.1.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of values for proportion of non-functional water points at the LGA level.\n\nfips <- order(nga_wp_filter$shapeName)\nlocalMI <- localmoran(nga_wp_filter$pct_nonfunctional, wm)\nhead(localMI)\n\n          Ii          E.Ii     Var.Ii      Z.Ii Pr(z != E(Ii))\n1  0.6506454 -0.0008294518 0.07810908  2.331025    0.019752051\n2  0.5944165 -0.0005017373 0.04726386  2.736483    0.006209989\n3  0.1855012 -0.0016465926 0.15493203  0.475460    0.634459103\n4  0.8661740 -0.0007449612 0.07015857  3.272941    0.001064347\n5  0.6411397 -0.0010566011 0.09947700  2.036134    0.041736858\n6 -0.1639149 -0.0001770915 0.01668751 -1.267515    0.204971134\n\n\nThe results can be interpreted as follows:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local Moran’s I statistic under the random distribution hypothesis\nVar.li: the variance of local Moran’s I statistic under the random distribution hypothesis\nZ.li: the standard deviation of local Moran’s I statistic\nPr(z != E(Ii)): the p-value of local Moran’s I statistic\n\nThe code chunk below lists the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n    localMI[fips,],\n    row.names=nga_wp_filter$shapeName[fips])\n)\n\n                            Ii        E.Ii      Var.Ii        Z.Ii\nAba North           6.5065e-01 -8.2945e-04  7.8109e-02  2.3310e+00\nAba South           5.9442e-01 -5.0174e-04  4.7264e-02  2.7365e+00\nAbaji               1.8550e-01 -1.6466e-03  1.5493e-01  4.7546e-01\nAbak                8.6617e-01 -7.4496e-04  7.0159e-02  3.2729e+00\nAbakaliki           6.4114e-01 -1.0566e-03  9.9477e-02  2.0361e+00\nAbeokuta North     -1.6391e-01 -1.7709e-04  1.6688e-02 -1.2675e+00\nAbeokuta South      1.6738e-01 -2.3915e-04  2.2534e-02  1.1166e+00\nAbi                -3.7908e-02 -5.5709e-05  5.2502e-03 -5.2240e-01\nAboh-Mbaise         4.3653e-03 -2.5136e-05  2.3689e-03  9.0206e-02\nAbua/Odual         -2.7858e-03 -3.1673e-05  2.9850e-03 -5.0410e-02\nAbuja Municipal    -3.4991e-02 -9.4799e-04  8.9261e-02 -1.1395e-01\nAdavi               8.4999e-01 -1.1149e-03  1.0496e-01  2.6270e+00\nAdo                 8.5035e-02 -2.1824e-04  2.0564e-02  5.9451e-01\nAdo-Odo/Ota        -2.0427e-01 -9.0414e-05  8.5205e-03 -2.2120e+00\nAdo Ekiti          -6.2785e-02 -1.3661e-04  1.2873e-02 -5.5216e-01\nAfijio              4.2374e-02 -8.2204e-06  7.7475e-04  1.5227e+00\nAfikpo North       -1.0247e-02 -7.2796e-05  6.8604e-03 -1.2283e-01\nAfikpo South       -1.8950e-01 -5.5866e-04  5.2623e-02 -8.2363e-01\nAgaie              -5.3845e-02 -5.1493e-04  4.8506e-02 -2.4215e-01\nAgatu               1.9097e+00 -2.7984e-03  2.6300e-01  3.7292e+00\nAgege               1.5453e+00 -2.7510e-03  2.5856e-01  3.0445e+00\nAguata              6.6844e-01 -1.3273e-03  1.2493e-01  1.8949e+00\nAgwara              1.4579e-01 -7.8758e-05  7.4222e-03  1.6932e+00\nAhiazu-Mbaise       5.9097e-02 -1.1578e-04  1.0910e-02  5.6689e-01\nAhoada East        -5.8811e-01 -7.9844e-04  7.5191e-02 -2.1419e+00\nAhoada West        -2.7147e-01 -4.1159e-03  3.8632e-01 -4.3014e-01\nAiyedade            4.1678e-02 -2.5957e-05  2.4463e-03  8.4318e-01\nAiyedire            6.7943e-02 -4.8520e-05  4.5727e-03  1.0055e+00\nAiyekire (Gbonyin)  1.7970e-02 -8.4428e-06  7.9571e-04  6.3735e-01\nAjaokuta            1.2070e+00 -1.6970e-03  1.5966e-01  3.0248e+00\nAjeromi-Ifelodun    1.3442e+00 -1.7815e-03  1.6760e-01  3.2878e+00\nAjingi              8.9605e-01 -1.0236e-03  9.6377e-02  2.8896e+00\nAkamkpa             2.9688e-02 -3.4733e-06  3.2735e-04  1.6411e+00\nAkinyele            5.1974e-02 -1.8662e-05  1.7588e-03  1.2397e+00\nAkko                4.7475e-01 -1.3504e-03  1.2710e-01  1.3354e+00\nAkoko-Edo           6.6804e-01 -8.5849e-04  8.0841e-02  2.3526e+00\nAkoko North East    2.8353e-01 -8.2161e-04  7.7371e-02  1.0223e+00\nAkoko North West    2.5056e-01 -1.6078e-03  1.5128e-01  6.4833e-01\nAkoko South East    5.7549e-01 -3.0416e-03  2.8579e-01  1.0822e+00\nAkoko South West    4.4815e-02 -9.7942e-04  9.2218e-02  1.5080e-01\nAkpabuyo            9.1209e-01 -8.0867e-04  7.6154e-02  3.3081e+00\nAkuku Toru          1.2590e-01 -1.9569e-04  1.8440e-02  9.2855e-01\nAkure North         8.6667e-02 -1.3477e-03  1.2685e-01  2.4712e-01\nAkure South        -7.7893e-01 -1.6601e-03  1.5620e-01 -1.9667e+00\nAkwanga            -1.2082e-01 -4.9332e-04  4.6471e-02 -5.5819e-01\nAlbasu              3.2864e-01 -1.2634e-04  1.1906e-02  3.0131e+00\nAleiro              1.5559e-01 -1.2308e-04  1.1599e-02  1.4459e+00\nAlimosho            7.8090e-01 -6.0492e-04  5.6978e-02  3.2740e+00\nAlkaleri           -1.1565e-01 -1.6754e-04  1.5788e-02 -9.1907e-01\nAmuwo-Odofin        8.8678e-01 -8.4326e-04  7.9408e-02  3.1499e+00\nAnambra East        4.7014e-01 -5.4946e-04  5.1757e-02  2.0689e+00\nAnambra West        5.2398e-02 -7.8844e-05  7.4303e-03  6.0878e-01\nAnaocha             7.6334e-01 -9.2916e-04  8.7490e-02  2.5839e+00\nAndoni              4.3666e-01 -2.4460e-03  2.2997e-01  9.1568e-01\nAninri              7.2099e-01 -4.1159e-03  3.8632e-01  1.1666e+00\nAniocha North       8.5013e-01 -6.7509e-03  6.3196e-01  1.0779e+00\nAniocha South       3.0196e-02 -1.0262e-04  9.6704e-03  3.0811e-01\nAnka                9.3418e-02 -4.8469e-04  4.5659e-02  4.3946e-01\nAnkpa               2.3056e+00 -4.7828e-03  4.4861e-01  3.4495e+00\nApa                 1.8683e+00 -1.9268e-03  1.8125e-01  4.3928e+00\nApapa               1.9094e+00 -4.1159e-03  3.8632e-01  3.0787e+00\nArdo-Kola           1.4008e-02 -7.0588e-05  6.6523e-03  1.7261e-01\nArewa-Dandi        -1.1832e-02 -8.9425e-07  8.4281e-05 -1.2887e+00\nArgungu             1.1059e-01 -2.8503e-04  2.6856e-02  6.7660e-01\nArochukwu          -2.4392e-01 -2.2477e-04  2.1179e-02 -1.6745e+00\nAsa                -6.4815e-02 -1.2069e-04  1.1374e-02 -6.0662e-01\nAsari-Toru          7.4318e-01 -1.4444e-03  1.3593e-01  2.0197e+00\nAskira/Uba         -1.1885e-01 -9.0087e-04  8.4828e-02 -4.0498e-01\nAtakumosa East      1.2897e-01 -6.8597e-05  6.4646e-03  1.6049e+00\nAtakumosa West      5.6030e-02 -8.7627e-05  8.2579e-03  6.1754e-01\nAtiba               1.8197e-01 -3.4939e-04  3.2918e-02  1.0049e+00\nAtigbo             -1.9332e-01 -2.4956e-04  2.3515e-02 -1.2590e+00\nAugie               1.6554e-01 -2.0920e-04  1.9712e-02  1.1805e+00\nAuyo                1.4371e+00 -2.1595e-03  2.0309e-01  3.1938e+00\nAwe                 8.9122e-02 -1.2914e-04  1.2170e-02  8.0905e-01\nAwgu                1.9860e-01 -1.0262e-04  9.6704e-03  2.0206e+00\nAwka North          4.0785e-01 -4.1159e-03  3.8632e-01  6.6280e-01\nAwka South          4.1101e-01 -6.0759e-04  5.7229e-02  1.7206e+00\nAyamelum           -3.7404e-01 -1.3644e-03  1.2842e-01 -1.0400e+00\nBabura              8.2270e-01 -1.3153e-03  1.2380e-01  2.3420e+00\nBadagry            -3.8115e-01 -4.1175e-04  3.8790e-02 -1.9332e+00\nBade                9.0763e-01 -8.8243e-04  8.3094e-02  3.1517e+00\nBagudo             -2.0188e-01 -3.8392e-05  3.6182e-03 -3.3555e+00\nBagwai              9.4657e-01 -1.1598e-03  1.0918e-01  2.8682e+00\nBakori              5.6203e-01 -2.4567e-03  2.3097e-01  1.1746e+00\nBakura              1.4699e-01 -2.3424e-03  2.2025e-01  3.1819e-01\nBalanga            -1.6819e-01 -1.7865e-04  1.6834e-02 -1.2949e+00\nBali                1.7557e-02 -1.5112e-04  1.4240e-02  1.4839e-01\nBama                2.8354e+00 -4.1159e-03  3.8632e-01  4.5685e+00\nBarikin Ladi        2.1284e-02 -8.8612e-06  8.3514e-04  7.3682e-01\nBaruten             5.4132e-02 -1.8299e-04  1.7243e-02  4.1363e-01\nBassa (Kogi)        1.4357e+00 -1.5182e-03  1.4287e-01  3.8022e+00\nBassa (Pleateau)    1.5478e-01 -4.0157e-04  3.7832e-02  7.9786e-01\nBatagarawa         -1.5457e-02 -1.7650e-05  1.6635e-03 -3.7856e-01\nBatsari             5.1543e-02 -5.0283e-05  4.7388e-03  7.4947e-01\nBauchi              5.3176e-01 -7.7875e-04  7.3339e-02  1.9664e+00\nBaure              -7.8261e-02 -1.4678e-05  1.3833e-03 -2.1038e+00\nBayo               -4.5988e-02 -1.6754e-04  1.5788e-02 -3.6467e-01\nBebeji              8.9254e-01 -2.0146e-03  1.8949e-01  2.0550e+00\nBekwara            -3.2563e-02 -1.2602e-04  1.1875e-02 -2.9766e-01\nBende              -8.0584e-03 -4.1046e-04  3.8669e-02 -3.8892e-02\nBiase               1.8620e-01 -1.8451e-04  1.7387e-02  1.4135e+00\nBichi               3.1340e-01 -1.0262e-04  9.6704e-03  3.1880e+00\nBida               -2.9400e-01 -1.7892e-03  1.6832e-01 -7.1223e-01\nBilliri             8.2260e-02 -8.8058e-04  8.2920e-02  2.8873e-01\nBindawa             3.8016e-01 -8.8902e-04  8.3714e-02  1.3170e+00\nBinji               3.1816e-01 -2.1402e-03  2.0128e-01  7.1393e-01\nBiriniwa            9.9731e-01 -1.1913e-03  1.1214e-01  2.9817e+00\nBirni Kudu          1.1359e+00 -2.0596e-03  1.9371e-01  2.5855e+00\nBirnin-Gwari        6.2227e-01 -3.4642e-03  3.2537e-01  1.0970e+00\nBirnin Kebbi       -7.2654e-01 -1.6601e-03  1.5620e-01 -1.8341e+00\nBirnin Magaji       4.6169e-01 -6.8344e-04  6.4369e-02  1.8225e+00\nBiu                 1.2174e+00 -4.1159e-03  3.8632e-01  1.9653e+00\nBodinga            -5.3689e-02 -4.0211e-04  3.7883e-02 -2.7378e-01\nBogoro              5.2533e-01 -7.4746e-04  7.0394e-02  1.9828e+00\nBoki               -3.8109e-03 -1.8968e-06  1.7877e-04 -2.8488e-01\nBokkos             -4.8301e-03 -4.1046e-04  3.8669e-02 -2.2475e-02\nBoluwaduro          6.0635e-02 -2.7678e-05  2.6085e-03  1.1877e+00\nBomadi              2.1433e+00 -4.5605e-03  4.2786e-01  3.2836e+00\nBonny               3.7862e-01 -4.1159e-03  3.8632e-01  6.1578e-01\nBorgu              -4.1731e-01 -5.5278e-04  5.2070e-02 -1.8264e+00\nBoripe              1.9844e-01 -4.0659e-04  3.8304e-02  1.0160e+00\nBosso               6.1353e-03 -6.6928e-04  6.3036e-02  2.7102e-02\nBrass               9.4150e-01 -4.0375e-03  3.7899e-01  1.5359e+00\nBuji                1.1117e+00 -1.7871e-03  1.6813e-01  2.7157e+00\nBukkuyum            5.5818e-02 -2.3662e-04  2.2296e-02  3.7541e-01\nBungudu             1.2128e-01 -8.0502e-05  7.5865e-03  1.3933e+00\nBunkure             4.4582e-01 -5.1435e-04  4.8451e-02  2.0277e+00\nBunza               7.3094e-01 -1.3765e-03  1.2955e-01  2.0346e+00\nBursari             9.6155e-01 -9.9686e-04  9.3858e-02  3.1419e+00\nBuruku             -1.2069e-02 -3.2247e-05  3.0391e-03 -2.1835e-01\nBurutu              4.0611e-01 -1.2308e-04  1.1599e-02  3.7720e+00\nBwari               9.5568e-03 -4.9053e-04  4.6209e-02  4.6740e-02\nCalabar-Municipal  -3.0857e-01 -7.1959e-05  6.7815e-03 -3.7462e+00\nCalabar South       1.7220e+00 -2.6313e-03  2.4734e-01  3.4676e+00\nChanchaga          -3.5770e-02 -1.1149e-03  1.0496e-01 -1.0697e-01\nCharanchi           2.9333e-01 -4.1954e-04  3.9524e-02  1.4776e+00\nChibok              2.9192e-01 -4.6613e-04  4.3911e-02  1.3953e+00\nChikun              1.0009e+00 -1.2416e-02  1.1557e+00  9.4257e-01\nDala               -8.7201e-02 -1.0749e-05  1.0130e-03 -2.7394e+00\nDamaturu            1.0394e+00 -2.5653e-03  2.4116e-01  2.1217e+00\nDamban             -4.6837e-01 -2.0242e-03  1.9039e-01 -1.0688e+00\nDambatta            5.6823e-02 -3.5336e-06  3.3303e-04  3.1139e+00\nDamboa              2.2940e+00 -4.1159e-03  3.8632e-01  3.6974e+00\nDan Musa            9.4580e-01 -2.0206e-03  1.9005e-01  2.1742e+00\nDandi               1.2512e+00 -3.5147e-03  3.3009e-01  2.1838e+00\nDandume             1.1662e-03 -2.2418e-06  2.1128e-04  8.0388e-02\nDange-Shuni        -1.8412e-02 -1.8092e-05  1.7051e-03 -4.4546e-01\nDanja              -2.0700e-02 -1.9269e-04  1.8157e-02 -1.5219e-01\nDarazo              1.2387e-01 -5.5866e-04  5.2623e-02  5.4243e-01\nDass                9.8202e-01 -2.6252e-03  2.4677e-01  1.9822e+00\nDaura              -2.3456e-01 -4.4983e-03  4.2205e-01 -3.5413e-01\nDawakin Kudu        1.6550e-01 -1.3760e-04  1.2967e-02  1.4546e+00\nDawakin Tofa        1.0593e+00 -2.9520e-03  2.7740e-01  2.0168e+00\nDegema              6.5563e-01 -4.1046e-04  3.8669e-02  3.3362e+00\nDekina              1.7395e+00 -3.1040e-03  2.9164e-01  3.2268e+00\nDemsa               3.7119e-01 -5.5868e-04  5.2625e-02  1.6205e+00\nDikwa               2.8354e+00 -4.1159e-03  3.8632e-01  4.5685e+00\nDoguwa             -1.2955e-01 -5.8889e-05  5.5498e-03 -1.7383e+00\nDoma                1.0277e-01 -1.3567e-05  1.2787e-03  2.8745e+00\nDonga               6.1698e-02 -2.1373e-04  2.0139e-02  4.3626e-01\nDukku               1.2034e+00 -7.3285e-03  6.8563e-01  1.4622e+00\nDunukofia           4.0041e-02 -2.9791e-06  2.8078e-04  2.3898e+00\nDutse               1.5906e+00 -3.8286e-03  3.5945e-01  2.6595e+00\nDutsi              -1.1947e-02 -2.3973e-05  2.2594e-03 -2.5084e-01\nDutsin-Ma           6.1534e-01 -6.8038e-04  6.4081e-02  2.4335e+00\nEastern Obolo       2.3470e+00 -6.9446e-03  6.4997e-01  2.9197e+00\nEbonyi              8.0068e-01 -1.3796e-03  1.2984e-01  2.2258e+00\nEdati               2.5648e-02 -2.0439e-04  1.9259e-02  1.8629e-01\nEde North          -1.4858e-01 -5.5278e-04  5.2070e-02 -6.4870e-01\nEde South          -3.1828e-02 -2.9767e-04  2.8047e-02 -1.8828e-01\nEdu                 8.4913e-02 -6.2539e-04  5.8904e-02  3.5244e-01\nEfon                1.9148e-01 -6.5469e-04  6.1663e-02  7.7373e-01\nEgbado North       -5.8311e-02 -9.9306e-06  9.3593e-04 -1.9057e+00\nEgbado South        3.5893e-01 -2.8283e-03  2.6581e-01  7.0167e-01\nEgbeda              1.6719e-02 -6.8172e-06  6.4250e-04  6.5985e-01\nEgbedore            5.7921e-02 -1.0090e-04  9.5089e-03  5.9501e-01\nEgor                5.7683e-01 -7.2968e-04  6.8720e-02  2.2032e+00\nEhime-Mbano         2.4006e-01 -4.7385e-04  4.4638e-02  1.1385e+00\nEjigbo              8.3081e-02 -2.5937e-04  2.4439e-02  5.3311e-01\nEkeremor            2.3024e+00 -8.1261e-03  7.5964e-01  2.6509e+00\nEket                6.5674e-01 -2.5248e-04  2.3790e-02  4.2595e+00\nEkiti               4.0731e-01 -1.6827e-03  1.5832e-01  1.0279e+00\nEkiti East         -7.0638e-01 -3.1755e-03  2.9834e-01 -1.2874e+00\nEkiti South West    1.9775e-01 -4.1553e-04  3.9146e-02  1.0016e+00\nEkiti West         -3.4190e-03 -6.8982e-06  6.5014e-04 -1.3382e-01\nEkwusigo            1.4605e+00 -2.4526e-03  2.3058e-01  3.0466e+00\nEleme               5.8003e-01 -4.1159e-03  3.8632e-01  9.3982e-01\nEmohua              8.5911e-02 -3.1673e-05  2.9850e-03  1.5730e+00\nEmure              -1.7180e-01 -2.4126e-04  2.2733e-02 -1.1379e+00\nEnugu East          5.0525e-01 -1.1303e-03  1.0640e-01  1.5524e+00\nEnugu North         1.1400e+00 -3.2307e-03  3.0351e-01  2.0752e+00\nEnugu South         1.1817e+00 -3.0156e-03  2.8336e-01  2.2255e+00\nEpe                -1.1246e-01 -6.3104e-05  5.9470e-03 -1.4575e+00\nEsan Central        1.4290e+00 -2.0779e-03  1.9543e-01  3.2372e+00\nEsan North East     1.5081e+00 -1.5310e-03  1.4408e-01  3.9771e+00\nEsan South East     1.7508e+00 -3.7529e-03  3.5238e-01  2.9557e+00\nEsan West           8.7205e-01 -8.2945e-04  7.8109e-02  3.1232e+00\nEse-Odo             1.3962e+00 -2.3188e-03  2.1804e-01  2.9950e+00\nEsit - Eket         2.6946e+00 -4.5605e-03  4.2786e-01  4.1265e+00\nEssien Udim         2.2915e+00 -2.9062e-03  2.7310e-01  4.3905e+00\nEtche              -9.4956e-03 -3.6158e-04  3.4066e-02 -4.9488e-02\nEthiope East        1.2421e+00 -2.2638e-03  2.1287e-01  2.6971e+00\nEthiope West        1.5545e+00 -3.0516e-03  2.8673e-01  2.9087e+00\nEti-Osa             1.8990e+00 -4.1159e-03  3.8632e-01  3.0620e+00\nEtim Ekpo           2.2806e+00 -2.4460e-03  2.2997e-01  4.7609e+00\nEtinan              2.5006e+00 -5.0829e-03  4.7661e-01  3.6295e+00\nEtsako Central      1.2357e+00 -1.7578e-03  1.6538e-01  3.0429e+00\nEtsako East         7.3273e-01 -1.0238e-03  9.6393e-02  2.3633e+00\nEtsako West        -1.6303e-01 -3.1673e-05  2.9850e-03 -2.9834e+00\nEtung              -9.4515e-02 -6.3666e-04  5.9966e-02 -3.8337e-01\nEwekoro             3.6810e-01 -1.0532e-03  9.9157e-02  1.1723e+00\nEzeagu              5.2042e-01 -8.8373e-04  8.3215e-02  1.8071e+00\nEzinihitte         -1.8415e-02 -2.1001e-05  1.9793e-03 -4.1345e-01\nEzza North          6.9991e-01 -8.6582e-04  8.1531e-02  2.4542e+00\nEzza South          3.8128e-01 -9.3665e-04  8.8194e-02  1.2870e+00\nFagge               1.0849e+00 -2.8098e-03  2.6407e-01  2.1167e+00\nFakai              -6.3904e-01 -1.0389e-03  9.7809e-02 -2.0400e+00\nFaskari             1.0287e-01 -5.7358e-04  5.4028e-02  4.4503e-01\nFika               -1.9854e-01 -7.3933e-04  6.9629e-02 -7.4960e-01\nFufore              7.9327e-01 -4.1159e-03  3.8632e-01  1.2829e+00\nFunakaye            7.5906e-01 -1.4762e-03  1.3893e-01  2.0404e+00\nFune                2.5014e-01 -2.9476e-04  2.7772e-02  1.5027e+00\nFuntua             -5.7382e-02 -4.6285e-04  4.3602e-02 -2.7258e-01\nGabasawa            1.3360e+00 -3.5480e-03  3.3321e-01  2.3206e+00\nGada               -2.3219e-02 -2.7552e-06  2.5967e-04 -1.4407e+00\nGagarawa            1.3981e+00 -2.6148e-03  2.4579e-01  2.8254e+00\nGamawa              1.1133e-01 -3.4717e-05  3.2719e-03  1.9469e+00\nGanjuwa             4.7896e-01 -1.6250e-03  1.5290e-01  1.2290e+00\nGanye               4.4700e-03 -2.0947e-06  1.9742e-04  3.1828e-01\nGarki               8.7769e-01 -8.3387e-04  7.8524e-02  3.1351e+00\nGarko               8.1498e-01 -1.8024e-03  1.6956e-01  1.9836e+00\nGarum Mallam        4.3323e-01 -3.1813e-04  2.9973e-02  2.5042e+00\nGashaka             5.5558e-03 -2.5136e-05  2.3689e-03  1.1467e-01\nGassol             -8.7348e-04 -2.2586e-05  2.1287e-03 -1.8443e-02\nGaya                1.2953e+00 -3.7749e-03  3.5443e-01  2.1820e+00\nGbako               1.4521e-02 -1.0183e-04  9.5961e-03  1.4927e-01\nGboko               2.0696e-03 -1.0187e-06  9.6008e-05  2.1132e-01\nGezawa              1.9572e-01 -5.0063e-05  4.7181e-03  2.8501e+00\nGiade               1.6440e-01 -1.7100e-04  1.6114e-02  1.2965e+00\nGirei               7.4354e-01 -1.6601e-03  1.5620e-01  1.8855e+00\nGiwa                5.5998e-01 -8.8572e-04  8.3403e-02  1.9421e+00\nGokana             -3.8880e-01 -5.5866e-04  5.2623e-02 -1.6924e+00\nGombe               7.5605e-01 -1.1336e-03  1.0672e-01  2.3178e+00\nGombi               2.5577e-02 -2.9791e-06  2.8078e-04  1.5266e+00\nGoronyo             6.5714e-02 -2.3736e-03  2.2317e-01  1.4413e-01\nGudu                4.2219e-01 -1.3546e-03  1.2749e-01  1.1862e+00\nGulani              7.5631e-02 -5.5866e-04  5.2623e-02  3.3213e-01\nGuma                2.5404e-01 -7.5009e-04  7.0641e-02  9.5865e-01\nGumel              -7.4442e-02 -5.3752e-06  5.0660e-04 -3.3072e+00\nGummi              -4.9577e-02 -8.3212e-05  7.8419e-03 -5.5891e-01\nGurara             -1.0787e-01 -2.2221e-04  2.0938e-02 -7.4395e-01\nGuri                1.2613e+00 -2.9626e-03  2.7839e-01  2.3961e+00\nGusau               2.0180e-02 -1.4431e-05  1.3601e-03  5.4759e-01\nGuyuk              -4.9073e-01 -5.5866e-04  5.2623e-02 -2.1368e+00\nGwadabawa           1.1418e-01 -2.0721e-04  1.9525e-02  8.1865e-01\nGwagwalada          5.4028e-02 -1.3764e-04  1.2971e-02  4.7560e-01\nGwale               7.3553e-01 -9.9779e-04  9.3945e-02  2.4030e+00\nGwandu              1.6061e-01 -3.3346e-04  3.1418e-02  9.0801e-01\nGwaram              9.5914e-01 -1.9269e-03  1.8125e-01  2.2574e+00\nGwarzo              9.4389e-01 -1.8803e-03  1.7688e-01  2.2488e+00\nGwer East           4.5640e-01 -1.9837e-03  1.8659e-01  1.0612e+00\nGwer West           1.7353e+00 -7.4553e-03  6.9741e-01  2.0868e+00\nGwiwa               7.5388e-02 -1.0534e-04  9.9274e-03  7.5769e-01\nGwoza               1.5502e+00 -4.1159e-03  3.8632e-01  2.5007e+00\nHadejia            -4.6271e-01 -1.6033e-04  1.5108e-02 -3.7632e+00\nHawul               8.9211e-01 -2.8283e-03  2.6581e-01  1.7359e+00\nHong               -2.0433e-01 -4.1046e-04  3.8669e-02 -1.0370e+00\nIbadan North        1.8897e-01 -1.8381e-03  1.7292e-01  4.5886e-01\nIbadan North East   1.9699e-02 -3.7678e-06  3.5510e-04  1.0456e+00\nIbadan North West   1.9303e-01 -1.8771e-04  1.7688e-02  1.4528e+00\nIbadan South East   2.4488e-01 -1.2174e-03  1.1460e-01  7.2697e-01\nIbadan South West   3.0518e-01 -5.3507e-04  5.0402e-02  1.3617e+00\nIbaji               1.4122e+00 -5.6668e-03  5.3106e-01  1.9456e+00\nIbarapa Central     4.7796e-02 -2.8599e-05  2.6953e-03  9.2118e-01\nIbarapa East        3.9693e-02 -1.5260e-05  1.4382e-03  1.0470e+00\nIbarapa North       6.9513e-02 -3.1673e-05  2.9850e-03  1.2729e+00\nIbeju/Lekki         4.0714e-02 -2.2541e-05  2.1244e-03  8.8383e-01\nIbeno               1.6050e+00 -1.6970e-03  1.5966e-01  4.0209e+00\nIbesikpo Asutan     1.1448e+00 -9.0836e-04  8.5533e-02  3.9175e+00\nIbi                -2.5361e-03 -1.6296e-04  1.5356e-02 -1.9151e-02\nIbiono Ibom         1.6282e+00 -1.8123e-03  1.7050e-01  3.9475e+00\nIdah                1.3830e+00 -2.1119e-03  1.9863e-01  3.1080e+00\nIdanre              7.7736e-01 -8.2374e-04  7.7572e-02  2.7940e+00\nIdeato North        3.9566e-01 -1.5266e-03  1.4366e-01  1.0479e+00\nIdeato South        4.2575e-02 -3.3677e-04  3.1729e-02  2.4091e-01\nIdemili North       9.8711e-01 -3.2477e-03  3.0510e-01  1.7930e+00\nIdemili South       1.4317e+00 -2.6640e-03  2.5041e-01  2.8665e+00\nIdo                 1.7847e-01 -2.1667e-04  2.0416e-02  1.2506e+00\nIdo-Osi            -4.3724e-01 -2.8283e-03  2.6581e-01 -8.4259e-01\nIfako-Ijaye         3.1405e-01 -8.9600e-05  8.4439e-03  3.4187e+00\nIfe Central         1.2241e-01 -1.6596e-03  1.5615e-01  3.1396e-01\nIfe East            2.2484e-01 -7.6434e-04  7.1983e-02  8.4089e-01\nIfe North           1.2514e-01 -1.6236e-04  1.5300e-02  1.0130e+00\nIfe South           1.8334e-01 -6.1673e-05  5.8122e-03  2.4056e+00\nIfedayo             4.8169e-02 -8.1073e-05  7.6403e-03  5.5200e-01\nIfedore             6.4596e-01 -1.6970e-03  1.5966e-01  1.6208e+00\nIfelodun (Kwara)    2.8030e-01 -2.9113e-04  2.7431e-02  1.6942e+00\nIfelodun (Osun)     3.2526e-01 -1.7432e-03  1.6401e-01  8.0745e-01\nIfo                 1.1250e+00 -1.8491e-03  1.7395e-01  2.7019e+00\nIgabi               1.2309e+00 -4.2621e-03  3.9998e-01  1.9531e+00\nIgalamela-Odolu     1.3088e-01 -1.4644e-03  1.3782e-01  3.5648e-01\nIgbo-Etiti          5.9903e-01 -2.6469e-04  2.4940e-02  3.7949e+00\nIgbo-Eze North     -1.1173e-02 -2.6640e-03  2.5041e-01 -1.7005e-02\nIgbo-Eze South      5.2542e-01 -2.3681e-03  2.2266e-01  1.1185e+00\nIgueben             1.9666e+00 -5.8234e-03  5.4564e-01  2.6702e+00\nIhiala              5.0069e-01 -6.3938e-04  6.0222e-02  2.0429e+00\nIhitte/Uboma        2.0295e-02 -3.5189e-04  3.3153e-02  1.1340e-01\nIjebu East         -2.3276e-01 -2.7908e-03  2.6229e-01 -4.4904e-01\nIjebu North        -5.7304e-02 -8.4815e-04  7.9868e-02 -1.9977e-01\nIjebu North East   -1.2757e-01 -2.5066e-04  2.3618e-02 -8.2843e-01\nIjebu Ode           5.1058e-02 -2.4708e-04  2.3281e-02  3.3625e-01\nIjero               1.0755e-02 -3.7536e-04  3.5364e-02  5.9189e-02\nIjumu               5.8605e-01 -6.2877e-04  5.9222e-02  2.4108e+00\nIka                 3.0076e+00 -6.8494e-03  6.4112e-01  3.7648e+00\nIka North East     -2.0990e+00 -4.1159e-03  3.8632e-01 -3.3704e+00\nIka South           1.5253e+00 -4.1739e-03  3.9173e-01  2.4437e+00\nIkara               7.3713e-01 -1.7950e-03  1.6887e-01  1.7981e+00\nIkeduru             2.0895e-02 -3.1673e-05  2.9850e-03  3.8302e-01\nIkeja               1.6262e+00 -3.1130e-03  2.9248e-01  3.0126e+00\nIkenne             -2.4983e-02 -7.3933e-04  6.9629e-02 -9.1877e-02\nIkere              -3.2143e-02 -1.1284e-03  1.0623e-01 -9.5157e-02\nIkole              -7.4249e-04 -1.4676e-07  1.3832e-05 -1.9960e-01\nIkom               -7.8392e-02 -1.2033e-04  1.1340e-02 -7.3503e-01\nIkono               1.4365e+00 -1.5182e-03  1.4287e-01  3.8045e+00\nIkorodu             4.6657e-01 -3.2634e-04  3.0747e-02  2.6627e+00\nIkot Abasi          1.3792e+00 -1.2777e-03  1.2027e-01  3.9805e+00\nIkot Ekpene         1.9497e+00 -3.0681e-03  2.8827e-01  3.6370e+00\nIkpoba-Okha         9.0904e-01 -1.1749e-03  1.1061e-01  2.7369e+00\nIkwerre             4.9925e-01 -2.8638e-03  2.6913e-01  9.6789e-01\nIkwo                2.7189e-01 -1.4596e-03  1.3736e-01  7.3754e-01\nIkwuano             9.4455e-02 -4.1035e-05  3.8673e-03  1.5195e+00\nIla                 3.1260e-02 -8.0083e-06  7.5476e-04  1.1382e+00\nIlaje               6.6282e-01 -7.1093e-04  6.6956e-02  2.5643e+00\nIle-Oluji-Okeigbo   1.0107e+00 -2.5801e-03  2.4254e-01  2.0574e+00\nIlejemeji           2.2084e-01 -1.0238e-03  9.6393e-02  7.1460e-01\nIlesha East         7.3160e-02 -4.3335e-05  4.0841e-03  1.1455e+00\nIlesha West         1.4084e-01 -2.9931e-04  2.8201e-02  8.4046e-01\nIllela              1.4346e-01 -1.2679e-03  1.1935e-01  4.1893e-01\nIlorin East        -6.5085e-02 -7.7291e-05  7.2839e-03 -7.6170e-01\nIlorin South        1.3031e-02 -1.5819e-06  1.4909e-04  1.0674e+00\nIlorin West         4.3606e-03 -1.5819e-06  1.4909e-04  3.5725e-01\nImeko-Afon          2.0028e-01 -4.1159e-03  3.8632e-01  3.2885e-01\nIngawa              7.1814e-01 -2.0733e-03  1.9500e-01  1.6310e+00\nIni                 1.0955e+00 -1.8251e-03  1.7170e-01  2.6483e+00\nIpokia             -5.0799e-02 -3.0473e-05  2.8720e-03 -9.4733e-01\nIrele               1.4548e+00 -2.5889e-03  2.4337e-01  2.9543e+00\nIrepo               3.9668e-02 -5.7940e-05  5.4604e-03  5.3760e-01\nIrepodun (Kwara)    3.7051e-01 -1.5875e-03  1.4938e-01  9.6273e-01\nIrepodun (Osun)     3.0841e-02 -4.5603e-05  4.2978e-03  4.7113e-01\nIrepodun/Ifelodun  -1.4347e-01 -3.0767e-04  2.8988e-02 -8.4086e-01\nIrewole             4.2832e-02 -2.2308e-04  2.1020e-02  2.9696e-01\nIsa                 2.1948e-01 -1.1792e-03  1.1101e-01  6.6230e-01\nIse/Orun           -5.3541e-01 -3.4974e-03  3.2847e-01 -9.2809e-01\nIseyin              5.5720e-01 -1.9606e-03  1.8442e-01  1.3021e+00\nIshielu             9.4132e-02 -1.3756e-05  1.2965e-03  2.6147e+00\nIsi-Uzo            -8.5713e-01 -4.3584e-03  4.0898e-01 -1.3335e+00\nIsiala-Ngwa North  -5.3351e-02 -8.9844e-06  8.4676e-04 -1.8331e+00\nIsiala-Ngwa South  -3.1258e-03 -8.4815e-04  7.9868e-02 -8.0595e-03\nIsiala Mbano        3.7556e-02 -2.0721e-04  1.9525e-02  2.7025e-01\nIsin                7.5012e-03 -1.7115e-07  1.6131e-05  1.8677e+00\nIsiukwuato         -3.5922e-02 -2.3173e-04  2.1835e-02 -2.4154e-01\nIsokan              5.0372e-02 -3.3549e-05  3.1618e-03  8.9641e-01\nIsoko North         1.3891e+00 -1.9268e-03  1.8125e-01  3.2675e+00\nIsoko South         7.8612e-01 -1.1978e-03  1.1276e-01  2.3446e+00\nIsu                -1.2066e-01 -2.4526e-03  2.3058e-01 -2.4616e-01\nItas/Gadau          3.4536e-01 -2.2624e-04  2.1318e-02  2.3669e+00\nItesiwaju           4.5893e-01 -2.1944e-03  2.0636e-01  1.0151e+00\nItu                 2.0291e+00 -4.5605e-03  4.2786e-01  3.1090e+00\nIvo                -1.4295e-02 -1.3567e-05  1.2787e-03 -3.9939e-01\nIwajowa             1.4155e-01 -8.2277e-05  7.7538e-03  1.6084e+00\nIwo                 1.0199e-01 -3.2634e-04  3.0747e-02  5.8349e-01\nIzzi                1.0390e+00 -2.3226e-03  2.1839e-01  2.2283e+00\nJaba                1.7682e-01 -1.8123e-03  1.7050e-01  4.3262e-01\nJada               -1.7787e-01 -1.2308e-04  1.1599e-02 -1.6504e+00\nJahun               1.6144e+00 -1.5640e-03  1.4717e-01  4.2123e+00\nJakusko             9.9621e-01 -1.9438e-03  1.8285e-01  2.3343e+00\nJalingo            -1.4320e-01 -9.2934e-05  8.7580e-03 -1.5292e+00\nJama'are            2.9083e-01 -1.5865e-04  1.4950e-02  2.3799e+00\nJega                3.7220e-01 -4.0308e-04  3.7974e-02  1.9121e+00\nJema'a              4.8967e-03 -8.6019e-04  8.1001e-02  2.0228e-02\nJere                9.5403e-01 -4.5860e-04  4.3202e-02  4.5922e+00\nJibia               3.5493e-02 -2.5118e-05  2.3673e-03  7.3000e-01\nJos East            2.3076e-01 -3.1889e-04  3.0045e-02  1.3331e+00\nJos North           1.7591e-01 -7.6664e-04  7.2199e-02  6.5754e-01\nJos South          -1.3964e-01 -2.4508e-04  2.3092e-02 -9.1733e-01\nKabba/Bunu          7.5356e-01 -7.4223e-04  6.9901e-02  2.8530e+00\nKabo                8.0031e-01 -9.7555e-04  9.1853e-02  2.6439e+00\nKachia              5.6057e-02 -1.7813e-05  1.6788e-03  1.3686e+00\nKaduna North        7.0513e-01 -1.7472e-03  1.6438e-01  1.7435e+00\nKaduna South       -1.4667e+00 -3.1193e-03  2.9307e-01 -2.7035e+00\nKafin Hausa         1.8061e+00 -4.0249e-03  3.7781e-01  2.9449e+00\nKafur               3.3251e-01 -8.1042e-04  7.6319e-02  1.2065e+00\nKagarko             1.6236e-01 -3.2866e-03  3.0874e-01  2.9812e-01\nKaiama             -2.9834e-02 -3.2910e-05  3.1016e-03 -5.3511e-01\nKaita              -1.9038e-02 -3.3899e-05  3.1948e-03 -3.3621e-01\nKajola              1.2278e-01 -9.8057e-05  9.2407e-03  1.2782e+00\nKajuru              7.7392e-01 -3.3659e-03  3.1616e-01  1.3824e+00\nKalgo               7.6474e-01 -2.9781e-03  2.7984e-01  1.4512e+00\nKaltungo           -1.7849e-01 -2.8050e-04  2.6429e-02 -1.0962e+00\nKanam               3.0131e-01 -3.5142e-04  3.3109e-02  1.6579e+00\nKankara             7.7038e-01 -9.5942e-04  9.0336e-02  2.5663e+00\nKanke               5.3193e-01 -8.5697e-04  8.0699e-02  1.8755e+00\nKankia              4.5493e-01 -3.4897e-04  3.2878e-02  2.5108e+00\nKano Municipal      5.7710e-01 -5.7811e-04  5.4454e-02  2.4755e+00\nKarasuwa            8.3879e-01 -7.8434e-04  7.3864e-02  3.0892e+00\nKaraye             -2.2981e-01 -1.0875e-04  1.0248e-02 -2.2690e+00\nKarim-Lamido        1.1958e-02 -1.9269e-04  1.8157e-02  9.0171e-02\nKaru               -2.6251e-04 -1.4546e-09  1.3709e-07 -7.0897e-01\nKatagum             9.0627e-03 -5.7940e-05  5.4604e-03  1.2343e-01\nKatcha             -2.5773e-03 -9.5060e-06  8.9591e-04 -8.5787e-02\nKatsina             4.7831e-03 -1.8470e-05  1.7407e-03  1.1508e-01\nKatsina-Ala        -5.4987e-02 -2.7641e-05  2.6050e-03 -1.0768e+00\nKaugama             1.4503e+00 -2.9460e-03  2.7684e-01  2.7620e+00\nKaura               1.5419e-02 -8.6776e-05  8.1778e-03  1.7147e-01\nKaura Namoda        3.1550e-01 -8.4326e-04  7.9408e-02  1.1226e+00\nKauru              -5.2217e-02 -8.7409e-05  8.2374e-03 -5.7437e-01\nKazaure             1.8532e-01 -2.1444e-04  2.0206e-02  1.3052e+00\nKeana               2.5512e-01 -7.3205e-04  6.8944e-02  9.7441e-01\nKebbe               1.8228e-01 -2.3733e-04  2.2363e-02  1.2205e+00\nKeffi              -2.7183e-01 -6.4468e-04  6.0720e-02 -1.1005e+00\nKhana               1.4005e-01 -9.9591e-05  9.3853e-03  1.4466e+00\nKibiya              4.1029e-01 -9.2160e-04  8.6779e-02  1.3959e+00\nKirfi               1.7751e-01 -1.5715e-04  1.4809e-02  1.4600e+00\nKiri Kasamma        9.0956e-01 -8.3918e-04  7.9024e-02  3.2385e+00\nKiru                5.2408e-01 -6.1045e-04  5.7499e-02  2.1881e+00\nKiyawa              1.0698e+00 -1.2174e-03  1.1460e-01  3.1638e+00\nKogi                3.9207e-01 -1.6970e-03  1.5966e-01  9.8546e-01\nKoko/Besse          8.6204e-01 -2.8404e-03  2.6694e-01  1.6740e+00\nKokona              3.7254e-03 -8.8776e-05  8.3662e-03  4.1700e-02\nKolokuma/Opokuma   -9.7679e-01 -3.0665e-03  2.8813e-01 -1.8140e+00\nKonduga             2.1301e+00 -4.1159e-03  3.8632e-01  3.4337e+00\nKonshisha           1.3345e-02 -4.7701e-04  4.4936e-02  6.5204e-02\nKontagora           4.9917e-02 -9.2593e-06  8.7266e-04  1.6901e+00\nKosofe              1.5196e+00 -2.1152e-03  1.9894e-01  3.4118e+00\nKubau               7.3394e-01 -2.5256e-03  2.3743e-01  1.5114e+00\nKudan              -1.6081e-02 -1.2276e-03  1.1556e-01 -4.3695e-02\nKuje                4.2818e-02 -7.1319e-04  6.7169e-02  1.6796e-01\nKumbotso            5.9076e-01 -1.1003e-03  1.0358e-01  1.8390e+00\nKunchi              1.1101e+00 -2.0206e-03  1.9005e-01  2.5511e+00\nKura                1.4284e-01 -4.2529e-05  4.0081e-03  2.2569e+00\nKurfi               5.5109e-02 -3.8392e-05  3.6182e-03  9.1682e-01\nKurmi               7.1477e-02 -8.6540e-05  8.1555e-03  7.9245e-01\nKusada              1.1302e+00 -3.4800e-03  3.2684e-01  1.9830e+00\nKwali               7.5075e-02 -6.1673e-05  5.8122e-03  9.8556e-01\nKwami               1.1943e+00 -2.5562e-03  2.4030e-01  2.4416e+00\nKwande              1.8458e-01 -2.3876e-03  2.2449e-01  3.9460e-01\nKware              -8.9844e-03 -2.3121e-06  2.1791e-04 -6.0847e-01\nKwaya Kusar         5.7866e-02 -3.1673e-05  2.9850e-03  1.0597e+00\nLafia              -2.3680e-02 -1.0577e-05  9.9683e-04 -7.4969e-01\nLagelu             -5.3696e-02 -5.5985e-05  5.2762e-03 -7.3846e-01\nLagos Island        4.1510e-01 -1.4293e-04  1.3469e-02  3.5780e+00\nLagos Mainland      1.7948e+00 -3.1130e-03  2.9248e-01  3.3244e+00\nLamurde             1.6335e-01 -4.1159e-03  3.8632e-01  2.6944e-01\nLangtang North      2.4354e-01 -4.2481e-04  4.0021e-02  1.2195e+00\nLangtang South     -9.3727e-02 -1.9862e-04  1.8716e-02 -6.8365e-01\nLapai              -3.0254e-01 -5.7503e-04  5.4164e-02 -1.2975e+00\nLau                -1.5028e-01 -1.6033e-04  1.5108e-02 -1.2213e+00\nLavun              -3.3183e-02 -1.9868e-05  1.8724e-03 -7.6639e-01\nLere               -1.1267e-01 -3.0306e-05  2.8562e-03 -2.1077e+00\nLogo                3.6353e-02 -7.5785e-05  7.1420e-03  4.3105e-01\nLokoja             -3.9833e-01 -2.2109e-04  2.0833e-02 -2.7583e+00\nMachina             8.2894e-01 -9.5711e-04  9.0119e-02  2.7645e+00\nMadobi              1.0374e+00 -1.6875e-03  1.5877e-01  2.6078e+00\nMafa                2.8354e+00 -4.1159e-03  3.8632e-01  4.5685e+00\nMagama              2.1577e-01 -1.7164e-04  1.6174e-02  1.6980e+00\nMagumeri            1.0205e+00 -6.3187e-04  5.9515e-02  4.1856e+00\nMai'adua            6.0409e-02 -1.8205e-04  1.7155e-02  4.6260e-01\nMaiduguri           2.4133e+00 -3.4663e-03  3.2555e-01  4.2358e+00\nMaigatari           6.6568e-01 -4.3165e-04  4.0665e-02  3.3032e+00\nMaiha              -1.9441e-01 -5.2175e-04  4.9148e-02 -8.7458e-01\nMaiyama             6.7041e-01 -9.3999e-04  8.8509e-02  2.2566e+00\nMakoda              1.3171e+00 -3.7018e-03  3.4760e-01  2.2402e+00\nMakurdi             1.2322e-01 -4.1724e-05  3.9322e-03  1.9657e+00\nMalam Madori        1.4966e+00 -2.8098e-03  2.6407e-01  2.9178e+00\nMalumfashi          6.7939e-01 -1.0931e-03  1.0291e-01  2.1212e+00\nMangu               9.3270e-02 -8.3666e-05  7.8847e-03  1.0513e+00\nMani               -2.7787e-02 -2.3685e-05  2.2322e-03 -5.8763e-01\nMaradun             2.2418e-01 -1.2354e-04  1.1642e-02  2.0789e+00\nMariga              2.7360e-01 -6.3121e-04  5.9453e-02  1.1247e+00\nMarkafi             2.1149e-01 -3.5444e-03  3.3287e-01  3.7271e-01\nMaru               -5.6961e-02 -1.5970e-04  1.5049e-02 -4.6303e-01\nMashegu             3.8439e-01 -2.3736e-03  2.2317e-01  8.1870e-01\nMashi               9.0518e-02 -4.3088e-04  4.0592e-02  4.5142e-01\nMatazu              4.1188e-01 -4.1973e-04  3.9542e-02  2.0734e+00\nMayo-Belwa          2.2631e-01 -4.1046e-04  3.8669e-02  1.1530e+00\nMbaitoli            1.3917e-01 -5.1321e-04  4.8344e-02  6.3527e-01\nMbo                 2.9421e+00 -5.4468e-03  5.1055e-01  4.1251e+00\nMichika             3.1200e-04 -4.1046e-04  3.8669e-02  3.6739e-03\nMiga                2.2601e+00 -3.7714e-03  3.5411e-01  3.8043e+00\nMikang              9.0255e-02 -7.7480e-05  7.3017e-03  1.0571e+00\nMinjibir            1.4612e+00 -3.9001e-03  3.6614e-01  2.4213e+00\nMisau               5.6435e-02 -1.7485e-04  1.6476e-02  4.4102e-01\nMkpat Enin          1.9160e+00 -2.6917e-03  2.5301e-01  3.8144e+00\nMoba                1.0701e-01 -9.5534e-05  9.0030e-03  1.1288e+00\nMokwa               3.7411e-02 -2.6559e-05  2.5031e-03  7.4830e-01\nMonguno             2.5976e+00 -4.1159e-03  3.8632e-01  4.1859e+00\nMopa-Muro           8.0522e-01 -2.9443e-03  2.7667e-01  1.5365e+00\nMoro               -8.2532e-03 -1.6573e-05  1.5620e-03 -2.0841e-01\nMubi North         -7.3485e-01 -1.2416e-02  1.1557e+00 -6.7202e-01\nMubi South         -2.7019e-01 -1.2416e-02  1.1557e+00 -2.3978e-01\nMusawa              8.1506e-01 -1.4723e-03  1.3856e-01  2.1936e+00\nMushin              1.4007e+00 -1.3484e-03  1.2691e-01  3.9355e+00\nMuya                8.6641e-02 -1.8146e-04  1.7099e-02  6.6397e-01\nNafada              5.3408e-01 -8.7426e-04  8.2325e-02  1.8645e+00\nNangere             1.8992e-01 -2.7891e-04  2.6280e-02  1.1733e+00\nNasarawa            3.0522e-01 -2.4854e-04  2.3418e-02  1.9961e+00\nNasarawa-Eggon      7.9510e-02 -2.0305e-04  1.9133e-02  5.7629e-01\nNassarawa          -5.0526e-01 -4.7874e-04  4.5099e-02 -2.3770e+00\nNdokwa East         3.0036e-01 -1.0993e-03  1.0349e-01  9.3708e-01\nNdokwa West         9.0154e-01 -1.8251e-03  1.7170e-01  2.1801e+00\nNembe               4.8202e-01 -2.1247e-03  1.9982e-01  1.0831e+00\nNgala               2.8354e+00 -4.1159e-03  3.8632e-01  4.5685e+00\nNgaski              3.3484e-01 -4.5564e-04  4.2924e-02  1.6184e+00\nNgor-Okpala         1.2921e-01 -1.1003e-03  1.0358e-01  4.0488e-01\nNguru               1.4019e+00 -2.3749e-03  2.2330e-01  2.9718e+00\nNingi               6.2054e-01 -1.0056e-03  9.4678e-02  2.0200e+00\nNjaba              -1.1153e-01 -3.1624e-04  2.9796e-02 -6.4431e-01\nNjikoka            -7.0717e-02 -8.8753e-06  8.3647e-04 -2.4448e+00\nNkanu East          1.3422e+00 -3.7093e-03  3.4830e-01  2.2806e+00\nNkanu West         -4.9969e-01 -2.5144e-04  2.3692e-02 -3.2447e+00\nNkwerre            -1.6191e-01 -9.9964e-04  9.4119e-02 -5.2450e-01\nNnewi North         5.5722e-01 -3.6612e-04  3.4493e-02  3.0022e+00\nNnewi South         1.1750e+00 -2.8638e-03  2.6913e-01  2.2705e+00\nNsit Atai           2.8425e+00 -4.9160e-03  4.6104e-01  4.1935e+00\nNsit Ibom           1.1110e+00 -8.4164e-04  7.9256e-02  3.9493e+00\nNsit Ubium          1.2512e+00 -1.2679e-03  1.1935e-01  3.6256e+00\nNsukka              5.7879e-01 -1.0759e-03  1.0130e-01  1.8219e+00\nNuman               8.6041e-02 -4.1159e-03  3.8632e-01  1.4505e-01\nNwangele           -1.2619e-01 -1.8019e-03  1.6952e-01 -3.0211e-01\nObafemi-Owode       2.3504e-01 -5.8808e-04  5.5392e-02  1.0011e+00\nObanliku            2.3322e-03 -2.3249e-07  2.1912e-05  4.9827e-01\nObi (Benue)        -7.3037e-02 -1.7915e-04  1.6881e-02 -5.6076e-01\nObi (Nasarawa)      5.0340e-01 -4.0375e-03  3.7899e-01  8.2427e-01\nObi Ngwa            1.4700e+00 -2.6571e-03  2.4976e-01  2.9467e+00\nObia/Akpor          3.2478e-02 -5.5240e-06  5.2062e-04  1.4236e+00\nObokun              1.0077e-01 -7.8485e-05  7.3965e-03  1.1726e+00\nObot Akara          1.6736e+00 -4.1021e-03  3.8503e-01  2.7038e+00\nObowo               1.4030e-02 -5.5375e-06  5.2189e-04  6.1437e-01\nObubra             -1.0226e-01 -5.4099e-04  5.0960e-02 -4.5061e-01\nObudu               1.5642e-02 -1.1785e-05  1.1107e-03  4.6970e-01\nOdeda               3.9153e-02 -4.4406e-05  4.1849e-03  6.0592e-01\nOdigbo              1.4861e+00 -5.1287e-03  4.8089e-01  2.1505e+00\nOdo-Otin            6.4710e-02 -1.5987e-05  1.5067e-03  1.6675e+00\nOdogbolu           -3.8093e-02 -1.9569e-04  1.8440e-02 -2.7908e-01\nOdukpani            1.0468e+00 -9.9360e-04  9.3552e-02  3.4257e+00\nOffa                5.5253e-01 -1.2141e-03  1.1428e-01  1.6380e+00\nOfu                 8.8304e-01 -2.9835e-03  2.8035e-01  1.6734e+00\nOgba/Egbema/Ndoni   1.1286e-01 -9.1033e-04  8.5719e-02  3.8860e-01\nOgbadibo           -6.9957e-03 -1.3721e-04  1.2930e-02 -6.0315e-02\nOgbaru              1.8159e-01 -3.3677e-04  3.1729e-02  1.0213e+00\nOgbia               2.7444e-01 -3.7042e-04  3.4899e-02  1.4711e+00\nOgbomosho North    -6.5565e-03 -2.2477e-04  2.1179e-02 -4.3508e-02\nOgbomosho South    -1.5849e-01 -5.5866e-04  5.2623e-02 -6.8848e-01\nOgo Oluwa          -1.1476e-02 -7.2796e-05  6.8604e-03 -1.3768e-01\nOgoja               5.0489e-02 -3.9326e-05  3.7062e-03  8.2998e-01\nOgori/Magongo       7.7147e-01 -7.4496e-04  7.0159e-02  2.9154e+00\nOgu/Bolo            8.5112e-01 -4.1159e-03  3.8632e-01  1.3760e+00\nOgun waterside      4.8053e-02 -2.1660e-05  2.0414e-03  1.0640e+00\nOguta              -6.4686e-01 -1.7858e-03  1.6800e-01 -1.5738e+00\nOhafia              1.4453e-01 -5.5866e-04  5.2623e-02  6.3249e-01\nOhaji/Egbema        1.3935e-01 -1.9177e-04  1.8070e-02  1.0381e+00\nOhaozara            1.8837e-01 -3.5431e-04  3.3381e-02  1.0329e+00\nOhaukwu             3.4857e-01 -5.2175e-04  4.9148e-02  1.5747e+00\nOhimini             1.1378e+00 -1.4817e-03  1.3944e-01  3.0510e+00\nOji-River           6.5855e-02 -1.6709e-05  1.5748e-03  1.6600e+00\nOjo                -1.2091e-02 -1.8210e-07  1.7162e-05 -2.9185e+00\nOju                 7.3144e-01 -2.0125e-03  1.8929e-01  1.6858e+00\nOke-Ero             5.4426e-01 -1.5467e-03  1.4555e-01  1.4307e+00\nOkehi               1.5833e+00 -4.0925e-03  3.8413e-01  2.5613e+00\nOkene               5.7509e-01 -4.7874e-04  4.5099e-02  2.7103e+00\nOkigwe             -1.8957e-01 -1.4919e-03  1.4040e-01 -5.0195e-01\nOkitipupa           1.1921e+00 -3.5908e-03  3.3721e-01  2.0590e+00\nOkobo               1.8637e+00 -2.4737e-03  2.3256e-01  3.8697e+00\nOkpe                4.4205e-01 -2.8503e-04  2.6856e-02  2.6992e+00\nOkpokwu             2.1084e-01 -7.8961e-04  7.4360e-02  7.7610e-01\nOkrika              8.6025e-01 -2.4526e-03  2.3058e-01  1.7966e+00\nOla-oluwa           3.9618e-01 -2.2607e-03  2.1258e-01  8.6418e-01\nOlamabolo          -1.9991e-01 -2.5356e-03  2.3837e-01 -4.0425e-01\nOlorunda           -9.4687e-04 -1.7105e-08  1.6121e-06 -7.4573e-01\nOlorunsogo          5.4857e-02 -8.4181e-05  7.9332e-03  6.1684e-01\nOluyole             1.1095e-01 -5.6734e-04  5.3440e-02  4.8242e-01\nOmala               2.7630e+00 -7.6913e-03  7.1931e-01  3.2668e+00\nOmumma             -3.6662e-01 -4.8469e-04  4.5659e-02 -1.7135e+00\nOna-Ara            -3.4816e-01 -7.1377e-04  6.7223e-02 -1.3401e+00\nOndo East           7.8159e-01 -2.4008e-03  2.2573e-01  1.6501e+00\nOndo West           1.4120e+00 -2.6467e-03  2.4878e-01  2.8362e+00\nOnicha              3.8188e-01 -5.9873e-04  5.6395e-02  1.6106e+00\nOnitsha North       9.0238e-01 -2.5653e-03  2.4116e-01  1.8428e+00\nOnitsha South       7.3158e-01 -1.2174e-03  1.1460e-01  2.1647e+00\nOnna                1.3833e+00 -1.3088e-03  1.2319e-01  3.9448e+00\nOpobo/Nkoro         4.0385e-01 -2.4508e-04  2.3092e-02  2.6592e+00\nOredo               3.1050e-01 -1.4847e-04  1.3991e-02  2.6263e+00\nOrelope            -4.1254e-02 -3.2711e-05  3.0828e-03 -7.4241e-01\nOrhionmwon          1.1884e+00 -1.7495e-03  1.6460e-01  2.9335e+00\nOri Ire            -3.1396e-03 -1.3670e-03  1.2866e-01 -4.9418e-03\nOriade              3.2387e-02 -1.3229e-05  1.2468e-03  9.1759e-01\nOrlu                6.2811e-02 -2.5460e-04  2.3990e-02  4.0718e-01\nOrolu               1.9154e-01 -1.1477e-03  1.0805e-01  5.8621e-01\nOron                2.5270e-01 -3.6938e-05  3.4812e-03  4.2836e+00\nOrsu                2.8989e-02 -7.2980e-06  6.8781e-04  1.1056e+00\nOru East            1.8344e-01 -5.5868e-04  5.2625e-02  8.0207e-01\nOru West            1.9397e-01 -6.5602e-04  6.1788e-02  7.8297e-01\nOruk Anam           3.3007e+00 -6.6696e-03  6.2440e-01  4.1855e+00\nOrumba North        3.2045e-01 -5.8808e-04  5.5392e-02  1.3641e+00\nOrumba South        5.2120e-02 -3.1673e-05  2.9850e-03  9.5454e-01\nOse                 1.3930e+00 -3.4519e-03  3.2421e-01  2.4525e+00\nOshimili North      5.4164e-02 -1.4102e-03  1.3272e-01  1.5255e-01\nOshimili South     -8.0771e-01 -7.5367e-04  7.0978e-02 -3.0289e+00\nOshodi-Isolo        2.0782e+00 -4.1159e-03  3.8632e-01  3.3502e+00\nOsisioma Ngwa       8.5495e-02 -5.8889e-05  5.5498e-03  1.1484e+00\nOsogbo              5.8769e-03 -1.0364e-05  9.7679e-04  1.8837e-01\nOturkpo             1.0259e+00 -1.2225e-03  1.1507e-01  3.0278e+00\nOvia North East     1.3283e-01 -3.1974e-05  3.0134e-03  2.4204e+00\nOvia South West     2.3318e-01 -7.7687e-05  7.3213e-03  2.7261e+00\nOwan East           5.1085e-01 -2.7784e-04  2.6178e-02  3.1591e+00\nOwan West           1.4435e+00 -5.1154e-03  4.7965e-01  2.0917e+00\nOwerri-Municipal    5.0347e-01 -2.7908e-03  2.6229e-01  9.8852e-01\nOwerri North       -1.3866e-01 -1.7709e-04  1.6688e-02 -1.0720e+00\nOwerri West         9.9709e-02 -4.3393e-05  4.0895e-03  1.5599e+00\nOwo                 2.6594e-01 -6.2956e-04  5.9298e-02  1.0947e+00\nOye                 1.0282e-01 -6.1864e-04  5.8269e-02  4.2851e-01\nOyi                -7.4829e-02 -1.0185e-05  9.5989e-04 -2.4149e+00\nOyigbo             -3.6685e-01 -1.8921e-03  1.7799e-01 -8.6506e-01\nOyo East            4.2511e-02 -1.8470e-05  1.7407e-03  1.0194e+00\nOyo West            2.9289e-01 -9.7555e-04  9.1853e-02  9.6961e-01\nOyun                5.1294e-01 -1.0087e-03  9.4971e-02  1.6677e+00\nPaikoro             4.0396e-03 -1.5447e-04  1.4556e-02  3.4762e-02\nPankshin            2.9272e-01 -4.0157e-04  3.7832e-02  1.5070e+00\nPatani              1.6174e+00 -6.3208e-03  5.9195e-01  2.1105e+00\nPategi              1.5758e-01 -6.3890e-05  6.0211e-03  2.0316e+00\nPort-Harcourt       6.4576e-01 -1.9631e-03  1.8466e-01  1.5073e+00\nPotiskum            2.3385e-01 -2.4526e-03  2.3058e-01  4.9210e-01\nQua'an Pan         -1.2123e-02 -7.5368e-05  7.1027e-03 -1.4295e-01\nRabah               2.0393e-01 -2.5221e-03  2.3710e-01  4.2400e-01\nRafi               -9.5586e-02 -9.2513e-05  8.7184e-03 -1.0227e+00\nRano                3.6742e-01 -5.6508e-04  5.3228e-02  1.5950e+00\nRemo North         -3.8715e-02 -1.3606e-04  1.2821e-02 -3.4070e-01\nRijau               2.6158e-01 -5.8648e-04  5.5242e-02  1.1154e+00\nRimi               -1.8544e-02 -2.8152e-05  2.6532e-03 -3.5947e-01\nRimin Gado          1.4231e+00 -3.4653e-03  3.2547e-01  2.5005e+00\nRingim              1.7206e+00 -3.3708e-03  3.1662e-01  3.0638e+00\nRiyom              -7.7615e-03 -2.7487e-05  2.5905e-03 -1.5195e-01\nRogo               -2.2127e-02 -1.0435e-05  9.8350e-04 -7.0522e-01\nRoni                6.7894e-02 -1.0803e-05  1.0181e-03  2.1281e+00\nSabon-Gari          1.4920e-01 -2.0520e-04  1.9336e-02  1.0744e+00\nSabon Birni        -3.2592e-01 -2.2638e-03  2.1287e-01 -7.0149e-01\nSabuwa             -5.2995e-01 -4.9836e-03  4.6735e-01 -7.6792e-01\nSafana              5.6177e-01 -1.6131e-03  1.5178e-01  1.4461e+00\nSagbama             8.5524e-01 -3.6544e-03  3.4316e-01  1.4662e+00\nSakaba             -4.1150e-03 -3.7627e-04  3.5450e-02 -1.9857e-02\nSaki East          -2.7474e-03 -7.7619e-08  7.3154e-06 -1.0158e+00\nSaki West           5.8267e-02 -3.6280e-05  3.4192e-03  9.9709e-01\nSandamu            -8.9392e-03 -2.6124e-05  2.4621e-03 -1.7963e-01\nSanga               1.2038e-01 -4.5607e-04  4.2964e-02  5.8299e-01\nSapele              1.6613e+00 -2.7984e-03  2.6300e-01  3.2448e+00\nSardauna            3.2475e-02 -1.1677e-03  1.0992e-01  1.0147e-01\nShagamu            -4.3613e-01 -6.2877e-04  5.9222e-02 -1.7896e+00\nShagari            -8.3930e-02 -4.5608e-05  4.2983e-03 -1.2795e+00\nShanga              5.9142e-01 -3.6345e-03  3.4130e-01  1.0186e+00\nShani              -1.4969e-02 -4.1159e-03  3.8632e-01 -1.7461e-02\nShanono             3.6091e-01 -2.4025e-04  2.2638e-02  2.4004e+00\nShelleng           -2.6518e-01 -1.9269e-04  1.8157e-02 -1.9665e+00\nShendam             1.3798e-01 -3.7789e-04  3.5602e-02  7.3328e-01\nShinkafi            3.0428e-01 -4.2187e-04  3.9743e-02  1.5284e+00\nShira               3.8406e-01 -4.5499e-04  4.2862e-02  1.8573e+00\nShiroro            -3.1366e-01 -5.7046e-04  5.3733e-02 -1.3506e+00\nShomgom             7.9679e-02 -2.0142e-04  1.8980e-02  5.7982e-01\nShomolu             9.6142e-01 -7.0387e-04  6.6292e-02  3.7368e+00\nSilame             -1.7460e-01 -4.1046e-04  3.8669e-02 -8.8583e-01\nSoba               -4.3914e-03 -9.1003e-06  8.5767e-04 -1.4964e-01\nSokoto North       -3.7903e-01 -2.3226e-03  2.1839e-01 -8.0610e-01\nSokoto South       -1.1840e-01 -4.8469e-04  4.5659e-02 -5.5182e-01\nSong                2.8746e-01 -4.1046e-04  3.8669e-02  1.4639e+00\nSouthern Ijaw       2.5308e+00 -5.1523e-03  4.8309e-01  3.6486e+00\nSule-Tankarkar      9.0145e-01 -1.6503e-03  1.5528e-01  2.2918e+00\nSuleja             -8.2968e-02 -1.6296e-04  1.5356e-02 -6.6822e-01\nSumaila             3.0234e-01 -3.4287e-04  3.2303e-02  1.6841e+00\nSuru                1.8118e+00 -5.3853e-03  5.0482e-01  2.5576e+00\nSurulere (Lagos)    1.4723e+00 -2.1982e-03  2.0672e-01  3.2431e+00\nSurulere (Oyo)      1.4848e-01 -4.5426e-04  4.2794e-02  7.1995e-01\nTafa               -4.2791e-01 -1.7815e-03  1.6760e-01 -1.0409e+00\nTafawa-Balewa       6.7682e-01 -1.2495e-03  1.1762e-01  1.9771e+00\nTai                -1.0046e+00 -2.7984e-03  2.6300e-01 -1.9534e+00\nTakai               7.4994e-01 -7.3257e-04  6.8993e-02  2.8579e+00\nTakum               1.8758e-01 -3.1624e-04  2.9796e-02  1.0885e+00\nTalata Mafara      -8.6017e-03 -3.9915e-07  3.7619e-05 -1.4024e+00\nTambuwal            3.4253e-01 -1.0571e-03  9.9528e-02  1.0891e+00\nTangaza             3.8728e-01 -2.3355e-03  2.1960e-01  8.3140e-01\nTarauni             7.9235e-01 -2.3456e-03  2.2055e-01  1.6922e+00\nTarka              -3.0279e-01 -5.8463e-04  5.5068e-02 -1.2878e+00\nTarmua              1.1296e+00 -1.5816e-03  1.4882e-01  2.9323e+00\nTaura               1.3111e+00 -1.9907e-03  1.8724e-01  3.0346e+00\nTofa                1.7764e+00 -3.9155e-03  3.6758e-01  2.9365e+00\nToro                4.2172e-01 -7.3933e-04  6.9629e-02  1.6010e+00\nToto                1.3416e-01 -2.3786e-05  2.2417e-03  2.8340e+00\nToungo              1.4408e-01 -8.4326e-04  7.9408e-02  5.1428e-01\nTsafe               4.3856e-01 -6.4177e-04  6.0447e-02  1.7864e+00\nTsanyawa            4.1927e-01 -2.7484e-04  2.5896e-02  2.6071e+00\nTudun Wada         -2.8425e-01 -1.8950e-04  1.7857e-02 -2.1258e+00\nTureta             -4.1698e-01 -1.7495e-03  1.6460e-01 -1.0235e+00\nUdenu               2.9287e-01 -3.1556e-03  2.9647e-01  5.4368e-01\nUdi                 1.3374e+00 -2.2499e-03  2.1157e-01  2.9125e+00\nUdu                -7.6829e-03 -9.4349e-08  8.8922e-06 -2.5764e+00\nUdung Uko           2.8961e+00 -5.2431e-03  4.9156e-01  4.1382e+00\nUghelli North      -1.3746e-01 -2.0463e-05  1.9285e-03 -3.1297e+00\nUghelli South       9.7072e-01 -1.1677e-03  1.0992e-01  2.9314e+00\nUgwunagbo           5.4614e-01 -1.9000e-03  1.7873e-01  1.2963e+00\nUhunmwonde          4.6652e-01 -1.9269e-04  1.8157e-02  3.4636e+00\nUkanafun            3.0508e+00 -6.0814e-03  5.6967e-01  4.0501e+00\nUkum                7.0756e-02 -2.8792e-04  2.7128e-02  4.3134e-01\nUkwa East           1.5300e+00 -3.0086e-03  2.8270e-01  2.8833e+00\nUkwa West           2.2244e-01 -1.0325e-03  9.7207e-02  7.1675e-01\nUkwuani             1.2491e+00 -4.3436e-03  4.0760e-01  1.9633e+00\nUmu-Nneochi         4.9245e-02 -6.8695e-05  6.4739e-03  6.1290e-01\nUmuahia North      -5.0488e-02 -5.6734e-04  5.3440e-02 -2.1595e-01\nUmuahia South       1.9621e-02 -3.2910e-05  3.1016e-03  3.5289e-01\nUngogo              1.0222e+00 -2.4048e-03  2.2611e-01  2.1548e+00\nUnuimo             -4.0352e-02 -3.1673e-05  2.9850e-03 -7.3799e-01\nUruan               2.7728e+00 -6.7509e-03  6.3196e-01  3.4965e+00\nUrue-Offong/Oruko   2.4238e+00 -3.7529e-03  3.5238e-01  4.0894e+00\nUshongo             3.5845e-02 -1.2067e-04  1.1371e-02  3.3728e-01\nUssa                1.0172e-01 -9.7497e-05  9.1880e-03  1.0622e+00\nUvwie               1.3821e+00 -4.0375e-03  3.7899e-01  2.2516e+00\nUyo                 1.3813e+00 -1.1978e-03  1.1276e-01  4.1172e+00\nUzo-Uwani           1.3249e-01 -3.2641e-03  3.0663e-01  2.4516e-01\nVandeikya          -4.3754e-02 -7.6795e-05  7.2372e-03 -5.1341e-01\nWamako              4.6153e-02 -3.3185e-04  3.1266e-02  2.6289e-01\nWamba               5.8195e-03 -1.3424e-04  1.2650e-02  5.2935e-02\nWarawa              2.8417e-01 -2.7258e-04  2.5683e-02  1.7749e+00\nWarji               9.9525e-01 -1.7480e-03  1.6445e-01  2.4585e+00\nWarri North         2.2967e+00 -4.9644e-03  4.6556e-01  3.3734e+00\nWarri South         8.5525e-01 -7.2968e-04  6.8720e-02  3.2653e+00\nWarri South West    2.4347e+00 -7.4553e-03  6.9741e-01  2.9244e+00\nWasagu/Danko       -8.6690e-03 -4.2615e-06  4.0164e-04 -4.3235e-01\nWase                9.0399e-02 -2.2006e-04  2.0736e-02  6.2930e-01\nWudil               4.1315e-01 -3.6254e-04  3.4156e-02  2.2375e+00\nWukari              1.0119e-02 -1.4179e-05  1.3363e-03  2.7721e-01\nWurno              -4.1666e-03 -1.7321e-06  1.6325e-04 -3.2597e-01\nWushishi           -5.3596e-02 -4.1935e-04  3.9506e-02 -2.6754e-01\nYabo               -1.1225e-01 -2.0294e-03  1.9088e-01 -2.5227e-01\nYagba East          8.7013e-01 -3.7010e-03  3.4752e-01  1.4823e+00\nYagba West          1.2614e+00 -2.5941e-03  2.4386e-01  2.5596e+00\nYakurr              8.4336e-03 -8.0437e-06  7.5809e-04  3.0660e-01\nYala                1.0714e-01 -5.1577e-05  4.8607e-03  1.5375e+00\nYamaltu/Deba        8.2980e-02 -6.2760e-04  5.9113e-02  3.4388e-01\nYankwashi           1.4686e-01 -1.3095e-03  1.2325e-01  4.2205e-01\nYauri               3.6196e-01 -9.2350e-04  8.6958e-02  1.2306e+00\nYenegoa             3.0740e-01 -1.1149e-03  1.0496e-01  9.5228e-01\nYola North          7.9953e-01 -1.9269e-03  1.8125e-01  1.8825e+00\nYola South         -7.6797e-01 -9.2350e-04  8.6958e-02 -2.6012e+00\nYorro               2.8050e-01 -4.3771e-04  4.1235e-02  1.3835e+00\nYunusari            1.7808e+00 -4.1159e-03  3.8632e-01  2.8717e+00\nYusufari            1.3627e+00 -1.8708e-03  1.7599e-01  3.2527e+00\nZaki                1.0296e+00 -1.8123e-03  1.7049e-01  2.4980e+00\nZango              -6.6335e-02 -8.8181e-04  8.3036e-02 -2.2714e-01\nZango-Kataf         3.8076e-02 -3.0891e-03  2.9024e-01  7.6410e-02\nZaria               1.8910e-01 -3.5938e-04  3.3859e-02  1.0296e+00\nZing                5.5477e-02 -2.5118e-05  2.3673e-03  1.1408e+00\nZurmi               7.0303e-02 -1.8205e-05  1.7158e-03  1.6977e+00\nZuru                2.1917e-02 -1.2740e-05  1.2007e-03  6.3287e-01\n                   Pr.z....E.Ii..\nAba North                  0.0198\nAba South                  0.0062\nAbaji                      0.6345\nAbak                       0.0011\nAbakaliki                  0.0417\nAbeokuta North             0.2050\nAbeokuta South             0.2641\nAbi                        0.6014\nAboh-Mbaise                0.9281\nAbua/Odual                 0.9598\nAbuja Municipal            0.9093\nAdavi                      0.0086\nAdo                        0.5522\nAdo-Odo/Ota                0.0270\nAdo Ekiti                  0.5808\nAfijio                     0.1278\nAfikpo North               0.9022\nAfikpo South               0.4102\nAgaie                      0.8087\nAgatu                      0.0002\nAgege                      0.0023\nAguata                     0.0581\nAgwara                     0.0904\nAhiazu-Mbaise              0.5708\nAhoada East                0.0322\nAhoada West                0.6671\nAiyedade                   0.3991\nAiyedire                   0.3147\nAiyekire (Gbonyin)         0.5239\nAjaokuta                   0.0025\nAjeromi-Ifelodun           0.0010\nAjingi                     0.0039\nAkamkpa                    0.1008\nAkinyele                   0.2151\nAkko                       0.1817\nAkoko-Edo                  0.0186\nAkoko North East           0.3067\nAkoko North West           0.5168\nAkoko South East           0.2792\nAkoko South West           0.8801\nAkpabuyo                   0.0009\nAkuku Toru                 0.3531\nAkure North                0.8048\nAkure South                0.0492\nAkwanga                    0.5767\nAlbasu                     0.0026\nAleiro                     0.1482\nAlimosho                   0.0011\nAlkaleri                   0.3581\nAmuwo-Odofin               0.0016\nAnambra East               0.0386\nAnambra West               0.5427\nAnaocha                    0.0098\nAndoni                     0.3598\nAninri                     0.2434\nAniocha North              0.2811\nAniocha South              0.7580\nAnka                       0.6603\nAnkpa                      0.0006\nApa                        0.0000\nApapa                      0.0021\nArdo-Kola                  0.8630\nArewa-Dandi                0.1975\nArgungu                    0.4987\nArochukwu                  0.0940\nAsa                        0.5441\nAsari-Toru                 0.0434\nAskira/Uba                 0.6855\nAtakumosa East             0.1085\nAtakumosa West             0.5369\nAtiba                      0.3150\nAtigbo                     0.2080\nAugie                      0.2378\nAuyo                       0.0014\nAwe                        0.4185\nAwgu                       0.0433\nAwka North                 0.5075\nAwka South                 0.0853\nAyamelum                   0.2984\nBabura                     0.0192\nBadagry                    0.0532\nBade                       0.0016\nBagudo                     0.0008\nBagwai                     0.0041\nBakori                     0.2402\nBakura                     0.7503\nBalanga                    0.1954\nBali                       0.8820\nBama                       0.0000\nBarikin Ladi               0.4612\nBaruten                    0.6791\nBassa (Kogi)               0.0001\nBassa (Pleateau)           0.4250\nBatagarawa                 0.7050\nBatsari                    0.4536\nBauchi                     0.0492\nBaure                      0.0354\nBayo                       0.7154\nBebeji                     0.0399\nBekwara                    0.7660\nBende                      0.9690\nBiase                      0.1575\nBichi                      0.0014\nBida                       0.4763\nBilliri                    0.7728\nBindawa                    0.1878\nBinji                      0.4753\nBiriniwa                   0.0029\nBirni Kudu                 0.0097\nBirnin-Gwari               0.2726\nBirnin Kebbi               0.0666\nBirnin Magaji              0.0684\nBiu                        0.0494\nBodinga                    0.7843\nBogoro                     0.0474\nBoki                       0.7757\nBokkos                     0.9821\nBoluwaduro                 0.2349\nBomadi                     0.0010\nBonny                      0.5380\nBorgu                      0.0678\nBoripe                     0.3096\nBosso                      0.9784\nBrass                      0.1246\nBuji                       0.0066\nBukkuyum                   0.7074\nBungudu                    0.1635\nBunkure                    0.0426\nBunza                      0.0419\nBursari                    0.0017\nBuruku                     0.8272\nBurutu                     0.0002\nBwari                      0.9627\nCalabar-Municipal          0.0002\nCalabar South              0.0005\nChanchaga                  0.9148\nCharanchi                  0.1395\nChibok                     0.1629\nChikun                     0.3459\nDala                       0.0062\nDamaturu                   0.0339\nDamban                     0.2852\nDambatta                   0.0018\nDamboa                     0.0002\nDan Musa                   0.0297\nDandi                      0.0290\nDandume                    0.9359\nDange-Shuni                0.6560\nDanja                      0.8790\nDarazo                     0.5875\nDass                       0.0475\nDaura                      0.7232\nDawakin Kudu               0.1458\nDawakin Tofa               0.0437\nDegema                     0.0008\nDekina                     0.0013\nDemsa                      0.1051\nDikwa                      0.0000\nDoguwa                     0.0822\nDoma                       0.0040\nDonga                      0.6626\nDukku                      0.1437\nDunukofia                  0.0169\nDutse                      0.0078\nDutsi                      0.8019\nDutsin-Ma                  0.0150\nEastern Obolo              0.0035\nEbonyi                     0.0260\nEdati                      0.8522\nEde North                  0.5165\nEde South                  0.8507\nEdu                        0.7245\nEfon                       0.4391\nEgbado North               0.0567\nEgbado South               0.4829\nEgbeda                     0.5093\nEgbedore                   0.5518\nEgor                       0.0276\nEhime-Mbano                0.2549\nEjigbo                     0.5940\nEkeremor                   0.0080\nEket                       0.0000\nEkiti                      0.3040\nEkiti East                 0.1979\nEkiti South West           0.3166\nEkiti West                 0.8935\nEkwusigo                   0.0023\nEleme                      0.3473\nEmohua                     0.1157\nEmure                      0.2552\nEnugu East                 0.1206\nEnugu North                0.0380\nEnugu South                0.0260\nEpe                        0.1450\nEsan Central               0.0012\nEsan North East            0.0001\nEsan South East            0.0031\nEsan West                  0.0018\nEse-Odo                    0.0027\nEsit - Eket                0.0000\nEssien Udim                0.0000\nEtche                      0.9605\nEthiope East               0.0070\nEthiope West               0.0036\nEti-Osa                    0.0022\nEtim Ekpo                  0.0000\nEtinan                     0.0003\nEtsako Central             0.0023\nEtsako East                0.0181\nEtsako West                0.0029\nEtung                      0.7014\nEwekoro                    0.2411\nEzeagu                     0.0707\nEzinihitte                 0.6793\nEzza North                 0.0141\nEzza South                 0.1981\nFagge                      0.0343\nFakai                      0.0413\nFaskari                    0.6563\nFika                       0.4535\nFufore                     0.1995\nFunakaye                   0.0413\nFune                       0.1329\nFuntua                     0.7852\nGabasawa                   0.0203\nGada                       0.1497\nGagarawa                   0.0047\nGamawa                     0.0515\nGanjuwa                    0.2191\nGanye                      0.7503\nGarki                      0.0017\nGarko                      0.0473\nGarum Mallam               0.0123\nGashaka                    0.9087\nGassol                     0.9853\nGaya                       0.0291\nGbako                      0.8813\nGboko                      0.8326\nGezawa                     0.0044\nGiade                      0.1948\nGirei                      0.0594\nGiwa                       0.0521\nGokana                     0.0906\nGombe                      0.0205\nGombi                      0.1269\nGoronyo                    0.8854\nGudu                       0.2355\nGulani                     0.7398\nGuma                       0.3377\nGumel                      0.0009\nGummi                      0.5762\nGurara                     0.4569\nGuri                       0.0166\nGusau                      0.5840\nGuyuk                      0.0326\nGwadabawa                  0.4130\nGwagwalada                 0.6344\nGwale                      0.0163\nGwandu                     0.3639\nGwaram                     0.0240\nGwarzo                     0.0245\nGwer East                  0.2886\nGwer West                  0.0369\nGwiwa                      0.4486\nGwoza                      0.0124\nHadejia                    0.0002\nHawul                      0.0826\nHong                       0.2997\nIbadan North               0.6463\nIbadan North East          0.2958\nIbadan North West          0.1463\nIbadan South East          0.4672\nIbadan South West          0.1733\nIbaji                      0.0517\nIbarapa Central            0.3570\nIbarapa East               0.2951\nIbarapa North              0.2031\nIbeju/Lekki                0.3768\nIbeno                      0.0001\nIbesikpo Asutan            0.0001\nIbi                        0.9847\nIbiono Ibom                0.0001\nIdah                       0.0019\nIdanre                     0.0052\nIdeato North               0.2947\nIdeato South               0.8096\nIdemili North              0.0730\nIdemili South              0.0042\nIdo                        0.2111\nIdo-Osi                    0.3995\nIfako-Ijaye                0.0006\nIfe Central                0.7536\nIfe East                   0.4004\nIfe North                  0.3111\nIfe South                  0.0161\nIfedayo                    0.5809\nIfedore                    0.1051\nIfelodun (Kwara)           0.0902\nIfelodun (Osun)            0.4194\nIfo                        0.0069\nIgabi                      0.0508\nIgalamela-Odolu            0.7215\nIgbo-Etiti                 0.0001\nIgbo-Eze North             0.9864\nIgbo-Eze South             0.2633\nIgueben                    0.0076\nIhiala                     0.0411\nIhitte/Uboma               0.9097\nIjebu East                 0.6534\nIjebu North                0.8417\nIjebu North East           0.4074\nIjebu Ode                  0.7367\nIjero                      0.9528\nIjumu                      0.0159\nIka                        0.0002\nIka North East             0.0008\nIka South                  0.0145\nIkara                      0.0722\nIkeduru                    0.7017\nIkeja                      0.0026\nIkenne                     0.9268\nIkere                      0.9242\nIkole                      0.8418\nIkom                       0.4623\nIkono                      0.0001\nIkorodu                    0.0078\nIkot Abasi                 0.0001\nIkot Ekpene                0.0003\nIkpoba-Okha                0.0062\nIkwerre                    0.3331\nIkwo                       0.4608\nIkwuano                    0.1286\nIla                        0.2551\nIlaje                      0.0103\nIle-Oluji-Okeigbo          0.0396\nIlejemeji                  0.4749\nIlesha East                0.2520\nIlesha West                0.4006\nIllela                     0.6753\nIlorin East                0.4462\nIlorin South               0.2858\nIlorin West                0.7209\nImeko-Afon                 0.7423\nIngawa                     0.1029\nIni                        0.0081\nIpokia                     0.3435\nIrele                      0.0031\nIrepo                      0.5909\nIrepodun (Kwara)           0.3357\nIrepodun (Osun)            0.6375\nIrepodun/Ifelodun          0.4004\nIrewole                    0.7665\nIsa                        0.5078\nIse/Orun                   0.3534\nIseyin                     0.1929\nIshielu                    0.0089\nIsi-Uzo                    0.1824\nIsiala-Ngwa North          0.0668\nIsiala-Ngwa South          0.9936\nIsiala Mbano               0.7870\nIsin                       0.0618\nIsiukwuato                 0.8091\nIsokan                     0.3700\nIsoko North                0.0011\nIsoko South                0.0190\nIsu                        0.8056\nItas/Gadau                 0.0179\nItesiwaju                  0.3101\nItu                        0.0019\nIvo                        0.6896\nIwajowa                    0.1077\nIwo                        0.5596\nIzzi                       0.0259\nJaba                       0.6653\nJada                       0.0989\nJahun                      0.0000\nJakusko                    0.0196\nJalingo                    0.1262\nJama'are                   0.0173\nJega                       0.0559\nJema'a                     0.9839\nJere                       0.0000\nJibia                      0.4654\nJos East                   0.1825\nJos North                  0.5108\nJos South                  0.3590\nKabba/Bunu                 0.0043\nKabo                       0.0082\nKachia                     0.1711\nKaduna North               0.0813\nKaduna South               0.0069\nKafin Hausa                0.0032\nKafur                      0.2276\nKagarko                    0.7656\nKaiama                     0.5926\nKaita                      0.7367\nKajola                     0.2012\nKajuru                     0.1669\nKalgo                      0.1467\nKaltungo                   0.2730\nKanam                      0.0973\nKankara                    0.0103\nKanke                      0.0607\nKankia                     0.0120\nKano Municipal             0.0133\nKarasuwa                   0.0020\nKaraye                     0.0233\nKarim-Lamido               0.9282\nKaru                       0.4783\nKatagum                    0.9018\nKatcha                     0.9316\nKatsina                    0.9084\nKatsina-Ala                0.2816\nKaugama                    0.0057\nKaura                      0.8639\nKaura Namoda               0.2616\nKauru                      0.5657\nKazaure                    0.1918\nKeana                      0.3299\nKebbe                      0.2223\nKeffi                      0.2711\nKhana                      0.1480\nKibiya                     0.1627\nKirfi                      0.1443\nKiri Kasamma               0.0012\nKiru                       0.0287\nKiyawa                     0.0016\nKogi                       0.3244\nKoko/Besse                 0.0941\nKokona                     0.9667\nKolokuma/Opokuma           0.0697\nKonduga                    0.0006\nKonshisha                  0.9480\nKontagora                  0.0910\nKosofe                     0.0006\nKubau                      0.1307\nKudan                      0.9651\nKuje                       0.8666\nKumbotso                   0.0659\nKunchi                     0.0107\nKura                       0.0240\nKurfi                      0.3592\nKurmi                      0.4281\nKusada                     0.0474\nKwali                      0.3243\nKwami                      0.0146\nKwande                     0.6931\nKware                      0.5429\nKwaya Kusar                0.2893\nLafia                      0.4534\nLagelu                     0.4602\nLagos Island               0.0003\nLagos Mainland             0.0009\nLamurde                    0.7876\nLangtang North             0.2226\nLangtang South             0.4942\nLapai                      0.1945\nLau                        0.2220\nLavun                      0.4434\nLere                       0.0351\nLogo                       0.6664\nLokoja                     0.0058\nMachina                    0.0057\nMadobi                     0.0091\nMafa                       0.0000\nMagama                     0.0895\nMagumeri                   0.0000\nMai'adua                   0.6436\nMaiduguri                  0.0000\nMaigatari                  0.0010\nMaiha                      0.3818\nMaiyama                    0.0240\nMakoda                     0.0251\nMakurdi                    0.0493\nMalam Madori               0.0035\nMalumfashi                 0.0339\nMangu                      0.2931\nMani                       0.5568\nMaradun                    0.0376\nMariga                     0.2607\nMarkafi                    0.7094\nMaru                       0.6433\nMashegu                    0.4130\nMashi                      0.6517\nMatazu                     0.0381\nMayo-Belwa                 0.2489\nMbaitoli                   0.5253\nMbo                        0.0000\nMichika                    0.9971\nMiga                       0.0001\nMikang                     0.2904\nMinjibir                   0.0155\nMisau                      0.6592\nMkpat Enin                 0.0001\nMoba                       0.2590\nMokwa                      0.4543\nMonguno                    0.0000\nMopa-Muro                  0.1244\nMoro                       0.8349\nMubi North                 0.5016\nMubi South                 0.8105\nMusawa                     0.0283\nMushin                     0.0001\nMuya                       0.5067\nNafada                     0.0623\nNangere                    0.2407\nNasarawa                   0.0459\nNasarawa-Eggon             0.5644\nNassarawa                  0.0175\nNdokwa East                0.3487\nNdokwa West                0.0292\nNembe                      0.2788\nNgala                      0.0000\nNgaski                     0.1056\nNgor-Okpala                0.6856\nNguru                      0.0030\nNingi                      0.0434\nNjaba                      0.5194\nNjikoka                    0.0145\nNkanu East                 0.0226\nNkanu West                 0.0012\nNkwerre                    0.5999\nNnewi North                0.0027\nNnewi South                0.0232\nNsit Atai                  0.0000\nNsit Ibom                  0.0001\nNsit Ubium                 0.0003\nNsukka                     0.0685\nNuman                      0.8847\nNwangele                   0.7626\nObafemi-Owode              0.3168\nObanliku                   0.6183\nObi (Benue)                0.5750\nObi (Nasarawa)             0.4098\nObi Ngwa                   0.0032\nObia/Akpor                 0.1545\nObokun                     0.2409\nObot Akara                 0.0069\nObowo                      0.5390\nObubra                     0.6523\nObudu                      0.6386\nOdeda                      0.5446\nOdigbo                     0.0315\nOdo-Otin                   0.0954\nOdogbolu                   0.7802\nOdukpani                   0.0006\nOffa                       0.1014\nOfu                        0.0943\nOgba/Egbema/Ndoni          0.6976\nOgbadibo                   0.9519\nOgbaru                     0.3071\nOgbia                      0.1413\nOgbomosho North            0.9653\nOgbomosho South            0.4912\nOgo Oluwa                  0.8905\nOgoja                      0.4066\nOgori/Magongo              0.0036\nOgu/Bolo                   0.1688\nOgun waterside             0.2873\nOguta                      0.1155\nOhafia                     0.5271\nOhaji/Egbema               0.2992\nOhaozara                   0.3016\nOhaukwu                    0.1153\nOhimini                    0.0023\nOji-River                  0.0969\nOjo                        0.0035\nOju                        0.0918\nOke-Ero                    0.1525\nOkehi                      0.0104\nOkene                      0.0067\nOkigwe                     0.6157\nOkitipupa                  0.0395\nOkobo                      0.0001\nOkpe                       0.0070\nOkpokwu                    0.4377\nOkrika                     0.0724\nOla-oluwa                  0.3875\nOlamabolo                  0.6860\nOlorunda                   0.4558\nOlorunsogo                 0.5373\nOluyole                    0.6295\nOmala                      0.0011\nOmumma                     0.0866\nOna-Ara                    0.1802\nOndo East                  0.0989\nOndo West                  0.0046\nOnicha                     0.1073\nOnitsha North              0.0654\nOnitsha South              0.0304\nOnna                       0.0001\nOpobo/Nkoro                0.0078\nOredo                      0.0086\nOrelope                    0.4578\nOrhionmwon                 0.0034\nOri Ire                    0.9961\nOriade                     0.3588\nOrlu                       0.6839\nOrolu                      0.5577\nOron                       0.0000\nOrsu                       0.2689\nOru East                   0.4225\nOru West                   0.4336\nOruk Anam                  0.0000\nOrumba North               0.1725\nOrumba South               0.3398\nOse                        0.0142\nOshimili North             0.8788\nOshimili South             0.0025\nOshodi-Isolo               0.0008\nOsisioma Ngwa              0.2508\nOsogbo                     0.8506\nOturkpo                    0.0025\nOvia North East            0.0155\nOvia South West            0.0064\nOwan East                  0.0016\nOwan West                  0.0365\nOwerri-Municipal           0.3229\nOwerri North               0.2837\nOwerri West                0.1188\nOwo                        0.2737\nOye                        0.6683\nOyi                        0.0157\nOyigbo                     0.3870\nOyo East                   0.3080\nOyo West                   0.3322\nOyun                       0.0954\nPaikoro                    0.9723\nPankshin                   0.1318\nPatani                     0.0348\nPategi                     0.0422\nPort-Harcourt              0.1317\nPotiskum                   0.6226\nQua'an Pan                 0.8863\nRabah                      0.6716\nRafi                       0.3064\nRano                       0.1107\nRemo North                 0.7333\nRijau                      0.2647\nRimi                       0.7192\nRimin Gado                 0.0124\nRingim                     0.0022\nRiyom                      0.8792\nRogo                       0.4807\nRoni                       0.0333\nSabon-Gari                 0.2826\nSabon Birni                0.4830\nSabuwa                     0.4425\nSafana                     0.1482\nSagbama                    0.1426\nSakaba                     0.9842\nSaki East                  0.3097\nSaki West                  0.3187\nSandamu                    0.8574\nSanga                      0.5599\nSapele                     0.0012\nSardauna                   0.9192\nShagamu                    0.0735\nShagari                    0.2007\nShanga                     0.3084\nShani                      0.9861\nShanono                    0.0164\nShelleng                   0.0492\nShendam                    0.4634\nShinkafi                   0.1264\nShira                      0.0633\nShiroro                    0.1768\nShomgom                    0.5620\nShomolu                    0.0002\nSilame                     0.3757\nSoba                       0.8810\nSokoto North               0.4202\nSokoto South               0.5811\nSong                       0.1432\nSouthern Ijaw              0.0003\nSule-Tankarkar             0.0219\nSuleja                     0.5040\nSumaila                    0.0922\nSuru                       0.0105\nSurulere (Lagos)           0.0012\nSurulere (Oyo)             0.4716\nTafa                       0.2979\nTafawa-Balewa              0.0480\nTai                        0.0508\nTakai                      0.0043\nTakum                      0.2764\nTalata Mafara              0.1608\nTambuwal                   0.2761\nTangaza                    0.4057\nTarauni                    0.0906\nTarka                      0.1978\nTarmua                     0.0034\nTaura                      0.0024\nTofa                       0.0033\nToro                       0.1094\nToto                       0.0046\nToungo                     0.6071\nTsafe                      0.0740\nTsanyawa                   0.0091\nTudun Wada                 0.0335\nTureta                     0.3061\nUdenu                      0.5867\nUdi                        0.0036\nUdu                        0.0100\nUdung Uko                  0.0000\nUghelli North              0.0017\nUghelli South              0.0034\nUgwunagbo                  0.1949\nUhunmwonde                 0.0005\nUkanafun                   0.0001\nUkum                       0.6662\nUkwa East                  0.0039\nUkwa West                  0.4735\nUkwuani                    0.0496\nUmu-Nneochi                0.5399\nUmuahia North              0.8290\nUmuahia South              0.7242\nUngogo                     0.0312\nUnuimo                     0.4605\nUruan                      0.0005\nUrue-Offong/Oruko          0.0000\nUshongo                    0.7359\nUssa                       0.2881\nUvwie                      0.0243\nUyo                        0.0000\nUzo-Uwani                  0.8063\nVandeikya                  0.6077\nWamako                     0.7926\nWamba                      0.9578\nWarawa                     0.0759\nWarji                      0.0140\nWarri North                0.0007\nWarri South                0.0011\nWarri South West           0.0035\nWasagu/Danko               0.6655\nWase                       0.5292\nWudil                      0.0253\nWukari                     0.7816\nWurno                      0.7444\nWushishi                   0.7891\nYabo                       0.8008\nYagba East                 0.1383\nYagba West                 0.0105\nYakurr                     0.7592\nYala                       0.1242\nYamaltu/Deba               0.7309\nYankwashi                  0.6730\nYauri                      0.2185\nYenegoa                    0.3410\nYola North                 0.0598\nYola South                 0.0093\nYorro                      0.1665\nYunusari                   0.0041\nYusufari                   0.0011\nZaki                       0.0125\nZango                      0.8203\nZango-Kataf                0.9391\nZaria                      0.3032\nZing                       0.2540\nZurmi                      0.0896\nZuru                       0.5268\n\n\nWe will append the local Moran’s I dataframe (i.e. localMI) onto the nga_wp_filter dataframe using the following code chunk. The output is saved in nga_wp_filter.localMI.\n\nnga_wp_filter.localMI <- cbind(nga_wp_filter, localMI)%>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n8.1.2 Mapping local Moran’s I values and p-values\nWe will use choropleth mapping functions of tmap package to plot the local Moran’s I values and the associated p-values by using the code chunks below.\n\nlocalMI.map <- tm_shape(nga_wp_filter.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local Moran's I statistics\") +\n    tm_shape(nga_wp) +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(nga_wp_filter.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n    tm_shape(nga_wp) +\n  tm_borders(alpha = 0.5)+\n  tmap_mode(mode = \"plot\")\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2) \n\n\n\n\nIn addition, we will plot only the local Moran’s I values with p-values < 0.05 (statistically significant) using the following code chunk.Here, we use tmap_mode() and specify mode = “view” to generate an interactive map and easier zooming in since there are over 700 LGAs.\n\ntm_shape(nga_wp_filter.localMI %>% filter(Pr.Ii < 0.05)) +\n    tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local Moran's I statistics\") +\n    tm_shape(nga_wp) +\n    tm_borders(alpha = 0.5)+\n  tmap_mode(mode = \"view\")\n\n\n\n\n\n\nWe can observe several spatial clusters for the proportion of non-functional water points - most notably (bigger plots) at:\n(1) Top end of the North East zone\n(2) Right end of North West zone\n(3) Left and right ends of South South zone\n(4) Parts of North Central zone\nIn addition, there are also LGAs with negative local Moran’s I, including Ika North East and Kaduna South. The geographical regions are identified in accordance to the 6 geopolitical zones identified in the following diagram.\n\nimage reference [3]\n\n\n\n8.2 Functional Water Points\nIn this section, we will focus for functional water points.\n\n8.2.1 Computing local Moran’s I\n\nfips <- order(nga_wp_filter$shapeName)\nlocalMIfunc <- localmoran(nga_wp_filter$pct_functional, wm)\nnga_wp_filter.localMIfunc <- cbind(nga_wp_filter, localMIfunc)%>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n8.2.2 Mapping local Moran’s I values and p-values\n\nlocalMI.map <- tm_shape(nga_wp_filter.localMIfunc) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local Moran's I statistics\") +\n    tm_shape(nga_wp) +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(nga_wp_filter.localMIfunc) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n    tm_shape(nga_wp) +\n  tm_borders(alpha = 0.5)+\n  tmap_mode(mode = \"plot\") \n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\nIn addition, we will plot only the local Moran’s I values with p-values < 0.05 (statistically significant) using the following code chunk.\n\ntm_shape(nga_wp_filter.localMIfunc %>% filter(Pr.Ii < 0.05)) +\n    tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local Moran's I statistics\") +\n    tm_shape(nga_wp) +\n    tm_borders(alpha = 0.5) +\n    tmap_mode(\"view\")"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#plotting-moran-scatterplot",
    "href": "take_home_ex/ex1/take-home-ex1.html#plotting-moran-scatterplot",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "9 Plotting Moran Scatterplot",
    "text": "9 Plotting Moran Scatterplot\n\n9.1 Non-Functional Water Points\nMoran scatterplots plots the spatially lagged values of interest (proportion of non-functional water points) against the original values of interest. It allows us to study the local spatial distribution. The Moran scatterplot is divided into four areas, with each quadrant representing the following categories:\n\nHigh-High (in the top right quadrant): indicates LGAs with high proportion of non-functional water points located next to other LGAs with high proportion of non-functional water points\nHigh-Low (in the bottom right quadrant): indicates LGAs with high proportion of non-functional water points located next to other LGAs with low proportion of non-functional water points\nLow-High (in the top left quadrant): indicates LGAs with low proportion of non-functional water points located next to other LGAs with high proportion of non-functional water points\nLow-Low (in the bottom left quadrant): indicates LGAs with low proportion of non-functional water points located next to other LGAs with low proportion of non-functional water points\n\nIn the following, we will plot a Moran scatterplot with standardised variable.\nWe will first use scale() to center and scale the variable of interest (proportion of non-functional water points). Centering is done by subtracting the mean and scaling is done by dividing the centered variable by its standard deviation. as.vector is added to the end to make sure that the data type of the output is a vector, which can then be mapped neatly into a dataframe.\n\nnga_wp_filter$Z.pct_nonfunctional <- scale(nga_wp_filter$pct_nonfunctional) %>% \n  as.vector\n\nNow, we can plot the Moran scatterplot using the following code chunk.\n\nmoran.plot(nga_wp_filter$Z.pct_nonfunctional, \n           wm,\n           labels=as.character(nga_wp_filter$shapeName),\n           xlab=\"z-Proportion of non-functional water points\", \n           ylab=\"Spatially Lag z-Proportion of non-functional water points\")\n\n\n\n\nThe plot is split into 4 quadrants - High-High (in the top right quadrant), High-Low (in the bottom right quadrant), Low-High (in the top left quadrant), and Low-Low (in the bottom left quadrant) as discused earlier.\nHowever, the Moran scatterplot has one drawback in that it does not indicate whether the LGAs identified are significant or not. As such, we will work on the LISA cluster map."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#creating-a-lisa-cluster-map",
    "href": "take_home_ex/ex1/take-home-ex1.html#creating-a-lisa-cluster-map",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "10 Creating a LISA Cluster Map",
    "text": "10 Creating a LISA Cluster Map\nLocal Indicators of Spatial Association (LISA) address the limitation in Moran scatterplot as it allows us to identify hotspots and as well as the associated statistical significance. As such, in addition to the four quadrants identified (high-high, high-low, low-high, and low-low), in LISA cluster map, there is a fifth category, i.e. LGAs with no statistically significant spatial autocorrelation (no clustering).\n\n10.1 Non-Functional Water Points\n\n10.1.1 Preparing LISA map classes\nThe following outlines the steps to prepare a LISA cluster map.\nWe will first derive the spatially lagged variable of interest, i.e. the proportion of non-functional water points using lag.listw() and we center the spatially lagged variable around it mean.\nIn the following code chunk for lag.listw(), we can provide an object that is created by nb2listw, in our case, this is the weight distance matrix of the 8 nearest neighbours wm. For the second argument, we need to list a numeric vector to calculate the spatially lagged values.\n\nnga_wp_filter$lag_pct_nf <- lag.listw(wm, nga_wp_filter$pct_nonfunctional)\nDV <- nga_wp_filter$lag_pct_nf - mean(nga_wp_filter$lag_pct_nf)\n\nThis is followed by centering the local Moran’s I around its mean.\n\nLM_I <- localMI[,1] - mean(localMI[,1])\n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05 \n\nIn the following code chunk, we define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nnonfunctional <- vector(mode=\"numeric\",length=nrow(localMI))\nnonfunctional[DV <0 & LM_I>0] <- 1\nnonfunctional[DV >0 & LM_I<0] <- 2\nnonfunctional[DV <0 & LM_I<0] <- 3  \nnonfunctional[DV >0 & LM_I>0] <- 4 \n\nWe create an additional category for LGAs with no statistically significant autocorrelation in the following code chunk.\n\nnonfunctional[localMI[,5]>signif] <- 0\n\n\n\n10.1.2 Plotting LISA map\nUsing the following code chunk, we will plot the proportion of non-functional water points on the map on the left. For the map on the right, we will map only the LISA map for the proportion of non-functional water points.\n\nnga_wp_filter.localMI$nonfunctional <- nonfunctional\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISA <- tm_shape(nga_wp_filter.localMI) +\n  tm_fill(col = \"nonfunctional\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(nonfunctional)))+1], \n          labels = clusters[c(sort(unique(nonfunctional)))+1]) +\n  tm_borders(alpha=0.7)\n\nnonfunc <- tm_shape(nga_wp_filter.localMI) +\n    tm_fill(col = \"pct_nonfunctional\") +\n  tm_borders(alpha=0.7)\n\ntmap_arrange(nonfunc, LISA, asp=1, ncol=2) \n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the LISA map, the following observations can be made:\n\n\n\n\n\n\n\nLISA Map region\nObservations\n\n\n\n\n\n\nHigh number of LGAs belonging to the low-low quadrant found in both North East and North West zones\nA few outlier LGAs belonging to high-low quadrant, more of such found in North West\n2 LGAs were belonging to high-high quadrant (North East)\n\n\n\n\nAnalysis\nNorth East zone has a clear majority in the ethnic/regious group, with the major tribes being Hausa and Fulani. [4] It is likely that there is politically stability in this region resulting in consistent use and maintenance of these water points, hence explaining the significant clusters of low-low proportion of non-functional water points observed in this zone. In addition, a single major tribe could also mean strong knitted community that works together to properly maintain public goods. Because in areas where small and large ethno-religious groups in Nigeria have long coexisted, these groups are constantly colliding over land, resources and political power. [4] Such circumstances may result in water points being abandoned or poorly maintained.\nNorth West has a similar demographic, populated by Hausa and Fulani tribes. The similar demographics could be the likely reason why a significant low-low cluster is observed in North West. However, in the North West, we could see higher number of outlier LGAs classified as high-low quadrant, reflecting that there are some LGAs with high proportion of non-functional water points surrounded by LGAs with low proportion of non-functional water points. This is aligned with the plot for proportion of non-functional water points where we observe more LGAs in North West zone that are orange in colour (higher proportion of non-functional water points) compared to the surrounding LGAs that are yellow in colour (lower proportion of non-functional water points).\n\n\n\n\n\n\n\nLISA Map region\nObservations\n\n\n\n\n\nSouth South zone:\n\nSignificant clusters of high-high\nPockets of outliers (low-high)\n\nSouth East zone:\n\nSome LGAs in low-low quadrant and some LGAs in outliers that are high-low quadrant\n\nSouth West zone:\n\nCluster of high-high observed in area along the border shared with South South\n\nNorth Central zone:\n\nCluster of high-high observed in area closest to South South\nJust north of this cluster, there is a region of outliers of low-high\n\n\n\n\nMost of the LGAs classified in the high-high quadrant either lie with the South South zone or are found near the South South zone of Nigeria. Most significantly, on the right of South South zone, the cluster is almost entirely high-high. The South South zone is the economic mainstream of the country as it is the location of the country’s crude oil deposit and crude oil production is the major economic activity of the region. [4] As urban areas are concentrated in the South due to the higher volume of economic activities compared to the other zones in Nigeria, large scale migration is likely to put pressure on existing water points infrastructure [5], resulting in significant clusters of high-high proportion of non-functional water points found in this zone.\nInterestingly, just above the cluster of high-high observed in North Central, there is a clear region of outliers (low-high), implying the LGAs in North Central that are further from the South South zone has lower proportion of non-functional water points compared to those nearer to the South South zone.\nIn comparison to the urban South South zone, both the North East and North West zones’ main economic activity is agriculture and farming. [4] As such, we can see that the clusters in urban areas tend to be high-high whereas the clusters in the more rural areas tend to be low-low.\n\n\n\n10.2 Functional Water Points\n\n10.2.1 Preparing LISA map classes\nWe will perform similar steps for functional water points as shown in the following code chunk.\n\nnga_wp_filter$lag_pct_func <- lag.listw(wm, nga_wp_filter$pct_functional)\nDVfunc <- nga_wp_filter$lag_pct_func - mean(nga_wp_filter$lag_pct_func)\nLM_Ifunc <- localMIfunc[,1] - mean(localMIfunc[,1])\nsignif <- 0.05 \nFunctional <- vector(mode=\"numeric\",length=nrow(localMIfunc))\nFunctional[DVfunc <0 & LM_Ifunc>0] <- 1\nFunctional[DVfunc >0 & LM_Ifunc<0] <- 2\nFunctional[DVfunc <0 & LM_Ifunc<0] <- 3  \nFunctional[DVfunc >0 & LM_Ifunc>0] <- 4 \nFunctional[localMIfunc[,5]>signif] <- 0\n\n\n\n10.2.2 Plotting LISA map\nUsing the following code chunk, we will plot the proportion of functional water points on the map on the left. For the map on the right, we will map only the LISA map for the proportion of functional water points.\n\nnga_wp_filter.localMIfunc$Functional <- Functional\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAfunc <- tm_shape(nga_wp_filter.localMIfunc) +\n  tm_fill(col = \"Functional\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(Functional)))+1], \n          labels = clusters[c(sort(unique(Functional)))+1]) +\n  tm_borders(alpha=0.7) \n\nfunc <- tm_shape(nga_wp_filter.localMIfunc) +\n    tm_fill(col = \"pct_functional\") +\n  tm_borders(alpha=0.7)\n\ntmap_arrange(func, LISAfunc, asp=1, ncol=2) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.3 LISA map Comparison Between Non-Functional and Functional WP\nWe will plot the LISA maps for non-functional water points and functional water points side by side using the following code chunk.\n\ntmap_arrange(LISA, LISAfunc, asp=1, ncol=2) \n\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, the 2 LISA maps agree with each other, where:\n\nlow-low LGAs in the non-functional water points map should correspond to high-high LGAs in the functional water points map\nhigh-high LGAs in the non-functional water points map should correspond to low-low LGAs in the functional water points map\n\nAn exception is observed at the top right most of the map where cold spots are observed in both the maps show LGAs that are low-low. Upon further review of the data, it turns out that a number of the LGAs here (Monguno, Jere, Mafa, Dikwa, Ngala, and Bama) have the status of all their water points as unknown. Hence, resulting in both plots reflecting these LGAs as low-low.\nIn addition, it can also be observed that in the North West and North East regions, there are more high-high LGAs (red) in functional water points map compared to the number of low-low LGAs (dark blue) in the non-functional water points map. Nonetheless, it is a good sign that there are more spatial clusters of LGAs with a high proportion of functional water points in these zones.\nWhen comparing these 2 plots, it is also apparent that understanding the non-functional water points clustering is not sufficient to get the full picture of which LGA clusters do not have access to satisfactory water points. In particular, in the South East zone - while the non-functional map does not have much significant LGAs, in the functional map, we could see that there are significant numbers of LGAs that are low-low (blue LGAs outlined in black, with reference to images below) which implies that there is a likely cluster of LGAs with low proportion of functioning water points.\nEconomically, the South East region is quite diverse, with crude oil production and agriculture being its major economic activities. Some states in the region are also actively involved in agriculture. [4] As the South East zone lies in the middle of the South South zone LGAs, there is a possibility the rural to urban migration to South South zone is spilled over to the South East zone and hence puts a strain on the water points within South East, resulting in clustering of low-low LGAs on the proportion of functional water points observed in South East zone (blue LGAs outlined in black below) along with some high-low LGAs observed."
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#gi-statistics",
    "href": "take_home_ex/ex1/take-home-ex1.html#gi-statistics",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "11 Gi statistics",
    "text": "11 Gi statistics\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas. The High/Low Clustering (General G) tool measures the concentration of high or low values for a given study area. The null hypothesis for the High/Low Clustering (General G) statistic states that there is no spatial clustering of feature values. When the p-value returned is small and statistically significant, the null hypothesis can be rejected and the sign of the Gi value becomes important.\nIf the Gi value is positive and significant, it indicates that location i is associated with relatively high values of the surrounding area (i.e. hot spots). If the Gi value is negative and significant, it indicates that location i is associated with relatively low values in the surrounding areas (i.e. cold spots).\nThe High/Low Clustering (Getis-Ord General G) tool is most appropriate when there is a fairly even distribution of values and the intention is to look for unexpected spatial spikes of high values. Unfortunately, when both the high and low values cluster, they tend to cancel each other out.\n\n11.1 Non-Functional Water Points\n\n11.1.1 Computing Gi statistics\nTo compute the Gi statistics, we use localG() from the spdep package. We then combine the Gi statistics with the rest of the data in nga_wp_filter.\n\nfips <- order(nga_wp_filter$shapeName)\ngi <- localG(nga_wp_filter$pct_nonfunctional, wm)\nnga_wp_filter.gi <- cbind(nga_wp_filter, as.matrix(gi)) %>%\n  rename(gstat_adaptive = as.matrix.gi.)\n\nNext, we will calculate the p-values using the pnorm() from base R. We define lower.tail to be False because we want to evaluate for probability(X > x) instead of probability(X <= x). pnorm() is used because Gi statistics is actually a z-score, which implies that it comes from a normal distribution and has a mean and standard deviation of 0 and 1 respectively. [6] In the following for q, we need to apply abs() because there are both positive and negative values in gi statistics and we want to test for both of these values. Since the absolute gi value is greater than 0, we set lower.tail to False. And since pnorm is a one-sided test, we need to first calculate the p-value on the absolute gi and then multiply by 2.\n\npval = 2*pnorm(q = abs(gi), lower.tail = FALSE)\n\nWe then need to adjust the p-values using p.adjustSP() to address connectivity with neighbours, i.e. spatial association. We selected the method to adjust the p-values as bonferroni.[6] The Bonferroni correction adjusts p-values because of the increased risk of a type I error when making multiple statistical tests - since we are using each LGA multiple times (i.e. one LGA can be neighbours of differnet LGAs and hence are used in multiple statistical tests).\n\npvals_bon = p.adjustSP(p = pval, nb = knn8, method = \"bonferroni\")\n\nWe will then add the p-values to the rest of the data as shown in the following code chunk.\n\nnga_wp_filter.gi <- cbind(nga_wp_filter.gi, pvals_bon)\n\n\n\n11.1.2 Mapping Gi values\nUsing the following code chunk, we will plot the proportion of non-functional water points on the map on the left. For the map on the right, we will map only the statistically significant Gi values proportion of non-functional water points.\n\npct_nonfunctional <- qtm(nga_wp_filter, \n                         \"pct_nonfunctional\")\n\nGimap <-tm_shape(nga_wp_filter.gi %>% filter(pvals_bon < 0.05)) +\n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi for non-functional\") +\n    tm_shape(nga_wp_filter.gi) +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(pct_nonfunctional, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nA low negative local Gi score indicates a coldspot - high concentration of LGAs with low proportion of non-functional water points.. The lower the score, the more intense the clustering. We observe coldspots (blue) mainly in the North East area and parts of North West zone. The most intense coldspots (darkest blue) is also observed in the North East zone.\nA high positive local Gi score indicates a hotspot - high concentration of LGAs with high proportion of non-functional water points. The higher the local Gi score, the more intense the spatial clustering. We observe hotspots (red) mainly in the South South area. The most intense hotspots (darkest red) is observed in mainly in South South zone and 1 LGA in the North Central zone.\nBoth observations on coldspots and hotspots agree with the results concluded from LISA maps for non-functional water points.\nWhile not obvious in the LISA map, from the Gi map, we observe more areas of hotspots in the leftmost of North West region as well as more coldspots in the North East region.\n\n\n\n11.2 Functional Water Points\n\n11.2.1 Computing Gi statistics\nIn the following code chunk, we compute the Gi statistics for the proportion of functional water points.\n\nfips <- order(nga_wp_filter$shapeName)\ngifunc <- localG(nga_wp_filter$pct_functional, wm)\nnga_wp_filter.gifunc <- cbind(nga_wp_filter, as.matrix(gifunc)) %>%\n  rename(gstat_adaptive = as.matrix.gifunc.)\n\nNext, we will calculate the p-values using the pnorm() and then adjust them using p.adjustSP() to address connectivity with neighbours, i.e. spatial association.\n\npvalfunc = 2*pnorm(q = abs(gifunc), lower.tail = FALSE)\npvals_bonfunc = p.adjustSP(p = pvalfunc, nb = knn8, method = \"bonferroni\")\n\nWe will then add the p-values to the rest of the data as shown in the following code chunk.\n\nnga_wp_filter.gifunc <- cbind(nga_wp_filter.gifunc, pvals_bonfunc)\n\n\n\n11.2.2 Mapping Gi values\nUsing the following code chunk, we will plot the proportion of functional water points on the map on the left. For the map on the right, we will map only the statistically significant Gi values for the proportion of functional water points.\n\npct_functional <- qtm(nga_wp_filter, \n                      \"pct_functional\")\n\nGimapfunc <-tm_shape(nga_wp_filter.gifunc %>% filter(pvals_bonfunc < 0.05)) +\n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi for functional\") +\n    tm_shape(nga_wp_filter.gifunc) +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(pct_functional, Gimapfunc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.3 Gi Map Comparison Between Non-Functional and Functional WP\nWe will plot the Gi maps for non-functional water points and functional water points side by side using the following code chunk.\n\ntmap_arrange(Gimap, Gimapfunc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt can be observed that the 2 maps agree with each other in the top of the North East region where\n\nHotspots in the non-functional water points plot should correspond with coldspots in the functional water points map.\nLikewise, coldspots in the non-functional water points plot should correspond with hotspots in the functional water points map.\n\nThe results above also agree with the LISA map in the following:\n\nThere are hotspots in the left and right ends of the South South zone for the non-functional water points map (which means high concentration of LGAs with high proportion of non-functioning water points at these South South areas).\nThere are hotspots in the North West and North East zones for the functional water point map - high concentration of LGAs with high proportion of functioning water points at these areas.\nThere are coldspots in the South East zone for functional water point map - high concentration of LGAs with low proportion of functioning water points at these areas.\n\nSimilar to the LISA maps comparison, an exception is observed at the top right most of the map where cold spots are observed in both the maps show coldspots. It turns out that a number of the LGAs here (Monguno, Jere, Mafa, Dikwa, Ngala, and Bama) have the status of all their water points as unknown. Hence, resulting in both plots reflecting coldspots.\nWith reference to the images below, it is interesting to note that LISA map is able to point out the outliers, i.e. high-low areas in orange (within North West zone). At the same LGAs, Gi map does not show any clustering. This is as expected because when both the high and low values cluster, they tend to cancel each other out (as discussed in Section 11).\n\n\n\n\n\n\n\nLISA map for non-functional water points\nGi map for non-functional water points"
  },
  {
    "objectID": "take_home_ex/ex1/take-home-ex1.html#references",
    "href": "take_home_ex/ex1/take-home-ex1.html#references",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "12 References",
    "text": "12 References\n[1] Spatial Correlogram concept\n[2] Understanding Anselin Local Moran’s I\n[3] Geopolitical zones in Nigeria\n[4] 6 Geopolitical zones in Nigeria, their states, and their economic activities\n[5] Why are so many water points in Nigeria non-functional?\n[6] Computing p-values for Gi statistics"
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html",
    "href": "in_class_ex/ex3/in_class_ex3.html",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this in-class exercise, we will discuss ClustGeo method for spatially constrained clustering (discussed in Section 9). This is a continuation from the topics discussed in hands-on exercise 3. For easier reading, Sections from hands-on exercise 3 is also added here."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#getting-started",
    "href": "in_class_ex/ex3/in_class_ex3.html#getting-started",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using the penetration of multiple Information and Communication Technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#the-data",
    "href": "in_class_ex/ex3/in_class_ex3.html#the-data",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3 The Data",
    "text": "3 The Data\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries): This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth datasets are downloaded from Myanmar Information Management Unit (MIMU)\n\n3.1 Installing and loading R packages\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment. The R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse (which contains readr, ggplot2 and dplyr)\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(rgdal, spdep, tmap, sf, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse,\n               ClustGeo)"
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#data-import-and-preparation",
    "href": "in_class_ex/ex3/in_class_ex3.html#data-import-and-preparation",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4 Data Import and Preparation",
    "text": "4 Data Import and Preparation\n\n4.1 Importing geospatial data into R environment\nIn this section, we will import Myanmar Township Boundary GIS data and its associated attribute table into R environment.\nThe Myanmar Township Boundary GIS data is in ERSI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf <- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %>%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\"))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\lohsiying\\ISSS624\\in_class_ex\\ex3\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID           ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1       163 Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2       203 Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3       240 Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4       106 Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5        72 Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6        40 Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7       194 Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8       159 Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9        61 Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10      124 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                 ST_2            LABEL2 SELF_ADMIN ST_RG T_NAME_WIN T_NAME_M3\n1  Shan State (North)    Mongmit\\n61072       <NA> State   rdk;rdwf      မိုးမိတ်\n2  Shan State (South)    Pindaya\\n77769       Danu State     yif;w,     ပင်းတယ\n3  Shan State (South)    Ywangan\\n76933       Danu State      &GmiH       ရွာငံ\n4  Shan State (South)  Pinlaung\\n162537       Pa-O State  yifavmif;   ပင်လောင်း\n5  Shan State (North)     Mabein\\n35718       <NA> State     rbdrf;      မဘိမ်း\n6  Shan State (South)     Kalaw\\n163138       <NA> State       uavm      ကလော\n7  Shan State (South)      Pekon\\n94226       <NA> State     z,fcHk       ဖယ်ခုံ\n8  Shan State (South)          Lawksawk       <NA> State   &yfapmuf    ရပ်စောက်\n9  Shan State (North) Nawnghkio\\n128357       <NA> State  aemifcsdK    နောင်ချို\n10 Shan State (North)   Kyaukme\\n172874       <NA> State   ausmufrJ    ကျောက်မဲ\n       AREA                       geometry\n1  2703.611 MULTIPOLYGON (((96.96001 23...\n2   629.025 MULTIPOLYGON (((96.7731 21....\n3  2984.377 MULTIPOLYGON (((96.78483 21...\n4  3396.963 MULTIPOLYGON (((96.49518 20...\n5  5034.413 MULTIPOLYGON (((96.66306 24...\n6  1456.624 MULTIPOLYGON (((96.49518 20...\n7  2073.513 MULTIPOLYGON (((97.14738 19...\n8  5145.659 MULTIPOLYGON (((96.94981 22...\n9  3271.537 MULTIPOLYGON (((96.75648 22...\n10 3920.869 MULTIPOLYGON (((96.95498 22...\n\n\nSince sf.data.frame conforms to the tidy framework, we can use glimpse()` to reveal the data type in each field in shan_sf.\n\n\n4.2 Importing aspatial data into R environment\nThe csv file will be imported using read_csv frunction of readr package as shown in the following code chunk:\n\nict <- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s tibble data.frame format.\nThe code chunk below shows the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nWe can see that there a total of eleven fields and 55 observations in the tibble data.frame.\n\n\n4.3 Deriving new variables using dplyr package\nThe data in ict provides the count of the number of households. Such units of measurement is directly biased by the underlying total number of households in the town. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV etc.\nIn order to overcome this issue, we will derive the penetration rate for each ICT by using the code chunk below. We will multiply by 1000 so that we have the statistics for per thousand household.\n\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%\n  rename(`DT_PCODE` =`District Pcode`,\n         `DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, \n         `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, \n         `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, \n         `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, \n         `INTERNET`=`Internet at home`) \n\nWe can review the summary statistics of the newly derived variables using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985"
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#exploratory-data-analysis-eda",
    "href": "in_class_ex/ex3/in_class_ex3.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5 Exploratory Data Analysis (EDA)",
    "text": "5 Exploratory Data Analysis (EDA)\n\n5.1 EDA using statistical graphs\nWe can plot the overall distribution of the variables by using a histogram. Using a histogram allows us to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).\nIn the following code chunk, we derive the histogram plot for the number of radios.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nTo identify outliers, boxplots can be used.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nNext, we will plot the distribution of the newly derived variables. In the following code chunk, we plot the histogram for the radio penetration rate.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\nFrom the histogram, we can observe a slight right skew in the distribution of the radio penetration rate - there is more lower radio pentration rates compared to higher radio penetration rates.\nLikewise, we will generate the boxplot for the radio pentration rate.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\nFrom the boxplot, we can see that the median radio pentration rate is slightly over 20%. It can also be observed that there is an outlier township that with significantly high radio penetration rate of about 49%. The range of radio pentration rate across the townships also vary widely, from about 2% to 49% penetration rates.\nWe can also plot multiple histograms together in the same plot to reveal the distribution of various variables. We can do this by first creating the individual histograms and then using ggarange() function from ggpubr package is used to group these histograms together.\n\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n5.2 EDA using choropleth map\n\n5.2.1 Joining geospatial data with aspatial data\nIn order to plot the choropleth map, we need to combine the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived). This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table to keep the geometry field in shan_sf.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf <- left_join(shan_sf, \n                     ict_derived, \n                     by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n\n\n\n5.2.2 Plotting a choropleth map\nWe will have a look at the distribution of Radio penetration rate of Shan State at township level by plotting a choropleth map. The code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\nHowever, the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships. To demonstrate this, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\nThe choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\nHere, we can see that larger townships do not necessarily have higher radio penetration. By using the radio penetration rate, we are able to correctly reflect which township has higher proportion of their residents having radios."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#correlation-analysis",
    "href": "in_class_ex/ex3/in_class_ex3.html#correlation-analysis",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6 Correlation Analysis",
    "text": "6 Correlation Analysis\nIt is important for us to ensure that cluster variables are not highly correlated when we perform cluster analysis. This is because we do not want to give extra weight to these highly correlated variables.\nWe will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation between the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe fatter the ellipse, the more weakly correlated they are. Moving more like a line, means more strongly correlated.\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#hierarchical-cluster-analysis",
    "href": "in_class_ex/ex3/in_class_ex3.html#hierarchical-cluster-analysis",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7 Hierarchical Cluster Analysis",
    "text": "7 Hierarchical Cluster Analysis\nIn this section, we will perform hierarchical cluster analysis.\n\n7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into a data.frame. We will exclude the variables INTERNET_PR and keep only the COMPUTER_PR. We will also remove the geometry field by setting it to null (we will not be able to exclude the geometry column by using select()).\n\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNext, we will use the township name as the row names instead of using row number.\n\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nWe can then delete the TS.x field (column for township names).\n\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNow that our data.frame only contains clustering variables as attributes, we can perform clustering using this data.frame. The township names are in the row index and will not be used as variables for clustering. Also, when we plot the dendrogram, the township names will be the leaves.\n\n\n7.2 Data Standardisation\nNext, we will perform data standardisation. It is not unusual that value ranges of differnet variables can differ significantly. As we want to avoid the cluster analysis from being biased towards clustering variables that have larger values.\n\n7.2.1 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nWe can observe that the value range for each variable is now between 0 and 1 after min0max standardisation is performed.\n\n\n7.2.2 Z-score standardisation\nZ-score standardisation can be performed by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method. In here, we will use describe() from psych package to to review the results instead of summary() of Base R because the describe() provides standard deviation.\n\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nWe can observe that the mean and standard deviation of the Z-score standardised variable are now 0 and 1 respectively. However, we will also need to wary that Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n7.2.3 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plots the scaled Radio_PR field.\n\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\nWe can observe that the overall distribution of the clustering variable changes after data standardisation is performed. Hence, it is not advisable to perform data standardisation if the value ranges of the clustering variables are not very large.\n\n\n\n7.3 Computing proximity matrix\nIn R, there are many packages that provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is the euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat <- dist(shan_ict, method = 'euclidean')\n\n\n\n7.4 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used. There are eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the dendrogram produced by the clustering process.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the dendrogram by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n7.5 Selecting the optimal clustering algorithm\nOne of the challenges in performing hierarchical clustering is to identify the strongest clustering structures. The issue can be solved by using agnes() function from cluster package. It functions like hclus(), however, with the agnes() function we can also get the agglomerative coefficient, which measures the amount of clustering structure found. The closer the coefficient is to 1, the stronger the clustering structure.\nThe code chunk below will be used to compute the agglomerative coefficients of 4 hierarchical clustering algorithm: “average”, “single”, “complete”, and “ward”.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWe can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n7.6 Determining the optimal number of clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\nHere, we will explore the gap statistic method.\n\n7.6.1 Gap statistic method\nThe gap statistic compares the total intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be the value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is furthest away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the next largest gap statistic and should be the next best cluster to pick.\n\n\n\n7.7 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nWe use the height of the fusion, provided on the vertical axis, to tell the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Such conclusions on proximity of two observations can only be drawn based on the height where the branches containing those two observations first are fused.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n7.8 Visually-driven hierarchical clustering analysis\nIn this section, we will perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.8.1 Transforming the data frame into a matrix\nThe data has to be a data matrix to make a heatmap using the heatmaply package.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat <- data.matrix(shan_ict)\n\n\n\n7.8.2 Plotting the interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n7.9 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups which is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below performs the following three steps:\n\nthe groups list object will be converted into a matrix using as.matrix();\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map to show the 6 clusters formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nHowever, we can see that the clustered formed are very fragmented. The is one of the major limitations when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#spatially-constrained-clustering---skater-approach",
    "href": "in_class_ex/ex3/in_class_ex3.html#spatially-constrained-clustering---skater-approach",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8 Spatially Constrained Clustering - SKATER Approach",
    "text": "8 Spatially Constrained Clustering - SKATER Approach\nIn this section, we will derive spatially constrained cluster by using skater() from spdep package.\n\n8.1 Converting data into SpatialPolygonsDataFrame\nFirst, we will need to convert shan_sf into a SpatialPolygonsDataFrame. This is because SKATER function only supports sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp <- as_Spatial(shan_sf)\n\n\n\n8.2 Computing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb <- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe will plot the neighbours list in shan_sp by using the code chunk below. We will first plot the community area boundaries. It is important to first plot the area boundaries as the they extend further than the network graph. If done otherwise, some of the boundaries will be clipped. We then plot the neighbour list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n8.3 Computing minimum spanning tree\nIn this section, we will compute the minimum spanning tree. The minimum spanning tree is the one whose cumulative edge weights have the smallest value. We can think of this as the least cost path that goes through the entire graph and touches very node.\n\n8.3.1 Calculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts <- nbcosts(shan.nb, shan_ict)\n\nFor each observation, lcosts this gives the pairwise dissimilarity between its values on the five variables and that of each of its neighbours. This forms the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object, i.e., we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nWe specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n8.3.2 Computing minimum spanning tree\nNext, we will calculate the minimum spanning tree. The minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst <- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunks below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nWe can observe that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   31   25 229.44658\n[2,]   25   10 163.95741\n[3,]   10    1 144.02475\n[4,]   10    9 157.04230\n[5,]    9    8  90.82891\n[6,]    8    6 140.01101\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n8.4 Computing spatially constrained clusters using SKATER method\nThe code chunk below computes the spatially constrained cluster using skater() of spdep package.\n\nclust6 <- skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments:\n\nedges: the first two columns of the MST matrix (i.e. excluding the cost)\ndata: the data matrix (to update the costs as units are being grouped), and\nncuts: the number of cuts. Note: It is set to one less than the number of clusters.\n\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 31 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 31 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label is arbitary). This is followed by a detailed summary for each of the clusters, provided in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the code chunk below.\n\nccs6 <- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations there are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 22 (given by $ node: num [1:22]), which is also the number of observations in the first cluster ()which aligns with the results from the code chunk below).\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n8.5 Visualising the clusters in a choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat <- as.matrix(clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\nFor easy comparison, it is better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map <- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\n\n\n\nComparing these 2 maps, it is clear that the spatially constrained clustering gives a better clustering where clusters are constrained together and not fragmented, unlike in the map given by hierarchical clustering."
  },
  {
    "objectID": "in_class_ex/ex3/in_class_ex3.html#spatially-constrained-clustering-clustgeo-method",
    "href": "in_class_ex/ex3/in_class_ex3.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9 Spatially Constrained Clustering: ClustGeo Method",
    "text": "9 Spatially Constrained Clustering: ClustGeo Method\nIn this section, we will use functions provided in ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n9.1 Ward-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() used in the previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide a dissimilarity matrix to the function as shown in the code chunk below.\n\nnongeo_cluster <- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist().\n\n\n9.1.1 Mapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps in 7.9 Mapping the clusters formed.\n\ngroups <- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n9.2 Spatially Constrained Hierarchical Clustering\nBefore we perform spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist <- st_distance(shan_sf, shan_sf)\ndistmat <- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below. It uses both d0 distance (attribute homogeneity used in hierarchical clustering) as well as d1 contiguity matrix (spatial homogeneity). In hierarchical clustering, alpha value is 0 which is why only attribute space is considered and no spatial relationship is considered. Alpha value ranges from 0 to 1. At alpha = 1, only spatial homogeneity is considered (no consideration is given to attribute homogeneity).\nIn the following, we define the incremental value for alpha to be evaluated is 0.1.\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nTwo plots are given, the first graph shows the non-normalised result and the second graph shows the normalised result. The normalised graph should be used when there is significant difference in the range of values (for attribute distance and spatial relationship).\nWe can see that when we increase the value of alpha, the black line decreases - implying that the attribute homogeneity is being compromised.\nWe can also see that as we increase the alpha value from 0.1 to 0.2, the spatial homogeneity increases significantly from 0.3 to 0.6. Even as we increase the alpha value to 0.3, we only compromise the attribute homogeneity slightly as we continue to improve on spatial homogeneity.\nWith reference to the graphs above, alpha = 0.3 will be used as shown in the code chunk below.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster object.\n\ngroups <- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can not plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html",
    "href": "take_home_ex/ex2/take-home-ex2.html",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "",
    "text": "The process of creating regions is called regionalisation. Regionalisation is a special kind of clustering which groups observations by incorporating both the statistical attributes and their spatial relationships. The spatial relationships are commonly modeled using contiguity and proximity considerations. As such, geographical constraints within a region are not limited to connectivity (i.e. there exists a path from one member to another member that leaves the region), and in certain contexts it make sense to relax connectivity and to impose other types of geographical constraints.\nRegionalisation results in aggregation of basic spatial units into larger regions that preserve confidentiality, minimizes population differences and reduces the effects of outliers or inaccuracies in the data. This can help to facilitate visualisation and interpretation of information on the maps. [1]"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#objectives",
    "href": "take_home_ex/ex2/take-home-ex2.html#objectives",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "2 Objectives",
    "text": "2 Objectives\nIn this take-home exercise, we will regionalise Nigeria via conventional clustering without explicit spatial constraint i.e. hierarchical clustering, as well as clustering with explicit spatial constraints.\nThis will be performed by considering the following as potential clustering variables:\n\nTotal number of functional water points\nTotal number of non-functional water points\nPercentage of functional water points\nPercentage of non-functional water points\nPercentage of main water point technology (i.e. hand pump)\nPercentage of low usage water points (i.e. <1000)\nPercentage of high usage water points (i.e. >=1000)\nPercentage of rural water points\nPercentage of water points that require payment\nPercentage of crucial water points"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#the-data",
    "href": "take_home_ex/ex2/take-home-ex2.html#the-data",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "3 The Data",
    "text": "3 The Data\nIn this exercise, we will analyse the data from Nigeria. There are 2 datasets used, as outlined in sections 3.1 and 3.2.\n\n3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,008 unique water point records.\n\n\n3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#getting-the-data-into-r-environment",
    "href": "take_home_ex/ex2/take-home-ex2.html#getting-the-data-into-r-environment",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "4 Getting The Data Into R Environment",
    "text": "4 Getting The Data Into R Environment\n\n4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nHandling spatial data\n\nsf, rgdal, and spdep\n\nHandling attribute data (import, data wrangling, and visualising)\n\ntidyverse, especially readr, ggplot2, and dplyr\nrehshape2\n\nExploratory Data Analysis and Data Preparation\n\nfunModeling\n\nGenerating choropleth maps\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, factoextra, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\nBuild tables and manipulate table styles\n\nkableExtra\n\n\n\npacman::p_load(sf, tidyverse, tmap, spdep, funModeling, corrplot, ggpubr, rgdal,\n               heatmaply, cluster, ClustGeo, reshape2, factoextra, \n               kableExtra)\n\n\n\n4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga_sf <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\nnga_sf\n\nThe above printout shows the data is in wgs84 geographic coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga_sf, \n          \"geodata/nga_sf.rds\")\n\n\n\n4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwp <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwp <- st_as_sf(wp,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \nwp\n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(wp, \n          \"geodata/wp.rds\")\n\n\n\n4.4 Data Wrangling for Nigeria LGA boundary data\n\n4.4.1 Checking for duplicated area name\nWe will first sort the names of the LGAs in alphabetical order using sort(). We will then use duplicated() to retrieve all the shapeName that is duplicated and store them in a list. [Concise code chunk is adapted from Reference 2]\n\nnga_sf <- read_rds(\"geodata/nga_sf.rds\")\nnga_sf <- (nga_sf[order(nga_sf$shapeName), ])\nduplicate_area <- nga_sf$shapeName[nga_sf$shapeName %in%\n                                nga_sf$shapeName[duplicated(nga_sf$shapeName)] ]\nduplicate_area\n\n [1] \"Bassa\"    \"Bassa\"    \"Ifelodun\" \"Ifelodun\" \"Irepodun\" \"Irepodun\"\n [7] \"Nasarawa\" \"Nasarawa\" \"Obi\"      \"Obi\"      \"Surulere\" \"Surulere\"\n\n\nWe will add 2 columns for longitude and latitude which we will use to check the LGA names for the duplicated rows using latlong.net. The following code chunk adds columns for longitude and latitude.\n\nnga_sf$longitude <- map_dbl(nga_sf$geometry, ~st_centroid(.x)[[1]])\nnga_sf$latitude <- map_dbl(nga_sf$geometry, ~st_centroid(.x)[[2]])\n\nBased on the results from latlong.net, the table below shows the index and the actual area name.\n\n\n\nIndex in nga table\nActual area name\n\n\n\n\n94\nBassa (Kogi)\n\n\n95\nBassa (Plateau)\n\n\n304\nIfelodun (Kwara)\n\n\n305\nIfelodun (Osun)\n\n\n355\nIrepodun (Kwara)\n\n\n356\nIrepodun (Osun)\n\n\n518\nNassarawa\n\n\n546\nObi (Benue)\n\n\n547\nObi (Nasarawa)\n\n\n693\nSurulere (Lagos)\n\n\n694\nSurulere (Oyo)\n\n\n\nWe will then rectify the incorrect names in nga table by accessing the relevant rows by their indexes as shown in the following code chunk.\n\nnga_sf$shapeName[c(94,95,304,305,355,356,519,546,547,693,694)] <- c(\n                               \"Bassa (Kogi)\", \"Bassa (Plateau)\",\n                               \"Ifelodun (Kwara)\", \"Ifelodun (Osun)\",\n                               \"Irepodun (Kwara)\", \"Irepodun (Osun)\",\n                               \"Nassarawa\",\n                               \"Obi (Benue)\", \"Obi(Nasarawa)\",\n                               \"Surulere (Lagos)\", \"Surulere (Oyo)\")\n\nWe will then check if all duplicated area names have been successfully rectified. We perform this by checking if there is anymore duplicated records using duplicated().\n\nnga_sf$shapeName[nga_sf$shapeName %in% nga_sf$shapeName[duplicated(nga_sf$shapeName)] ]\n\ncharacter(0)\n\n\nFrom the results, we can see that there is no more duplicated names observed.\nWe then remove the columns we have just created to assist us in renaming the LGAs using the following code chunk.\n\nnga_sf <- nga_sf[-c(7:8)]"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#references",
    "href": "take_home_ex/ex2/take-home-ex2.html#references",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "12 References",
    "text": "12 References\n[1] Use case for regionalisation\n[2] Data Wrangling steps for Take-Home Exercise 1\n[3] Linkage method definition and illustration\n[4] Geopolitical zones of Nigeria"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#section",
    "href": "take_home_ex/ex2/take-home-ex2.html#section",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "5",
    "text": "5\n\nfilter <- select(as.data.frame(nga_wp_filter), c(8,9,17:24))\ncluster_vars.cor = cor(filter)\ncorrplot.mixed(cluster_vars.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#data-wrangling-for-nigeria-water-point-data",
    "href": "take_home_ex/ex2/take-home-ex2.html#data-wrangling-for-nigeria-water-point-data",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "5 Data Wrangling for Nigeria water point data",
    "text": "5 Data Wrangling for Nigeria water point data\nIn this section, we will review several variables provided in the water point data that was downloaded from WPdx Global Data Repositories to be considered for clustering variables. To perform regionalisation of the LGAs based on the water points, we are interested in the following attributes for the water points:\n\nHow accessible is the water point, i.e. do we need to travel long distances to get to the water point?\nHow many people can be served by the water point?\nAre the water points still functioning?\nAre the water points using hand pump technology (i.e. the most common technology for water supply in rural communities)?\nAre there fees incurred for using the water point?\n\n\n5.1 Loading data and recoding NA values into string for status_clean field\nWe will first load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp <- read_rds(\"geodata/wp.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n5.2 EDA for distance attributes\nWe can plot multiple histograms together in the same plot to reveal the distribution of various variables. We can do this by first creating the individual histograms and then using ggarange() function from ggpubr package to group these histograms together.\nThere are 5 distance variables in wp, namely, distance to primary road, distance to secondary road, distance to tertiary road, distance to city, and distance to town. We are interested in understanding the distances to travel to reach the water points as we postulate that water points that are more accessible would likely to be used more frequently, be better maintained, and remain functional. We will plot the histograms for these variables using the following code chunk.\n\nprimary <- ggplot(data=wp,\n                  aes(x=`#distance_to_primary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nsecondary <- ggplot(data=wp,\n                  aes(x=`#distance_to_secondary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ntertiary <- ggplot(data=wp,\n                  aes(x=`#distance_to_tertiary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ncity <- ggplot(data=wp,\n                  aes(x=`#distance_to_city`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ntown <- ggplot(data=wp,\n                  aes(x=`#distance_to_town`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nggarrange(primary, secondary, tertiary, city, town, \n          ncol = 3,\n          nrow = 2)\n\n\nAccording to the data source for the description of these variables, the distances are measured in km. However, it is unlikely that the distances to reach the water points can go up to minimally 60,000 km (distance_to_tertiary_road). It is likely that some distances in the data set were recorded in metres and others in kilometers. As we are unable to tell the unit of measurement used for each water point record, we will not be using any of these distance variables in our subsequent analysis.\n\n\n5.3 EDA for status of water points\nWe are also interested in understanding the functionality of the water points, i.e. whether they are still functioning or not.\nIn the following code chunk, we use freq() to determine the number of records in each classification for the status of the water points.\n\nfreq(data = wp,\n     input = 'status_clean')\n\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. For instance, for non-functional water points, they may be categorised as ‘non-functional’, or as ‘non-functional due to dry season’. As such, we need to re-group the data to create 2 separate dataframes each containing either type of functional water points.\nIn addition, we will treat abandoned water points as non-functional.\n\n5.3.1 Extracting functionality of water points\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.5.2.\n\ntable(wp_functional$status_clean)\n\n\ntable(wp_nonfunctional$status_clean)\n\n\ntable(wp_unknown$status_clean)\n\nThe output shows that filtering was performed successfully.\n\n\n\n5.4 Extracting water points with hand pump technology\nIn the following code chunk, we want to see what are the types of water point technology listed in the data. From the output figures, we can also observe that the water point technology is not recorded for some of the records.\n\ntable(wp$`#water_tech_category`)\n\nFrom the results, we can tell that there are approximately 89% of the water points with the water technology information being recorded. Since this represents the majority (i.e. more than 80%), it remains to be a suitable variable to be used for subsequent analysis.\nWe can also see that the majority of the water points are built based on hand pump technology (approximately 62%). As such, we will want to extract water points that have this main water point technology (i.e. hand pump). Since there is only 1 category for hand pumps, we will extract water points with hand pump technology by specifying “Hand Pump”.\n\nwp_handpump <- wp %>% \n    filter(`#water_tech_category` %in% \"Hand Pump\")\n\n\n\n5.5 Extracting water points by their usage capacity\nWe will classify the usage capacity of water points as low if the maximum number of users that can be served by the water point is below 1000 and classify as high if the maximum number of users that can be served by the water point is 1000 and above.\nWe will first check whether the usage capacity is specified for all the water points. From the results, we are able to tell that the usage capacity for all water points are recorded.\n\nnrow(subset(wp, wp$usage_capacity < 1000))\nnrow(subset(wp, wp$usage_capacity >= 1000))\n\nIn the following code chunk, we will extract water points with low and high usage capacity respectively.\n\nwp_low_usage <- wp %>% \n    filter(usage_capacity < 1000)\nwp_high_usage <- wp %>% \n    filter(usage_capacity >= 1000)\n\n\n\n5.6 Extracting rural water points\nWe also expect that LGAs would differ by the number of water points that are in rural areas and in the urban areas. Likewise, we will first determine whether all water point records are classified as either urban or rural.\n\ntable(wp$is_urban)\n\nWe can see that the results add up to 95,008 which is the total number of records. Hence, there is no missing field for this column. Since the classification is binary, we will extract just one of them - rural.\nIn the following code chunk, we will extract the water points that are rural.\n\nwp_rural <- wp %>% \n    filter(is_urban %in% FALSE)\n\n\n\n5.7 Extracting water points with more than 50% crucialness_score\nAnother variable that we found useful for our analysis is the crucialness_score which is the ratio of likely current users to the total local population within a 1km radius of the water point. This can also serve as a substitute for the distance variables which we have identified as unsuitable for analysis previously in section 5.2.\nIn the following code chunk, we wanted to identify the number of water points with no crucialness_score recorded. From the results, we see that there are 6879 records (approximately 7% of all records) with missing crucialness score. Since the majority of the records have crucialness score, we can proceed with subsequent analysis.\n\nsum(is.na(wp$crucialness_score))\n\nIn the following code chunk, we will extract water points that are located within 1km of at least half of the total population, i.e. crucialness_score >= 0.5.\n\nwp_crucial <- wp %>% \n    filter(crucialness_score >=0.5)\n\n\n\n5.8 Extracting water points that do not require payment\nWe also expect LGAs to differ regionally based on whether the water points require payment for use. Likewise, we will first look at the different categories within this column. The results show that the records can be classified into - NA (11%), Yes (7%), and No (82%).\n\nfreq(data = wp,\n     input = '#pay')\n\n\nAlthough we have 11% missing data, the majority of the records are populated. Hence, we will proceed to using this variable by extracting water point records that do not require payment.\n\nwp_pay <- wp %>% \n    filter(`#pay` == \"No\")\n\n\n\n5.9 EDA for water points based on their pressure score\nWe are also interested in understanding whether the water points are stressed, i.e. serving more people than what it was built to support. For this, we can use the variable on pressure_score which is calculated based on the ratio of the number of people assigned to that water point over the theoretical maximum population which can be served based on the technology. Thus, a pressure_score of more than 100 implies that the water point is serving more than the recommended maximum.\nIn the following code chunk, we determine the number of water points that are serving below 80% of its recommended maximum capacity and those that are serving more than 80% of its recommended maximum capacity.\n\nnrow(subset(wp, wp$pressure_score < 80)) / 95008 * 100 \nnrow(subset(wp, wp$pressure_score >= 80)) / 95008 * 100\n\nThe results show that there are missing records, along with 92.6% of water points serving below 80% of its maximum and 0.1% serving above 80% of its maximum. Since we are only certain that 0.1% serve more than 80% of its maximum, this number of water points is too little for further analysis. Hence, we will not use this variable for subsequent analysis."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#performing-point-in-polygon-count",
    "href": "take_home_ex/ex2/take-home-ex2.html#performing-point-in-polygon-count",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "6 Performing Point-in-Polygon Count",
    "text": "6 Performing Point-in-Polygon Count\nWe want to find the number of water points in each LGA - including total, functional, non-functional, unknown functionality status, hand pump technology, low usage capacity, high usage capacity, and rural water points. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of such water points that fall inside each LGA.\n\nnga_wp <- nga_sf %>% \n    mutate(`total_wp` = lengths(\n        st_intersects(nga_sf, wp))) %>%\n    mutate(`wp_functional` = lengths(\n        st_intersects(nga_sf, wp_functional))) %>%\n    mutate(`wp_nonfunctional` = lengths(\n        st_intersects(nga_sf, wp_nonfunctional))) %>%\n    mutate(`wp_unknown` = lengths(\n        st_intersects(nga_sf, wp_unknown))) %>% \n    mutate(`wp_handpump` = lengths(\n        st_intersects(nga_sf, wp_handpump))) %>% \n    mutate(`wp_low_usage` = lengths(\n        st_intersects(nga_sf, wp_low_usage))) %>%\n    mutate(`wp_high_usage` = lengths(\n        st_intersects(nga_sf, wp_high_usage))) %>%\n    mutate(`wp_rural` = lengths(\n        st_intersects(nga_sf, wp_rural))) %>% \n    mutate(`wp_pay` = lengths(\n        st_intersects(nga_sf, wp_pay))) %>% \n    mutate(`wp_crucial` = lengths(\n        st_intersects(nga_sf, wp_crucial)))  \n\n\n6.1 Transforming the projection from wgs84 to EPSG: 26391\nIn this section, we will transform the geographic coordinate system to the projected coordinate system. This is because in the subsequent section, we will be performing adaptive distance weighting and geographic coordinate system is not appropriate for such steps.\nIn the following code chunk, we use st_transform() of sf package to perform the projection transformation.\n\nnga_wp <- st_transform(nga_wp,\n                       crs = 26391)\n\n\n\n6.2 Saving the Analytical Data Table\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")\n\n\n\n6.3 Performing Feature Engineering\nWe will tabulate the proportion of each type of water points against the total number of water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive these additional fields.\n\nnga_wp <- read_rds(\"geodata/nga_wp.rds\")\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_nonfunctional = wp_nonfunctional/total_wp) %>% \n    mutate(pct_handpump = wp_handpump/total_wp) %>% \n    mutate(pct_lowusage = wp_low_usage/total_wp) %>% \n    mutate(pct_highusage = wp_high_usage/total_wp) %>% \n    mutate(pct_rural = wp_rural/total_wp) %>% \n    mutate(pct_pay = wp_pay/total_wp) %>% \n    mutate(pct_crucial = wp_crucial/total_wp)\n\nAs we performed a division in the previous step, we will want to check if there is any NA values in the columns for pct_functional and pct_nonfunctional.\n\nif (any(is.na(nga_wp$pct_functional))){print(\"NA values in pct_functional\")}\n\n[1] \"NA values in pct_functional\"\n\nif (any(is.na(nga_wp$pct_nonfunctional))){print(\"NA values in pct_nonfunctional\")}\n\n[1] \"NA values in pct_nonfunctional\"\n\n\nFrom the printout, we are able to tell that there are NA values in both pct_functional and pct_nonfunctional columns.\nThis is likely due to 0 total water points in these LGAs. If we impute 0 into the pct_nonfunctional column for these LGAs with 0 water points, we may incorrectly regard these LGAs to have very low proportion of non-functional water points and lead to an incorrect analysis when performing spatial distribution analysis. As such, we will exclude LGAs with 0 water points from our analysis.\nIn the following code chunk, we want to calculate the number of LGAs with no water points. This is done by using nrow() to calculate the total number of LGAs in nga_wp and in nga_wp_filter.\n\nnrow(subset(nga_wp, total_wp == 0))\n\n[1] 13\n\n\nFrom the printout, we can see that there are 13 LGAs will 0 water points.\nIn the following code chunk, we retrieve only rows with non-zero total number of water points by using subset() and exclude the LGAs with 0 water points.\n\nnga_wp_filter <- subset(nga_wp, total_wp != 0)\n\nIn addition, we also want to exclude LGAs whereby the status of all their water points are unknown. This is because we are unable to deduce the number of functional or non-functional water points in these LGAs. Also, the values in the pct_functional and pct_nonfunctional columns for these LGAs are 0 which will affect our subsequent analysis like what we have discussed earlier.\nLikewise, we calculate the number of such LGAs first.\n\nnrow(subset(nga_wp_filter, total_wp == wp_unknown))\n\n[1] 8\n\n\nFor the printout, we can see that there are 8 LGAs whereby the status of all their water points are unknown.\nIn the following code chunk, we use filter() to exclude these LGAs.\n\nnga_wp <- subset(nga_wp, total_wp != wp_unknown)"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#correlation-analysis",
    "href": "take_home_ex/ex2/take-home-ex2.html#correlation-analysis",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "7 Correlation Analysis",
    "text": "7 Correlation Analysis\nIt is important for us to ensure that cluster variables are not highly correlated when we perform cluster analysis. This is because we do not want to give extra weight to variables that are highly correlated.\nWe will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation between the input variables. In the following, we have used data.frame() to transform the nga_wp_filter simple feature to a data.frame so that the geometry field is not being evaluated in the correlation plot.\n\nfilter <- select(as.data.frame(nga_wp), c(8,9,17:24))\ncluster_vars.cor = cor(filter)\ncorrplot.mixed(cluster_vars.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nIn the correlation plot above, the fatter the ellipse is, the more weakly correlated the 2 variables are. And the more the plot looks like a line, the more strongly correlated the 2 variables are.\nThe correlation plot above shows that pct_handpump, pct_lowusage, pct_highusage are highly correlated. This suggest that only one of them should be used in the cluster analysis. In the subsequent analysis, we will only keep pct_handpump out of the 3 variables.\nWe can visualise the how the clustering variables vary for the LGAs by plotting choropleth maps as shown in the following code chunk.\n\nwp_fun_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"wp_functional\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Num of Fuctional\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5)\n\nwp_nonfun_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"wp_nonfunctional\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Num of Non-Functional\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\npct_fun_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_functional\",\n          n = 5,\n          style = \"jenks\", \n          title = \"PCT Fuctional\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\npct_nonfun_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_nonfunctional\",\n          n = 5,\n          style = \"jenks\",\n          title = \"PCT Non-Functional\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\nlowusage_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_lowusage\",\n          n = 5,\n          style = \"jenks\", \n          title = \"PCT Low Usage\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\nrural_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_rural\",\n          n = 5,\n          style = \"jenks\",\n          title = \"PCT Rural\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\npay_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_pay\",\n          n = 5,\n          style = \"jenks\", \n          title = \"PCT Need Payment\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5) \n\ncrucial_map <- tm_shape(nga_wp) + \n  tm_fill(col = \"pct_crucial\",\n          n = 5,\n          style = \"jenks\",\n          title = \"PCT Crucial\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(legend.text.size = 0.5)\n\ntmap_arrange(wp_fun_map, wp_nonfun_map, pct_fun_map, pct_nonfun_map, lowusage_map,\n             rural_map, pay_map, crucial_map,\n             ncol=2, nrow = 4)"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#hierarchical-cluster-analysis",
    "href": "take_home_ex/ex2/take-home-ex2.html#hierarchical-cluster-analysis",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "8 Hierarchical Cluster Analysis",
    "text": "8 Hierarchical Cluster Analysis\nIn this section, we will perform hierarchical cluster analysis.\n\n8.1 Extracting cluster variables\nIn the following code chunk, we are extracting the clustering variables from the nga_wp_filter simple feature object into a data.frame. We will exclude both the pct_lowusage and pct_highusage variables. We will also remove the geometry field by setting it to null (as we will not be able to exclude the geometry column by using select().\n\ncluster_vars <- nga_wp %>%\n  st_set_geometry(NULL) %>%\n  select(\"shapeName\", \"wp_functional\", \"wp_nonfunctional\", \"pct_functional\", \"pct_nonfunctional\", \"pct_lowusage\", \"pct_rural\", \"pct_pay\", \"pct_crucial\")\nhead(cluster_vars,5)\n\n  shapeName wp_functional wp_nonfunctional pct_functional pct_nonfunctional\n1 Aba North             7                9      0.4117647         0.5294118\n2 Aba South            29               35      0.4084507         0.4929577\n4     Abaji            23               34      0.4035088         0.5964912\n5      Abak            23               25      0.4791667         0.5208333\n6 Abakaliki            82               42      0.3519313         0.1802575\n  pct_lowusage  pct_rural   pct_pay pct_crucial\n1   0.17647059 0.00000000 0.9411765   0.4705882\n2   0.12676056 0.05633803 0.8732394   0.3239437\n4   0.40350877 0.84210526 0.6315789   0.5614035\n5   0.08333333 0.83333333 0.9375000   0.7500000\n6   0.90557940 0.87553648 0.5278970   0.1502146\n\n\nNext, we will use the LGA name as the row names instead of using the row number. In this way, we will preserve the LGA name in our dataframe and still, the LGA names will not be used as a clustering variable.\n\nrow.names(cluster_vars) <- cluster_vars$\"shapeName\"\nhead(cluster_vars,5)\n\n          shapeName wp_functional wp_nonfunctional pct_functional\nAba North Aba North             7                9      0.4117647\nAba South Aba South            29               35      0.4084507\nAbaji         Abaji            23               34      0.4035088\nAbak           Abak            23               25      0.4791667\nAbakaliki Abakaliki            82               42      0.3519313\n          pct_nonfunctional pct_lowusage  pct_rural   pct_pay pct_crucial\nAba North         0.5294118   0.17647059 0.00000000 0.9411765   0.4705882\nAba South         0.4929577   0.12676056 0.05633803 0.8732394   0.3239437\nAbaji             0.5964912   0.40350877 0.84210526 0.6315789   0.5614035\nAbak              0.5208333   0.08333333 0.83333333 0.9375000   0.7500000\nAbakaliki         0.1802575   0.90557940 0.87553648 0.5278970   0.1502146\n\n\nWe can then delete the column for shapeName.\n\nnga_wp_cluster <- select(cluster_vars, c(2:9))\nhead(nga_wp_cluster, 5)\n\n          wp_functional wp_nonfunctional pct_functional pct_nonfunctional\nAba North             7                9      0.4117647         0.5294118\nAba South            29               35      0.4084507         0.4929577\nAbaji                23               34      0.4035088         0.5964912\nAbak                 23               25      0.4791667         0.5208333\nAbakaliki            82               42      0.3519313         0.1802575\n          pct_lowusage  pct_rural   pct_pay pct_crucial\nAba North   0.17647059 0.00000000 0.9411765   0.4705882\nAba South   0.12676056 0.05633803 0.8732394   0.3239437\nAbaji       0.40350877 0.84210526 0.6315789   0.5614035\nAbak        0.08333333 0.83333333 0.9375000   0.7500000\nAbakaliki   0.90557940 0.87553648 0.5278970   0.1502146\n\n\nNow that our data.frame only contains clustering variables as attributes, we can perform clustering using this data.frame.\n\n\n8.2 Data standardisation\nNext, we will evaluate the need for data standardisation. The purpose of the data standardisation is to avoid using variables with vastly different range of values as cluster analysis would be biased towards clustering variables with larger values.\nIn the following code chunk, we want to plot the range of values across all variables using boxplot.\n\nggplot(stack(nga_wp_cluster), aes(x=values, y=ind)) +\n    geom_boxplot()\n\n\n\n\nWe can see that the range of the values across all variables differ quite significantly, as such, we will need to perform data standardisation.\nThere are 2 common approaches to perform data standardisation, namely min-max scaling and z-score standardisation. With Min-Max scaling, we scale the data values for each variable to a range of 0 to 1. With Z-score standardisation, we will scale each variable to have mean to be 0 and standard deviation to be 1. However, z-score standardisation assumes that all variables come from a normal distribution.\n\n8.2.1 Visualising graphical distribution of variable values\nWe use the following code chunk to plot the distribution of the variable values to understand if the variables follow a normal distribution.\n\nfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`wp_functional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nnonfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`wp_nonfunctional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npct_funct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_functional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npct_nonfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_nonfunctional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nlowusage <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_lowusage`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nrural <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_rural`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ncrucial <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_crucial`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npay <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_pay`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nggarrange(funct, nonfunct, pct_funct, pct_nonfunct, lowusage, rural, crucial,\n          pay,\n          ncol = 4,\n          nrow = 2)\n\n\n\n\nWe observe that the distribution of most of the variables are skewed and do not follow a normal distribution. For instance, wp_functional has a right skew. As such, it is not suitable to use the Z-score normalisation.\n\n\n8.2.2 Min-Max standardisation\nIn the code chunk below, we will standardise the clustering variables by using Min-Max method.\nTo perform this, we use normalize() from the heatmaply package. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nnga_wp.std <- normalize(nga_wp_cluster)\nsummary(nga_wp.std)\n\n wp_functional     wp_nonfunctional  pct_functional   pct_nonfunctional\n Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:0.02394   1st Qu.:0.05036   1st Qu.:0.3381   1st Qu.:0.2260   \n Median :0.06383   Median :0.12590   Median :0.4808   Median :0.3636   \n Mean   :0.09207   Mean   :0.15380   Mean   :0.5123   Mean   :0.3693   \n 3rd Qu.:0.11835   3rd Qu.:0.22302   3rd Qu.:0.6780   3rd Qu.:0.5085   \n Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   \n  pct_lowusage      pct_rural         pct_pay        pct_crucial    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.4118   1st Qu.:0.6176   1st Qu.:0.6564   1st Qu.:0.1948  \n Median :0.6772   Median :0.8755   Median :0.8806   Median :0.3462  \n Mean   :0.6162   Mean   :0.7441   Mean   :0.8018   Mean   :0.3990  \n 3rd Qu.:0.8718   3rd Qu.:1.0000   3rd Qu.:0.9910   3rd Qu.:0.5714  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\nWe can observe that the value range for each variable is now between 0 and 1 after min-max standardisation is performed.\nIn the following code chunk, we want to plot the boxplots of our standardised variables.\n\nggplot(stack(nga_wp.std), aes(x=values, y=ind)) +\n    geom_boxplot()\n\n\n\n\nWe can that the values of all the variables now have the same range of 0 to 1.\n\n\n\n8.3 Computing the proximity matrix\nIn R, there are many packages that provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is the euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using the euclidean method.\n\nproxmat <- dist(nga_wp.std, method = 'euclidean')\n\n\n\n8.4 Computing the hierarchical clustering and selecting the optimal clustering algorithm\nThere are several ways to compute hierarchical clustering. This is because of the different linkage methods available to calculate the distance between clusters. The following provides explanations of 4 of the methods:\n\nAverage: Average linkage calculates all pairwise distances between cases in two clusters and finds the mean.\nSingle: Single linkage calculates the smallest distance between clusters.\nComplete: Complete linkage calculates the largest distance between clusters.\nWard: Ward’s method calculates the within-cluster sum of squares for each candidate merge and chooses the one with the smallest value.\n\nThe calculation involved in each algorithm is illustrated in the following diagram. [3]\n\nWe will use agnes() function from cluster package to perform hierarchical clustering. The advantage of using agnes() function is that we are able to get the agglomerative coefficient of the clusters obtained from each linkage calculation as described above. The agglomerative coefficient measures the amount of clustering structure found. The closer the coefficient is to 1, the stronger the clustering structure.\nIn the following code chunk, we will compute the agglomerative coefficient of the 4 hierarchical clustering algorithms: average, single, complete, and ward.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(nga_wp.std, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8524337 0.7438841 0.9172081 0.9818351 \n\n\nWe can see that Ward’s method provides the strongest clustering structure among the four algorithms assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n8.5 Determining the optimal number of clusters\nWe will determine the optimal number of clusters using a gap statistic.\n\n8.5.1 Gap statistic method\nThe gap statistic compares the total intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be the value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is furthest away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used. We will set seed 12345 to make the results reproducible as the calculations involve bootstrapping via Monte Carlo simulations. In the following code chunk, we have specified the number of Monte Carlo samples to be 50 (argument B).\n\nset.seed(12345)\ngap_stat <- clusGap(nga_wp.std, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = nga_wp.std, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 10\n          logW   E.logW       gap      SE.sim\n [1,] 5.091646 5.656593 0.5649472 0.006537434\n [2,] 4.980636 5.556008 0.5753712 0.009257900\n [3,] 4.882804 5.504556 0.6217523 0.009569719\n [4,] 4.803709 5.460590 0.6568811 0.009639142\n [5,] 4.726012 5.423250 0.6972383 0.009330416\n [6,] 4.676814 5.390737 0.7139238 0.009701430\n [7,] 4.644868 5.362836 0.7179680 0.009421233\n [8,] 4.618385 5.337163 0.7187785 0.008867952\n [9,] 4.589876 5.313976 0.7241001 0.008323950\n[10,] 4.562514 5.293071 0.7305569 0.008225253\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nThe results above reflect that the optimal number of clusters is 9.\n\n\n\n8.6 Visually-driven hierarchical clustering analysis\nWe can visualise the hierarchical clusters as a heatmap of the variables by using the heatmaply package. We will plot an interactive cluster heatmap for our visualisation.\nWe will first have to convert our data (which is in a data frame) into a data matrix to plot the heatmap. The code chunk below transforms the nga_wp.std data frame into a data matrix.\n\nnga_wp_mat <- data.matrix(nga_wp.std)\n\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(nga_wp_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 9,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 2,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of LGA by water point indicators\",\n          xlab = \"Water point indicators\",\n          ylab = \"LGA Names\"\n          )\n\n\n\n\n\nWe noticed several characteristics of the clusters (on going down the dendrogram):\n\n\n\n\n\n\n\n\nCluster\nColor on dendrogram\nSummary of key characteristics\n\n\n\n\n1\nDark Pink\n\nLow pct_pay\nHigh pct_crucial\n\n\n\n2\nPurple\n\nModerate to high pct_nonfunctional\nLow pct_functional\n\n\n\n3\nBlue\n\nModerate to high pct_nonfunctional\nLow pct_lowusage\nHigh pct_crucial\n\n\n\n4\nDark green\n\nHigh pct_functional\nLow pct_lowusage\nHigh pct_crucial\n\n\n\n5\nGreen\n\nHigh pct_lowusage\nHigh pct_functional\n\n\n\n6\nLight green\n\nLow to moderate pct_lowusage\n\n\n\n7\nYellow\n\nModerate pct_lowusage\nModerate pct_rural\nModerate pct_pay\n\n\n\n8\nOrange\n\nLow pct_rural\n\n\n\n9\nPink\n\nMostly moderate to high pct_functional\nHigh pct_lowusage\nLow pct_crucial\n\n\n\n\nFrom the analysis above, there is a distinction between each of the clusters. Hence, we will keep the clusters as 9.\n\n\n8.7 Mapping the clusters formed\nIn this section, we will map the clusters formed. We will use cutree() of R Base to derive a 9-cluster model in the following code chunk.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\ngroups <- as.factor(cutree(hclust_ward, k=9))\n\nThe output groups is a list object containing the cluster ID for each LGA.\nTo visualise the clusters, the group object needs to be appended onto the nga_wp simple feature object. This is performed using the code chunk below, in three steps as explained in the following:\n\nas.matrix() transforms the groups list into a matrix;\ncbind() appends the groups matrix onto nga_wp simple features to produce an output that is a simple feature;\nrename() is used to rename as.matrix.groups. field to H_CLUSTER\n\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) \n\n\nnga_wp <- nga_wp%>%\n  rename(`H_CLUSTER`=`as.matrix.groups.`)\n\nWe will then use qtm() from tmap package to plot the choropleth map to show the clusters.\n\nqtm(nga_wp, \"H_CLUSTER\")+\n    tm_layout(main.title = \"Hierarchical Clustering\",\n              main.title.size = 1.2,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nThe choropleth map above reveals that the clusters are very fragmented. This is a major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis is used for regionalisation.\nWe can also get the summary for each cluster by the mean of each clustering variables as shown in the following code chunk:\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(H_CLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  H_CLUSTER wp_functio…¹ wp_no…² pct_f…³ pct_n…⁴ pct_l…⁵ pct_r…⁶ pct_pay pct_c…⁷\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 57.5   37.6    0.566   0.324   0.497   0.168   0.788   0.174\n2 2                 70.6   51.9    0.433   0.335   0.744   0.872   0.646   0.381\n3 3                 15.1   28.4    0.332   0.651   0.146   0.907   0.902   0.715\n4 4                 88.7   82.9    0.478   0.476   0.626   0.849   0.905   0.226\n5 5                 14.7   23.4    0.257   0.483   0.340   0.392   0.670   0.748\n6 6                 29.1    5.94   0.833   0.140   0.202   0.710   0.909   0.467\n7 7                 38.6   50.8    0.443   0.527   0.751   0.933   0.931   0.554\n8 8                 13.3   11.0    0.203   0.172   0.712   0.707   0.288   0.789\n9 9                160.    33.0    0.812   0.185   0.874   0.905   0.969   0.224\n# … with abbreviated variable names ¹​wp_functional, ²​wp_nonfunctional,\n#   ³​pct_functional, ⁴​pct_nonfunctional, ⁵​pct_lowusage, ⁶​pct_rural,\n#   ⁷​pct_crucial"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#spatially-constrained-clustering-skater-approach",
    "href": "take_home_ex/ex2/take-home-ex2.html#spatially-constrained-clustering-skater-approach",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "9 Spatially Constrained Clustering: SKATER Approach",
    "text": "9 Spatially Constrained Clustering: SKATER Approach\nIn this section, we will derive spatially constrained clusters by using skater() method from spdep package.\n\n9.1 Converting data into SpatialPolygonsDataFrame\nWe will first need to convert nga_wp into a SpatialPolygonsDataFrame. This is because the SKATER function only supports sp objects such as the SpatialPolygonsDataFrame. We will perform this using as_Spatial() from sf package.\n\nnga_sp <- as_Spatial(nga_wp)\n\n\n\n9.2 Computing neighbour list\nNext, we will use poly2nb() from spdep package to compute the neighbours list object from the polygon list.\n\nnga.nb <- poly2nb(nga_sp)\nsummary(nga.nb)\n\nNeighbour list object:\nNumber of regions: 753 \nNumber of nonzero links: 4306 \nPercentage nonzero weights: 0.7594236 \nAverage number of links: 5.718459 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  19  54 121 175 136 122  68  39  11   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nWe can draw a graph representation of the neighbour structure. In the following code, we will plot the area boundaries first. This is followed by the plot of the neighbour list object. We also set the colour to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(nga_sp, \n     border=grey(.5))\nplot(nga.nb, \n     coordinates(nga_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n9.3 Computing minimum spanning tree\nThe SKATER algorithm uses a minimum spanning tree (MST) for the records in its calculation. The MST is a graph that includes all nodes in the network but only passes each node once. This way, the complexity of the graph is minimised since each node is connected to only one other node. The resulting tree has n nodes and n-1 edges. The objective of the calculation is to minimise the overall length (or cost) of the tree. This cost can be regarded as the distances between the nodes.\n\n9.3.1 Calculating edge costs\nWe will first need to compute the edge cost associated with each edge in the neighbour list. This cost refers to the dissimilarity between each pair of neighbours (as defined by the neighbours list). The following code chunk is used to compute the cost of each edge.\n\nlcosts <- nbcosts(nga.nb, nga_wp.std)\nhead(lcosts)\n\n[[1]]\n[1] 0.2076065 1.1530899 0.8947909 1.2052173\n\n[[2]]\n[1] 0.2076065 0.8921187 1.2167456\n\n[[3]]\n[1] 0.6560673 0.4979778 0.3962916 0.2315877 0.4816761 0.8372297 0.3884884\n\n[[4]]\n[1] 0.2442841 0.2488396 0.2128474 0.5014532 0.2767833\n\n[[5]]\n[1] 0.3687666 0.2284805 0.2303748 0.2652510 0.5847221 0.5444482 0.4443433\n\n[[6]]\n[1] 0.4345994 0.9122569 1.0792675 0.6983658 1.3413376 0.9867793\n\n\nFor each LGA, this gives the pairwise dissimilarity between its values on the eight clustering variables and its neighbour’s corresponding values. Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, we will convert the neighbour list to a list weights object by using the computed lcosts as the weights. To do this, we use nb2listw() of spdep package as shown in the code chunk below. We need to specify the style as B to make sure the cost values are not row-standardised.\n\nnga.w <- nb2listw(nga.nb,\n                  lcosts,\n                  style=\"B\")\nsummary(nga.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 753 \nNumber of nonzero links: 4306 \nPercentage nonzero weights: 0.7594236 \nAverage number of links: 5.718459 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  19  54 121 175 136 122  68  39  11   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\nWeights style: B \nWeights constants summary:\n    n     nn       S0       S1      S2\nB 753 567009 2429.924 3412.771 37813.4\n\n\n\n\n9.3.2 Computing minimum spanning tree\nThe minimium spanning tree is computed by mean of the mstree() from spdep package as shown in the code chunk below. The result is a special type of matrix and it summarises the tree by giving each edge as the pair of connected nodes and the cost associated with that edge.\n\nnga.mst <- mstree(nga.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(nga.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(nga.mst)\n\n[1] 752   3\n\n\nWe can see that the dimension is 752 instead of 753 (i.e. the total number of LGAs considered for clustering). This is because the minimum spanning tree consists of n-1 edges that traverses all the nodes.\nWe can display the content using head() as shown in the following code chunk.\n\nhead(nga.mst)\n\n     [,1] [,2]      [,3]\n[1,]  120  294 0.2397947\n[2,]  120  572 0.2555644\n[3,]  572  604 0.3290324\n[4,]  604  166 0.3269686\n[5,]  572  591 0.3336202\n[6,]  572  345 0.3790881\n\n\n\n\n\n9.4 Computing spatially constrained clusters using SKATER method\nThe skater() function takes three mandatory arguments: the first two columns of the MST matrix (i.e. not the costs), the standardized data matrix (to update the costs as units are being grouped), and the number of cuts. The value specified for the number of cuts is not the number of clusters, but instead, the number of cuts in the graph, i.e. one less than the number of clusters.\n\nclust9 <- spdep::skater(edges = nga.mst[,1:2], \n                 data = nga_wp.std, \n                 method = \"euclidean\", \n                 ncuts = 8)\n\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust9)\n\nList of 8\n $ groups      : num [1:753] 2 2 1 2 4 5 5 4 2 2 ...\n $ edges.groups:List of 9\n  ..$ :List of 3\n  .. ..$ node: num [1:181] 644 89 119 23 506 460 474 214 247 631 ...\n  .. ..$ edge: num [1:180, 1:3] 623 490 233 732 179 619 344 735 572 214 ...\n  .. ..$ ssw : num 84.6\n  ..$ :List of 3\n  .. ..$ node: num [1:198] 568 605 60 575 59 153 540 297 205 354 ...\n  .. ..$ edge: num [1:197, 1:3] 297 59 575 540 60 354 505 153 530 184 ...\n  .. ..$ ssw : num 110\n  ..$ :List of 3\n  .. ..$ node: num [1:173] 487 405 374 658 256 225 509 107 160 458 ...\n  .. ..$ edge: num [1:172, 1:3] 458 464 746 434 668 710 151 128 254 372 ...\n  .. ..$ ssw : num 78.7\n  ..$ :List of 3\n  .. ..$ node: num [1:16] 512 351 556 211 580 13 555 525 17 5 ...\n  .. ..$ edge: num [1:15, 1:3] 556 556 555 164 525 580 351 211 17 5 ...\n  .. ..$ ssw : num 5.3\n  ..$ :List of 3\n  .. ..$ node: num [1:55] 559 14 80 341 170 208 523 577 630 305 ...\n  .. ..$ edge: num [1:54, 1:3] 577 305 577 630 306 265 537 305 523 170 ...\n  .. ..$ ssw : num 26.5\n  ..$ :List of 3\n  .. ..$ node: num [1:47] 744 61 453 403 396 450 86 621 738 471 ...\n  .. ..$ edge: num [1:46, 1:3] 403 450 396 86 738 441 441 621 471 381 ...\n  .. ..$ ssw : num 16.6\n  ..$ :List of 3\n  .. ..$ node: num [1:42] 55 75 707 598 22 280 516 183 281 209 ...\n  .. ..$ edge: num [1:41, 1:3] 22 516 280 183 558 707 598 298 281 280 ...\n  .. ..$ ssw : num 22.2\n  ..$ :List of 3\n  .. ..$ node: num [1:27] 480 154 483 666 493 655 67 241 136 237 ...\n  .. ..$ edge: num [1:26, 1:3] 483 493 67 655 136 237 237 67 237 96 ...\n  .. ..$ ssw : num 15.3\n  ..$ :List of 3\n  .. ..$ node: num [1:14] 50 602 48 286 672 201 315 21 496 447 ...\n  .. ..$ edge: num [1:13, 1:3] 50 201 672 286 672 602 315 50 315 602 ...\n  .. ..$ ssw : num 4.83\n $ not.prune   : NULL\n $ candidates  : int [1:9] 1 2 3 4 5 6 7 8 9\n $ ssto        : num 463\n $ ssw         : num [1:9] 463 432 415 400 390 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:753] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector that contains the labels of the cluster to which each observation belongs . This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment using the following.\n\nccs9 <- clust9$groups\nccs9\n\n  [1] 2 2 1 2 4 5 5 4 2 2 1 1 4 5 1 5 4 2 1 1 9 7 1 2 2 2 1 1 1 1 9 3 2 5 6 2 1\n [38] 1 2 1 2 2 1 1 1 3 1 9 3 9 7 7 7 2 7 2 2 3 2 2 6 1 1 2 1 2 8 1 1 5 5 1 3 6\n [75] 7 7 7 7 3 5 3 1 3 3 3 6 6 6 1 1 6 3 3 3 3 8 3 2 2 2 3 1 6 3 1 3 3 3 1 3 8\n[112] 1 3 2 6 1 2 2 1 1 1 2 3 3 3 3 1 3 2 2 1 2 2 1 3 8 3 3 3 6 3 3 1 3 1 3 6 3\n[149] 3 3 3 2 2 8 3 1 6 6 7 3 3 3 2 4 1 1 1 1 1 5 5 5 1 2 2 1 2 2 1 1 1 1 7 2 2\n[186] 1 7 7 7 5 2 2 2 2 2 2 2 2 2 2 9 2 2 2 2 2 2 5 7 2 4 4 3 1 3 3 8 6 3 3 3 1\n[223] 3 3 3 8 3 3 3 6 6 3 1 2 3 3 8 3 2 6 8 1 1 3 2 3 1 1 3 3 8 1 1 3 1 3 3 2 2\n[260] 3 3 8 8 5 5 5 5 5 2 5 5 5 5 2 2 6 2 2 1 7 7 7 7 5 1 9 1 1 1 1 1 1 1 1 5 3\n[297] 2 7 7 7 2 7 2 5 5 5 5 1 1 2 2 2 3 2 9 5 1 1 2 2 5 2 2 2 2 4 2 1 2 1 1 1 1\n[334] 1 1 1 1 5 3 2 5 2 5 1 1 1 5 3 1 5 4 2 2 2 2 1 2 5 2 2 2 3 5 2 2 5 5 4 1 8\n[371] 3 3 6 3 1 1 3 3 6 6 6 1 3 1 3 3 3 3 1 1 3 5 3 1 6 6 3 6 3 3 3 3 6 1 3 1 3\n[408] 2 3 1 3 1 3 2 1 1 2 3 3 3 3 3 1 1 1 2 3 2 1 9 3 3 1 3 3 3 3 6 3 1 6 2 1 8\n[445] 1 5 9 9 8 6 6 1 6 1 3 2 1 3 3 1 3 3 3 3 8 1 3 1 3 3 6 3 3 1 3 3 1 3 3 8 2\n[482] 2 8 3 6 3 3 2 1 1 1 1 8 8 3 9 1 6 3 3 1 1 2 2 2 1 2 3 3 7 7 4 7 7 7 7 2 2\n[519] 2 7 8 2 5 2 4 2 2 2 1 2 2 2 2 5 2 1 5 2 1 2 2 2 2 2 1 1 1 2 2 2 5 2 2 2 4\n[556] 4 2 7 5 4 1 1 1 2 2 2 2 2 2 1 2 1 5 5 2 2 5 1 1 4 7 2 2 2 2 5 2 1 1 7 1 2\n[593] 7 2 2 2 7 7 2 2 2 9 2 1 2 2 2 2 2 2 2 2 1 1 7 2 5 5 1 1 6 2 1 2 3 6 3 1 3\n[630] 5 1 3 3 3 6 3 3 3 1 3 3 2 1 1 5 3 1 2 6 5 1 1 8 3 8 6 3 3 1 6 9 1 3 1 1 8\n[667] 2 3 1 3 1 9 1 1 3 2 3 6 3 1 1 3 2 3 3 3 3 1 8 3 3 3 1 7 7 2 2 2 2 2 2 2 2\n[704] 2 2 2 7 2 2 3 7 2 2 2 6 2 2 7 2 1 1 3 3 2 2 2 1 6 3 6 1 1 1 1 1 2 2 6 3 1\n[741] 2 8 8 6 3 3 3 3 3 3 6 3 1\n\n\nWe can also found out the number of LGAs in each cluster by means of the table() command.\n\ntable(ccs9)\n\nccs9\n  1   2   3   4   5   6   7   8   9 \n181 198 173  16  55  47  42  27  14 \n\n\n\n\n9.5 Visualising the clusters on a choropleth map\nFinally, we can illustrate the clustering on the map.\n\ngroups_mat <- as.matrix(clust9$groups)\nnga_wp <- cbind(nga_wp, as.factor(groups_mat)) %>%\n  rename(`Skater_CLUSTER`=`as.factor.groups_mat.`)\nqtm(nga_wp, \"Skater_CLUSTER\")+\n    tm_layout(main.title = \"SKATER Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nLikewise, we can get a summary of the water point attributes for each cluster using the following code chunk.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(Skater_CLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  Skater_CLUSTER wp_fu…¹ wp_no…² pct_f…³ pct_n…⁴ pct_l…⁵ pct_r…⁶ pct_pay pct_c…⁷\n  <fct>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 69.0   60.2    0.506   0.438   0.650  0.736    0.877   0.275\n2 2                 25.2   34.3    0.381   0.503   0.377  0.797    0.830   0.585\n3 3                144.    41.8    0.757   0.237   0.806  0.821    0.931   0.254\n4 4                102.    55.1    0.407   0.222   0.914  0.940    0.602   0.254\n5 5                 44.4   36.7    0.396   0.310   0.524  0.534    0.631   0.379\n6 6                 88.8   79.4    0.415   0.400   0.844  0.866    0.689   0.380\n7 7                 11.2    9.52   0.270   0.220   0.649  0.528    0.374   0.690\n8 8                 16.5    4.33   0.716   0.284   0.651  0.730    0.894   0.607\n9 9                 37.5    9.93   0.665   0.135   0.315  0.0147   0.634   0.198\n# … with abbreviated variable names ¹​wp_functional, ²​wp_nonfunctional,\n#   ³​pct_functional, ⁴​pct_nonfunctional, ⁵​pct_lowusage, ⁶​pct_rural,\n#   ⁷​pct_crucial\n\n\nFor easier comparison, we will plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other using the code chunk below.\n\nhclust.map <- qtm(nga_wp,\n                  \"H_CLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"Hierarchical Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nskclust.map <- qtm(nga_wp,\n                   \"Skater_CLUSTER\") + \n  tm_borders(alpha = 0.5)+\n    tm_layout(main.title = \"SKATER Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(hclust.map, skclust.map,\n             asp=NA, ncol=2)\n\n\n\n\nAs expected, the clusters formed from spatially constrained clustering is much more geographically cohesive compared to those formed from hierarchical clustering."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#spatially-constrained-clustering-using-clustgeo",
    "href": "take_home_ex/ex2/take-home-ex2.html#spatially-constrained-clustering-using-clustgeo",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "10 Spatially Constrained Clustering using ClustGeo",
    "text": "10 Spatially Constrained Clustering using ClustGeo\nClustGeo package implements a Ward-like hierarchical clustering algorithm that includes spatial/geographical constraints. The algorithm takes in two dissimilarity matrices D0 and D1, along with a mixing parameter alpha in that ranges from 0 to 1 (both inclusive). The dissimilarities can be non-Euclidean and the weights of the observations can be non-uniform. The first matrix gives the dissimilarities in the variable space and the second matrix gives the dissimilarities in the spatial space. The idea is to determine a value of alpha which increases the spatial contiguity without deteriorating too much on the quality of the solution calculated based on the variables.\n\n10.1 Ward-like hierarchical clustering: ClustGeo\nThe ClustGeo package provides the function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() that was used in section 8.8.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the dissimilarity matrix as shown in the following code chunk. The dissimilarity matrix provided here must be an object of class dist, i.e. an object that is obtained using dist().\n\nnongeo_cluster <- hclustgeo(proxmat)\n\n\n10.1.1 Mapping the clusters formed\nSimilarly, we can visualise the clusters on the map.\n\ngroups <- as.factor(cutree(nongeo_cluster, k=9))\n\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_HCLUSTER` = `as.matrix.groups.`)\n\n\nqtm(nga_wp, \"ClustG_HCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Hierarchical Clustering\",\n              main.title.size = 1.1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nAgain, the choropleth map above reveals that the clusters formed by using hierarchical analysis are very fragmented spatially.\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_HCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_HCLUS…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 56.4   33.8    0.606  0.316    0.445   0.169   0.830   0.153\n2 2                 47.3   48.1    0.472  0.482    0.460   0.919   0.870   0.373\n3 3                 14.8   27.8    0.334  0.650    0.144   0.895   0.905   0.722\n4 4                 89.8   74.6    0.430  0.371    0.793   0.844   0.710   0.314\n5 5                 18.8   21.2    0.275  0.357    0.510   0.328   0.541   0.652\n6 6                 14.5   11.6    0.222  0.187    0.680   0.807   0.308   0.775\n7 7                 40.2   47.7    0.475  0.494    0.829   0.920   0.930   0.579\n8 8                 25.5    2.74   0.927  0.0700   0.249   0.846   0.965   0.535\n9 9                161.    34.6    0.807  0.191    0.879   0.888   0.971   0.215\n# … with abbreviated variable names ¹​ClustG_HCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\n\n\n\n10.2 Spatially Constrained (by Distance) Hierarchical Clustering\nNext, we will perform clustering with spatial constraints. We will first need to compute a spatial matrix by using st_distance() from sf package. The function as.dist() is used to convert the data frame into a matrix.\n\ndist <- st_distance(nga_wp, nga_wp)\ndistmat <- as.dist(dist)\n\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=9, graph = TRUE)\n\n\n\n\n\n\n\nThe parameter alpha in [0,1] sets the importance of D0 and D1 in the clustering process. When alpha=0, the geographical dissimilarities are not taken into account and when alpha=1 the distances between water point attributes are not taken into account and the clusters are obtained with the geographical distances only.\nWe can also derive the exact proportion of explained inertia using the code chunk below. The homogeneity Q0 is the proportion of explained inertia calculated with D0 (likewise Q1 for D1).\n\ncr$Q\n\n                 Q0        Q1\nalpha=0   0.6197622 0.3242964\nalpha=0.1 0.6109510 0.4270533\nalpha=0.2 0.5633979 0.6280446\nalpha=0.3 0.5229639 0.7638126\nalpha=0.4 0.5328042 0.7663211\nalpha=0.5 0.5116800 0.8185793\nalpha=0.6 0.4292704 0.8690167\nalpha=0.7 0.3967863 0.8945010\nalpha=0.8 0.3648866 0.9140518\nalpha=0.9 0.2866144 0.9302453\nalpha=1   0.2474455 0.9383978\n\n\nThe plot and results show that the proportion of explained inertia with D0 (the water point attributes) is equal to 0.62 when alpha=0 and decreases when alpha increases (black line). On the other hand, the proportion of explained inertia calculated with D1 (the spatial distances) is equal to 0.94 when alpha=1 and decreases when alpha decreases (red line).\nHere, the results suggest to use alpha=0.2 which corresponds to a lost of water point attributes homogeneity by 6% and a significant gain in spatial homogeneity by 30%.\nWe will use alpha=0.2 in the following code chunk.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nNext, we will use cutree() to derive the cluster object.\n\ngroups <- as.factor(cutree(clustG, k=9))\n\nWe will then join back the group list with nga_wp polygon feature data frame by using the code chunk below.\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_SPCLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(nga_wp, \"ClustG_SPCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Spatially Constrained (by distance) Hierarchical Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_SPCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_SPCLU…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 49.6    36.5   0.565   0.343   0.410   0.182   0.815  0.167 \n2 2                 55.3    35.3   0.627   0.343   0.368   0.807   0.799  0.417 \n3 3                 21.4    30.0   0.408   0.554   0.193   0.889   0.897  0.600 \n4 4                 81.5    73.3   0.374   0.370   0.832   0.911   0.665  0.383 \n5 5                 12.9    13.0   0.242   0.274   0.574   0.556   0.431  0.748 \n6 6                 76.0    66.8   0.448   0.391   0.696   0.771   0.794  0.252 \n7 7                 27.4    59.9   0.311   0.644   0.701   0.955   0.928  0.592 \n8 8                131.     39.4   0.744   0.251   0.856   0.894   0.936  0.289 \n9 9                 82.2    38.8   0.706   0.275   0.617   0.110   0.914  0.0879\n# … with abbreviated variable names ¹​ClustG_SPCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\nAgain, for easier comparison, we will plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other using the code chunk below.\n\nHclust.map <- qtm(nga_wp,\n                  \"ClustG_HCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"ClustGeo Hierarchical Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nGclust.map <- qtm(nga_wp,\n                   \"ClustG_SPCLUSTER\") + \n  tm_borders(alpha = 0.5)+\n    tm_layout(main.title = \"ClustGeo Spatial Constrained (by Distance) Hierarchical Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(Hclust.map, Gclust.map,\n             asp=NA, ncol=2)\n\n\n\n\nWe can see that the clusters obtained by considering spatial constraints are less fragmented and has more geographical cohesion. In particular, the north west region has more geographical cohesion now (in spatially constrained hierarchical clustering).\n\n\n10.3 Contiguous Neighbour Constrained Hierarchical Clustering\nIn this section, we will attempt to improve the geographical cohesion of the clusters using ClustGeo. To do this, we will use a different matrix of dissimilarities D1 which takes into consideration the neighborhood around each LGA account rather than using the geographical distance. In this way, LGAs with contiguous boundaries (sharing one or more boundary point) are considered as neighbours. The adjacency matrix A is the binary matrix of the neighbourhoods between the LGAs.\nWe will use poly2nb() from spdep package to compute the neighbours list object from the polygon list (similar to in Section 9.2).\n\nlist.nb <- poly2nb(nga_sp)\n\nWe will then use nb2mat() from spdep package to generate a weights matrix for the neighbour list obtained. In here, we have specified the style to be binary, so LGAs with contiguous boundaries will have the value of 1 assigned, otherwise 0. We will also set the diagonal to be 1 to prepare for deriving the dissimilarity matrix in the subsequent step.\n\nA <- nb2mat(list.nb, style=\"B\")\ndiag(A) <- 1\n\nThe dissimilarity matrix D1 is then 1 minus A.\n\nD1 <- as.dist(1-A)\n\nThe procedure for the choice of alpha is repeated here with the new matrix D1.\n\ncr <- choicealpha(proxmat, D1, range.alpha = seq(0, 1, 0.1), K=9, graph = TRUE)\n\n\n\n\n\n\n\n\ncr$Q\n\n                 Q0         Q1\nalpha=0   0.6197622 0.03050810\nalpha=0.1 0.5818355 0.04097068\nalpha=0.2 0.5195099 0.05210635\nalpha=0.3 0.4896591 0.05534654\nalpha=0.4 0.4609872 0.05796505\nalpha=0.5 0.4223039 0.06021902\nalpha=0.6 0.3750095 0.06293002\nalpha=0.7 0.3596016 0.06397289\nalpha=0.8 0.3245149 0.06494931\nalpha=0.9 0.3135455 0.06501170\nalpha=1   0.2525992 0.06567767\n\n\nIn the first plot, we can see that the explained inertia calculated with D1 (red curve) is much smaller than the explained inertia calculated with D0 (black curve). To overcome this problem, we will use the second plot, i.e. the normalized proportion of explained inertia (Qnorm) instead.\nWe will also obtain the normalised proportion of explained inertia using the following code chunk.\n\ncr$Qnorm\n\n             Q0norm    Q1norm\nalpha=0   1.0000000 0.4645125\nalpha=0.1 0.9388044 0.6238144\nalpha=0.2 0.8382408 0.7933648\nalpha=0.3 0.7900759 0.8426995\nalpha=0.4 0.7438130 0.8825687\nalpha=0.5 0.6813967 0.9168873\nalpha=0.6 0.6050862 0.9581646\nalpha=0.7 0.5802251 0.9740433\nalpha=0.8 0.5236120 0.9889101\nalpha=0.9 0.5059126 0.9898600\nalpha=1   0.4075744 1.0000000\n\n\nThe plot for Qnorm and the normalised proportion of explained inertia suggests to choose alpha=0.2.\nAgain, we can derive the clusters and plot them on a choropleth.\n\nclustG <- hclustgeo(proxmat, D1, alpha = 0.2)\ngroups <- as.factor(cutree(clustG, k=9))\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_NCLUSTER` = `as.matrix.groups.`)\nqtm(nga_wp, \"ClustG_NCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Neighbourhood Constrained Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_NCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_NCLUS…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 56.9   30.4    0.617   0.306   0.442  0.0890   0.831   0.145\n2 2                 65.7   63      0.494   0.466   0.611  0.803    0.893   0.315\n3 3                 17.0   29.0    0.367   0.621   0.205  0.878    0.920   0.635\n4 4                 77.8   68.9    0.395   0.397   0.818  0.892    0.714   0.398\n5 5                 20.1   31.1    0.286   0.426   0.430  0.779    0.669   0.645\n6 6                 26.8    7.91   0.756   0.224   0.470  0.806    0.892   0.541\n7 7                 39.8   34.9    0.391   0.320   0.619  0.462    0.613   0.358\n8 8                 12.9   11.6    0.223   0.223   0.646  0.603    0.357   0.752\n9 9                164.    41.9    0.780   0.217   0.885  0.897    0.950   0.239\n# … with abbreviated variable names ¹​ClustG_NCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\nWe also want to compare the spatially constrained hierarchical clusters and the neighbourhood constrained hierarchical clusters.\n\nGclust.map <- qtm(nga_wp,\n                  \"ClustG_SPCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"ClustGeo Spatially Constrained (Distance) Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nNclust.map <- qtm(nga_wp,\n                   \"ClustG_NCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title=\"ClustGeo Neighbourhood Constrained (Contiguous) Clustering\",\n              main.title.size = 0.6,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(Gclust.map, Nclust.map,\n             asp=NA, ncol=2)\n\n\n\n\nAs expected, we can see that the neighbourhood constrained hierarchical clusters obtained are less fragmented compared to the spatially constrained hierarchical clusters. In particular, the geographical cohesion is improved in the region for cluster 2 (with reference to the map for neighbourhood constrained hierarchical clusters).\nHowever, we can also observe that the clustering process using neighbourhood constrained hierarchical clustering do not give completely geographically cohesive clusters. For instance, cluster 4 is divided spatially into 4 plots. The reason for this observation is that the clustering is based on soft contiguity constraints. This results in LGAs that are not neighbours are still allowed to be in the same clusters.\nComparing the water point attribute homogeneity obtained in the 2 clustering methods, we noticed that spatially constrained (by distance) hierarchical clusters is 56% (Q0 at alpha=0.2) which is higher than neighbourhood constrained hierarchical clusters which is at 52% (Q0 at alpha=0.2). Again, this is within expectation as neighbourhood constrained hierarchical clustering compromised water point attribute homogeneity for improved geographical cohesion."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that examines the way in which the relationships between a dependent variable and a set of predictors might vary over space. GWR operates by moving a search window from one regression point to the next, working sequentially through all the existing regression points in the data set. In this hands-on exercise, we will build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and location-based."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#the-data",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#the-data",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "2 The Data",
    "text": "2 The Data\nThere are two data sets used in this exercise and they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#getting-started",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#getting-started",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nThe R packages needed for this exercise are as follows:\n\nolsrr-R package for building OLS and performing diagnostics tests\nGWmodel- R package for calibrating geographical weighted family of models\ncorrplot- R package for multivariate data visualisation and analysis\nsf - Spatial data handling\ntidyverse, including readr, ggplot2, and dplyr - Attribute data handling\ntmap - choropleth mapping\n\nThe code chunk below installs and launches these packages into the R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#a-note-on-gwmodel",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#a-note-on-gwmodel",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4 A note on GWmodel",
    "text": "4 A note on GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, and is suitable for use in situations when data are not described well by a global model. The resulting output are mapped which provides a useful tool to explain data spatial heterogeneity. Currently, GWmodel includes functions for: GW summary statistics, GW principal components analysis, GW regression, and GW discriminant analysis."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#geospatial-data-wrangling",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5 Geospatial Data Wrangling",
    "text": "5 Geospatial Data Wrangling\n\n5.1 Importing geospatial data\nThe geospatial data in this hands-on exercise (MP14_SUBZONE_WEB_PL) is in ESRI shapefile format and contains URA Master Plan 2014’s planning subzone boundaries. These geographic boundaries are represented by polygon features. The GIS data is in svy21 projected coordinates systems.\nIn the following code chunk, we will import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\hands_on_ex\\hands_on_ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n5.2 Updating CRS information\nWe will need to updated the imported file with the correct ESPG code (i.e. 3414).\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\nWe can then verify the projection of the newly transformed mpsz_svy21 by using st_crs() from sf package.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWe can observe that the EPSG is indicated with 3414.\nWe will then reveal the extent of mpsz_svy21 by using st_bbox() from sf package.\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#aspatial-data-wrangling",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#aspatial-data-wrangling",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6 Aspatial Data Wrangling",
    "text": "6 Aspatial Data Wrangling\n\n6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data, we will use glimpse() to display its data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nNext, we will use summary() of base R to display the summary statistics of condo_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n6.2 Converting aspatial data frame into a sf object\nWe will now convert the aspatial condo_resale tibble data frame into a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() from sf package. We will then use st_transform() from sf package to convert the coordinates from wgs84 (i.e. crs=4326) to svy21 (i.e. crs=3414).\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN\n\n\nWe can see that the output is a point feature data frame."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#exploratory-data-analysis-eda",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#exploratory-data-analysis-eda",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7 Exploratory Data Analysis (EDA)",
    "text": "7 Exploratory Data Analysis (EDA)\nIn this section, we will use statistical graphic functions from ggplot2 package to perform EDA.\n\n7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using a histogram as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe plot above reveals a right skewed distribution. This means that there are more condominium units transacted at relative lower prices compared to higher prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. In the following code chunk, we will use mutate() of dplyr package to perform the log transformation.\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the log transformed variable using the following code chunk.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nWe can see that the distribution is relatively less skewed after the log transformation.\n\n\n7.2 Multiple Histogram Plots distribution of variables\nIn this section, we will generate trellis plots (i.e. small multiple histograms) by using ggarrange() from ggpubr package.\nIn the following code chink, we will create 12 histograms. ggarrange() is used to organised these histograms into a 3 columns by 4 rows multiple plot.\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n7.3 Drawing Statistical Point Map\nLastly, we want to have a view of the geographical distribution of the condominium resale prices in Singapore. This map will be prepared by using the tmap package.\nFor better viewing experience, we will turn on the interactive mode of tmap by using the following code chunk.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunks below is used to create an interactive point symbol map. We will use tm_dots() is used instead of tm_bubbles(). Also we make use of the set.zoom.limits argument of tm_view() to set the minimum and maximum zoom level to 11 and 14 respectively.\n\ntm_shape(mpsz_svy21)+\n    tmap_options(check.and.fix = TRUE)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nBefore moving on to the next section, we will turn R display back to plot mode using the following code chunk.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#hedonic-pricing-modelling-in-r",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#hedonic-pricing-modelling-in-r",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8 Hedonic Pricing Modelling in R",
    "text": "8 Hedonic Pricing Modelling in R\nIn this section, we will build hedonic pricing models for condominium resale units using lm() from R base.\n\n8.1 Simple Linear Regression Method\nWe will first build a simple linear regression model using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable. To do this, we put the dependent variable first, i.e. before the “~” sign and the independent variable after this sign.\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. In addition, effects(), fitted.values(), and residuals() functions also extract various useful features of the values returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince the p-value is much smaller than 0.0001, we will reject the null hypothesis that the mean is a good estimator of the SELLING_PRICE. This allows us to infer that the simple linear regression model we have built is a good estimator of the SELLING_PRICE.\nThe Coefficients section of the report reveals that the p-values of both the estimates of the Intercept and AREA_SQM are each smaller than 0.001. In view of this, the null hypothesis that the values of B0 and B1 are equal to 0 will be rejected. As a result, we can infer that B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe plot above reveals that there are a few statistical outliers that have relatively high selling prices.\n\n\n8.2 Multiple Linear Regression Model\n\n8.2.1 Visualising the relationships of the independent variables\nBefore we build a multiple regression model, it is important to ensure that the independent variables used are not highly correlated to each other (known as multicollinearity) to avoid compromising the resulting regression model.\nIn this section, we will use the corrplot package to visualise the relationships between the independent variables. The code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\",\n         number.cex = 0.4)\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in the matrix. THis allows variables that are relatively more correlated to be placed adjacent to each other in the correlation plot, allowing us to visualise their correlation (if any) more easily. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. As such, we will only include either one of them for model building. We will exclude LEASE_99YEAR from the subsequent model building steps.\n\n\n\n8.3 Building a hedonic pricing model using multiple linear regression method\nWe will use the following code chunk using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\n\n\n8.4 Preparing Publication Quality Table: olsrr method\nWe can see from the report that not all independent variables are statistically significant. As such, we will revise the model by removing the variables which are not statistically significant.\nIn the following code chunk, we will keep the variables that are statistically significant.\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                   PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                   FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith the gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() . In the following code chunk, we will demonstrate using add_glance_source_note().\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n8.5.1 Checking for multicollinearity\nIn this section, we will employ the methods from the olsrr package which is specially designed to perform OLS regression. It provides the following methods to support building better multiple regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() from olsrr package is used to test for multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF values obtained for the independent variables are less than 10, we can conclude that there is no sign of multicollinearity among the independent variables.\n\n\n8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important to confirm the linearity and additivity relationship between the dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe plot above reveals that most data points are scattered around the 0 line. As such, we can conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.5.3 Test for Normality Assumption\nWe will also use ols_plot_resid_hist() from olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure above suggests that the residual of the multiple linear regression model (i.e. condo.mlr1) follows a normal distribution.\nAlternatively, we can perform formal statistical test methods, such as the ols_test_normality() from olsrr package as shown in the code chunk below.\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are much smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model that we are trying to build uses geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model spatially.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nWe will then convert condo_resale.res.sf from a simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nWe will use the following code chunk to perform the data conversion.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nAgain, we will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunk below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nWe will switch the mode back to “plot” before continuing.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo validate our observation, we will perform the Moran's I test.\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function from spdep.\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nWe will then use lm.morantest() from spdep package to perform Moran's I test for residual spatial autocorrelation.\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran's I test for residual spatial autocorrelation shows that it's p-value is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.144 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "hands_on_ex/hands_on_ex4/hands_on_ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-On Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9 Building Hedonic Pricing Models using GWmodel",
    "text": "9 Building Hedonic Pricing Models using GWmodel\nIn this section, we will model hedonic prices using both fixed and adaptive bandwidth scheme.\n\n9.1 Building Fixed Bandwidth GWR Model\n\n9.1.1 Computing fixed bandwidth\nbw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Optimal fixed bandwidth is specified by setting the argument adaptive to FALSE.\nThe approach argument defines the stopping rule. There are two possible approaches can be used to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach.\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE +\n                     PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n                     PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                     PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                     FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe results shows that the recommended bandwidth is 971.3405 metres. The unit of measurement is metre because the unit of measurement for the projection we are using, i.e. CRS = 3414 is in metre.\n\n\n9.1.2 GWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                           PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                           PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                           PROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\n                           PROX_BUS_STOP + NO_Of_UNITS + \n                           FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class \"gwrm\". The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-09 21:01:48 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-09 21:01:50 \n\n\nThe report shows that the adjusted r-square of the gwr is 0.8430 which is significantly better than the globel multiple linear regression model of 0.6472.\n\n\n\n9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n9.2.1 Computing the adaptive bandwidth\nTo use the adaptive badnwidth approach, we will specify the adaptive argument to TRUE.\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe results show that 30 is the recommended number of data points to be used.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nWe will now calibrate calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\n                            PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                            FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe following code displays the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-09 21:01:58 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-09 21:02:00 \n\n\nThe report shows that the adjusted r-square of the gwr is 0.8561 which is significantly better than the global multiple linear regression model of 0.6472.\n\n\n\n9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes other useful statistics:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. When condition numbers are larger than 30, the results may be unreliable.\nLocal R2: this value ranges between 0.0 and 1.0 and indicates how well the local regression model fits the observed y values. Very low values indicate that the local model is performing poorly. By mapping the Local R2 values, we can see where GWR predicts well and where GWR predicts poorly. This may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. In addition, a cold-to-hot rendered map of standardized residuals can be generated with these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\n\n\n9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first convert it into sf data.frame by using the following code chunk.\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, we will use glimpse() to display the contents of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n9.5 Visualising local R2\nIn this section, we will create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nAgain, we will switch off the interactive plot mode.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n9.5.1 By URA Planning Region\nIn here, we will visualise the results against the URA planning regions.\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz_svy21[mpsz_svy21$REGION_N == \"CENTRAL REGION\", ] is\ninvalid. See sf::st_is_valid"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#spatially-const",
    "href": "take_home_ex/ex2/take-home-ex2.html#spatially-const",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "10 Spatially Const",
    "text": "10 Spatially Const\nFor easier comparison, we will plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other using the code chunk below.\n\nhclust.map <- qtm(nga_wp_hcluster,\n                  \"H_CLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nskclust.map <- qtm(nga_sf_spatialcluster,\n                   \"Skater_CLUSTER\") + \n  tm_borders(alpha = 0.5)+\n    tm_layout(main.title = \"SKATER Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(hclust.map, skclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\nAs expected, the clusters formed from spatially constrained clustering is much more geographically cohesive compared to those formed from hierarchical clustering."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2.html#visualisation-of-all-clustering-results",
    "href": "take_home_ex/ex2/take-home-ex2.html#visualisation-of-all-clustering-results",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "11 Visualisation of all clustering results",
    "text": "11 Visualisation of all clustering results\n\ntmap_arrange(skclust.map, Gclust.map, Nclust.map, hclust.map, Hclust.map,\n             asp=NA, ncol=3)\n\n\n\n\nComparing among the 3 spatially and neighbourhood constrained results, we can see that the SKATER spatially constrained hierarchical clustering gave the most geographically cohesive clusters, which is then followed by ClustGeo’s neighbourhood constrained cluster.\nThe results for hierarchical clustering are largely similar for both the hierarchical methods (hclust() and hclustgeo()). The only exception is at the most North West region where the LGAs are assigned to different clusters in the 2 methods.\n\n11.1 Comparing spatially constrained and neighbourhood constrained hierarchical clusters\nWe will generate boxplots for each water point attribute for each cluster to perform this comparison. As such, we want to create a data frame containing just the shapeName, cluster IDs, and the water point attribute values. This will then allow us to facet by the cluster ID and subsequently generate the boxplots.\nFirst, we will select the cluster IDs and the shapeName from nga_wp and drop the geometry field by setting it to NULL.\n\ncluster_summary <- nga_wp %>%\n    st_set_geometry(NULL) %>%\n  select(\"shapeName\", \"H_CLUSTER\", \"Skater_CLUSTER\", \"ClustG_HCLUSTER\", \"ClustG_SPCLUSTER\", \"ClustG_NCLUSTER\")\nhead(cluster_summary)\n\n       shapeName H_CLUSTER Skater_CLUSTER ClustG_HCLUSTER ClustG_SPCLUSTER\n1      Aba North         1              2               1                1\n2      Aba South         1              2               1                1\n4          Abaji         2              1               2                2\n5           Abak         3              2               3                3\n6      Abakaliki         2              4               4                4\n7 Abeokuta North         1              5               1                1\n  ClustG_NCLUSTER\n1               1\n2               1\n4               2\n5               3\n6               4\n7               1\n\n\nNext, we want to rename the IDs for each cluster field to differentiate the clusters generated from each clustering method. To do this, we use recode_factor() from dplyr package.\n\ncluster_summary$H_CLUSTER <- recode_factor(cluster_summary$H_CLUSTER, \n                                           \"1\" = \"Hier, Cluster 1\",\n                                           \"2\" = \"Hier, Cluster 2\",\n                                           \"3\" = \"Hier, Cluster 3\",\n                                           \"4\" = \"Hier, Cluster 4\",\n                                           \"5\" = \"Hier, Cluster 5\",\n                                           \"6\" = \"Hier, Cluster 6\",\n                                           \"7\" = \"Hier, Cluster 7\",\n                                           \"8\" = \"Hier, Cluster 8\",\n                                           \"9\" = \"Hier, Cluster 9\")\ncluster_summary$Skater_CLUSTER <- recode_factor(cluster_summary$Skater_CLUSTER, \n                                           \"1\" = \"Skater, Cluster 1\",\n                                           \"2\" = \"Skater, Cluster 2\",\n                                           \"3\" = \"Skater, Cluster 3\",\n                                           \"4\" = \"Skater, Cluster 4\",\n                                           \"5\" = \"Skater, Cluster 5\",\n                                           \"6\" = \"Skater, Cluster 6\",\n                                           \"7\" = \"Skater, Cluster 7\",\n                                           \"8\" = \"Skater, Cluster 8\",\n                                           \"9\" = \"Skater, Cluster 9\")\ncluster_summary$ClustG_HCLUSTER <- recode_factor(cluster_summary$ClustG_HCLUSTER, \n                                           \"1\" = \"ClustGeo Hier, Cluster 1\",\n                                           \"2\" = \"ClustGeo Hier, Cluster 2\",\n                                           \"3\" = \"ClustGeo Hier, Cluster 3\",\n                                           \"4\" = \"ClustGeo Hier, Cluster 4\",\n                                           \"5\" = \"ClustGeo Hier, Cluster 5\",\n                                           \"6\" = \"ClustGeo Hier, Cluster 6\",\n                                           \"7\" = \"ClustGeo Hier, Cluster 7\",\n                                           \"8\" = \"ClustGeo Hier, Cluster 8\",\n                                           \"9\" = \"ClustGeo Hier, Cluster 9\")\ncluster_summary$ClustG_SPCLUSTER <- recode_factor(cluster_summary$ClustG_SPCLUSTER, \n                                           \"1\" = \"ClustGeo, distance Cluster 1\",\n                                           \"2\" = \"ClustGeo, distance Cluster 2\",\n                                           \"3\" = \"ClustGeo, distance Cluster 3\",\n                                           \"4\" = \"ClustGeo, distance Cluster 4\",\n                                           \"5\" = \"ClustGeo, distance Cluster 5\",\n                                           \"6\" = \"ClustGeo, distance Cluster 6\",\n                                           \"7\" = \"ClustGeo, distance Cluster 7\",\n                                           \"8\" = \"ClustGeo, distance Cluster 8\",\n                                           \"9\" = \"ClustGeo, distance Cluster 9\")\ncluster_summary$ClustG_NCLUSTER <- recode_factor(cluster_summary$ClustG_NCLUSTER, \n                                           \"1\" = \"ClustGeo, contiguity Cluster 1\",\n                                           \"2\" = \"ClustGeo, contiguity Cluster 2\",\n                                           \"3\" = \"ClustGeo, contiguity Cluster 3\",\n                                           \"4\" = \"ClustGeo, contiguity Cluster 4\",\n                                           \"5\" = \"ClustGeo, contiguity Cluster 5\",\n                                           \"6\" = \"ClustGeo, contiguity Cluster 6\",\n                                           \"7\" = \"ClustGeo, contiguity Cluster 7\",\n                                           \"8\" = \"ClustGeo, contiguity Cluster 8\",\n                                           \"9\" = \"ClustGeo, contiguity Cluster 9\")\n\nNext, to nga_wp.std, we will use rownames_to_column from tibble package to bring the shapeName from index column to a field column. This allows us to merge this data frame with cluster_summary by the shapeName field as shown in the following code chunk.\n\nnga_wp.std <- tibble::rownames_to_column(nga_wp.std, \"shapeName\")\ncluster_summary <- merge(x=cluster_summary, y=nga_wp.std, \n                         by.x=\"shapeName\", by.y=\"shapeName\")\nhead(cluster_summary)\n\n       shapeName       H_CLUSTER    Skater_CLUSTER          ClustG_HCLUSTER\n1      Aba North Hier, Cluster 1 Skater, Cluster 2 ClustGeo Hier, Cluster 1\n2      Aba South Hier, Cluster 1 Skater, Cluster 2 ClustGeo Hier, Cluster 1\n3          Abaji Hier, Cluster 2 Skater, Cluster 1 ClustGeo Hier, Cluster 2\n4           Abak Hier, Cluster 3 Skater, Cluster 2 ClustGeo Hier, Cluster 3\n5      Abakaliki Hier, Cluster 2 Skater, Cluster 4 ClustGeo Hier, Cluster 4\n6 Abeokuta North Hier, Cluster 1 Skater, Cluster 5 ClustGeo Hier, Cluster 1\n              ClustG_SPCLUSTER                ClustG_NCLUSTER wp_functional\n1 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 1   0.009308511\n2 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 1   0.038563830\n3 ClustGeo, distance Cluster 2 ClustGeo, contiguity Cluster 2   0.030585106\n4 ClustGeo, distance Cluster 3 ClustGeo, contiguity Cluster 3   0.030585106\n5 ClustGeo, distance Cluster 4 ClustGeo, contiguity Cluster 4   0.109042553\n6 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 1   0.021276596\n  wp_nonfunctional pct_functional pct_nonfunctional pct_lowusage  pct_rural\n1       0.03237410      0.4117647         0.5294118   0.17647059 0.00000000\n2       0.12589928      0.4084507         0.4929577   0.12676056 0.05633803\n3       0.12230216      0.4035088         0.5964912   0.40350877 0.84210526\n4       0.08992806      0.4791667         0.5208333   0.08333333 0.83333333\n5       0.15107914      0.3519313         0.1802575   0.90557940 0.87553648\n6       0.05395683      0.4705882         0.4411765   0.23529412 0.20588235\n    pct_pay pct_crucial\n1 0.9387255   0.4705882\n2 0.8679577   0.3239437\n3 0.6162281   0.5614035\n4 0.9348958   0.7500000\n5 0.5082260   0.1502146\n6 0.7855392   0.3823529\n\n\nWe will then generate the boxplots for Skater clusters. We will need to use melt() from reshape2 package to convert cluster_summarydata frame with several measurement columns into a data frame in a canonical format, which has one row for every observed (measured) value. We set the ID of the variables, i.e. id.vars argument to the cluster ID, “Skater_CLUSTER” as shown in the following code chunk.\n\nskmelted<- melt(cluster_summary[c(3,7:14)],id.vars=\"Skater_CLUSTER\")\nhead(skmelted)\n\n     Skater_CLUSTER      variable       value\n1 Skater, Cluster 2 wp_functional 0.009308511\n2 Skater, Cluster 2 wp_functional 0.038563830\n3 Skater, Cluster 1 wp_functional 0.030585106\n4 Skater, Cluster 2 wp_functional 0.030585106\n5 Skater, Cluster 4 wp_functional 0.109042553\n6 Skater, Cluster 5 wp_functional 0.021276596\n\n\nWe will then use facet_wrap() to generate one plot for each cluster ID by specifying the first argument as Skater_CLUSTER.\n\nSKCLUSTER <- ggplot(skmelted,aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~Skater_CLUSTER,\n                               nrow = 9)\n\nWe will repeat the same steps for ClustG_SPCLUSTER and ClustG_NCLUSTER. Finally, we will use ggarrange() to combine the plots together.\n\nSPmelted<- melt(cluster_summary[c(5,7:14)],id.vars=\"ClustG_SPCLUSTER\")\nClustG_SPCLUSTER <- ggplot(SPmelted, aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~ClustG_SPCLUSTER,nrow = 9)\n \nNmelted<- melt(cluster_summary[c(6,7:14)],id.vars=\"ClustG_NCLUSTER\")\nClustG_NCLUSTER <- ggplot(Nmelted, aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~ClustG_NCLUSTER,nrow = 9)\n \nggarrange(SKCLUSTER, ClustG_SPCLUSTER, ClustG_NCLUSTER, \n          ncol = 3)\n\n\n\n\nWe can observe that the clusters formed using SKATER is less homogeneous compared to those formed using ClustGeo. For instance, in Skater cluster 2, we can see that LGAs belonging to this cluster has a wide range of values for pct_lowusage. Such wide range of values is observed in several skater clusters. This is within expectation as the Skater clusters are more spatially compact compared to those formed by ClustGeo.\nComparing ClustGeo distance and ClustGeo contiguity (aka neighbourhood) clusters, the boxplots are relatively similar such as ClustGeo distance clusters 3, 4, 6, and 8, resemble ClustGeo contiguity clusters 3, 4, 7, and 9 respectively. This is aligned with the water point attributes homogeneity which is similar in the 2 clustering methods, i.e. 56% and 52% for spatially constrained (by distance) hierarchical clusters and neighbourhood constrained hierarchical clusters respectively. Comparing the boxplots obtained from these 2 methods, ClustGeo distance seem to give more compact boxplots. This is aligned with expectation since ClustGeo contiguity has more spatial cohesion, and would have compromised more on water point attributes homogeneity.\n\n\n11.2 Analysing cluster characteristics for ClustGeo Spatially Constrained by Distance\nIn the following analysis, we may make reference to the geopolitical zones in Nigeria as illustrated in the following image.\n\nImage reference [4]\nWe will first generate boxplots for each cluster ID for each clustering variable. This will allow us to compare between the clusters for each variable more easily. To do this, we have listed the x-axis to be the cluster IDs (i.e. ClustG_SPCLUSTER) and y-axis to be the min-max standardised values of the attributes. Using the standardised values allows us to put all the variables on the same scale for easier visualisation. We will facet by the variable so that we generate separate plot for each variable.\n\nggplot(SPmelted,aes(x = ClustG_SPCLUSTER, y = value)) + \n     geom_boxplot()+facet_wrap(~variable,\n                               nrow = 2) +\n    theme(axis.text.x=element_text(angle=45,hjust=1))\n\n\n\n\nIn addition, we want to generate individual map, boxplot, and summary statistics table for each cluster. We will demonstrate how this can be done for cluster 1.\nFirst, we use mutate() to keep categorise LGAs as either “cluster 1” or “others”.\n\nnga_wp_1 <- nga_wp %>% \n    mutate(ClusterID = if_else(.$ClustG_SPCLUSTER == 1, \"Cluster 1\", \"Others\"))\n\nWe can then generate the map highlighting only the LGAs belonging to cluster 1. We have kept all the other LGAs in nga_wp_1 as “others”, allowing us to plot these non-cluster 1 LGAs on the map as well. We will let the colour of these LGAs be transparent, “#FFFFFF”.\n\nmap1 <- tm_shape(nga_wp_1) + \n    tm_fill(col= \"ClusterID\", palette = c(\"blue\", \"#FFFFFF\")) + \n  tm_borders(alpha = 0.5) \n\nTo generate the boxplot for the variables for cluster 1, we need to use the min-max standardised values of the attributes found in SPmelted. We will first use filter() to get only cluster 1 data rows, before plotting the boxplot.\n\nboxplot1 <- SPmelted %>% \n    filter(ClustG_SPCLUSTER == \"ClustGeo, distance Cluster 1\") %>% \n    ggplot(aes(x = value, y = variable)) + \n     geom_boxplot() + theme(axis.text.y = element_text(size = 15)) \n\nLastly, we will get the summary statistics for cluster 1. We will need to use the non-standardised attribute values to generate the statistics. We will first retrieve the attribute columns and the cluster ID column and save the results in cluster. We will also set geometry to NULL as we do not need the column here. We will then filter() to get the data for cluster 1 only.\n\ncluster <- nga_wp %>% \n    select(c(7,8,16,17,19,21,22,23,27)) %>% \n    st_set_geometry(NULL)\nclust1 <- cluster %>% \n    filter(.$ClustG_SPCLUSTER == 1) %>% \n    select(c(1:8))\n\nWe can efficiently get the summary statistics (min, Q1, median, Q3, and max) by using boxplot() and its attributes stats. We then use colnames() and rownames() to label each variable and each statistic respectively. we then use t() to transpose the data to make the columns to rows and vice versa for easier reading. Finally, we round of the results to 2 decimal places using round().\n\nsummary1 <- boxplot(clust1, plot=FALSE)$stats\ncolnames(summary1) <- c(\"wp_functional\", \"wp_nonfunctional\", \n                        \"pct_functional\", \"pct_nonfunctional\", \n                        \"pct_lowusage\", \"pct_rural\", \"pct_pay\",\n                        \"pct_crucial\")\nrownames(summary1)<-c(\"Min\",\"Q1\",\"Median\",\"Q3\",\"Max\")\nsummary1 <- t(summary1) %>% \n    round(digits = 2)\n\nLastly, we use kable() to format the summary statistics table in a tidy format.\n\nsummary1 <- kable(summary1, linesep = \"\") %>% \n    kable_styling(font_size = 10)\n\n\n\n\n\n\n\n\n\n\nAnalysis for Cluster 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    2.00 \n    23.00 \n    44.00 \n    73.00 \n    141.00 \n  \n  \n    wp_nonfunctional \n    0.00 \n    8.00 \n    30.00 \n    54.50 \n    120.00 \n  \n  \n    pct_functional \n    0.26 \n    0.45 \n    0.52 \n    0.67 \n    0.92 \n  \n  \n    pct_nonfunctional \n    0.00 \n    0.21 \n    0.36 \n    0.50 \n    0.73 \n  \n  \n    pct_lowusage \n    0.00 \n    0.21 \n    0.43 \n    0.58 \n    1.00 \n  \n  \n    pct_rural \n    0.00 \n    0.00 \n    0.15 \n    0.29 \n    0.67 \n  \n  \n    pct_pay \n    0.36 \n    0.71 \n    0.87 \n    0.95 \n    1.00 \n  \n  \n    pct_crucial \n    0.00 \n    0.06 \n    0.13 \n    0.25 \n    0.52 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster has low pct_rural and high pct_pay which corresponds to low percentage of water points in rural areas and high percentage of water points that require payment.\nAnalysis for Cluster 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    1.00 \n    37.00 \n    53.00 \n    70.00 \n    104.00 \n  \n  \n    wp_nonfunctional \n    0.00 \n    16.00 \n    36.00 \n    49.00 \n    94.00 \n  \n  \n    pct_functional \n    0.39 \n    0.52 \n    0.58 \n    0.73 \n    1.00 \n  \n  \n    pct_nonfunctional \n    0.00 \n    0.25 \n    0.37 \n    0.46 \n    0.60 \n  \n  \n    pct_lowusage \n    0.00 \n    0.24 \n    0.40 \n    0.53 \n    0.69 \n  \n  \n    pct_rural \n    0.39 \n    0.72 \n    0.86 \n    1.00 \n    1.00 \n  \n  \n    pct_pay \n    0.51 \n    0.66 \n    0.81 \n    0.95 \n    1.00 \n  \n  \n    pct_crucial \n    0.08 \n    0.29 \n    0.39 \n    0.49 \n    0.74 \n  \n\n\n\n\n\n\n\nThe LGAs here are characterise by having relatively low percentage of water points that are over-utilised (based on low pct_lowusage), and relatively higher percentage of functional water points (pct_functional). The LGAs here occupy parts of the North West, North East, and North Central regions in Nigeria.\nAnalysis for Cluster 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    1.00 \n    8.00 \n    15.50 \n    28.50 \n    44.00 \n  \n  \n    wp_nonfunctional \n    0.00 \n    14.50 \n    27.50 \n    40.00 \n    76.00 \n  \n  \n    pct_functional \n    0.12 \n    0.27 \n    0.38 \n    0.48 \n    0.76 \n  \n  \n    pct_nonfunctional \n    0.06 \n    0.45 \n    0.59 \n    0.71 \n    0.88 \n  \n  \n    pct_lowusage \n    0.00 \n    0.08 \n    0.17 \n    0.29 \n    0.55 \n  \n  \n    pct_rural \n    0.55 \n    0.81 \n    0.95 \n    1.00 \n    1.00 \n  \n  \n    pct_pay \n    0.66 \n    0.84 \n    0.95 \n    1.00 \n    1.00 \n  \n  \n    pct_crucial \n    0.12 \n    0.50 \n    0.62 \n    0.78 \n    1.00 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster is characterised by high percentage of non-functional water points (pct_nonfunctional) and also a high percentage of water points in the rural areas (pct_rural). The LGAs in this cluster is also characterised as having the lowest median for percentage of water points that are low usage (pct_lowusage). This is interesting as the LGAs here are mainly in the South South region, which is the urban region in Nigeria. The observation that there is a high proportion of water points that are in rural area indicates that there are possibly rural settlements within the urban South South region and could likely be due to rural-to-urban migration. Moreover, the high percentage of water points serving more than 50% of its total local population within a 1km radius of the water point (pct_crucial) indicates that the local population depends heavily on these water points.\nAnalysis for Cluster 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    6.00 \n    52.00 \n    79.00 \n    107.50 \n    168.00 \n  \n  \n    wp_nonfunctional \n    8.00 \n    51.00 \n    75.00 \n    93.50 \n    128.00 \n  \n  \n    pct_functional \n    0.12 \n    0.28 \n    0.37 \n    0.46 \n    0.59 \n  \n  \n    pct_nonfunctional \n    0.15 \n    0.29 \n    0.37 \n    0.44 \n    0.65 \n  \n  \n    pct_lowusage \n    0.58 \n    0.77 \n    0.86 \n    0.91 \n    0.98 \n  \n  \n    pct_rural \n    0.67 \n    0.86 \n    0.95 \n    1.00 \n    1.00 \n  \n  \n    pct_pay \n    0.36 \n    0.59 \n    0.67 \n    0.75 \n    0.91 \n  \n  \n    pct_crucial \n    0.00 \n    0.24 \n    0.40 \n    0.54 \n    0.82 \n  \n\n\n\n\n\n\n\nThe LGAs here are characterised as having the second highest (median for) percentage of water points that are of low usage (pct_lowusage) as well as relatively lower percentage of water points that are require payment for use (pct_pay).\nAnalysis for Cluster 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    0.00 \n    5.00 \n    10.50 \n    17.50 \n    32.00 \n  \n  \n    wp_nonfunctional \n    0.00 \n    3.50 \n    10.50 \n    17.00 \n    37.00 \n  \n  \n    pct_functional \n    0.00 \n    0.16 \n    0.23 \n    0.31 \n    0.50 \n  \n  \n    pct_nonfunctional \n    0.00 \n    0.12 \n    0.23 \n    0.38 \n    0.73 \n  \n  \n    pct_lowusage \n    0.00 \n    0.42 \n    0.55 \n    0.73 \n    1.00 \n  \n  \n    pct_rural \n    0.00 \n    0.27 \n    0.56 \n    0.83 \n    1.00 \n  \n  \n    pct_pay \n    0.04 \n    0.26 \n    0.42 \n    0.57 \n    1.00 \n  \n  \n    pct_crucial \n    0.32 \n    0.60 \n    0.78 \n    0.90 \n    1.00 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster are characterised as having the lowest median for the percentage of waterpoints that require payment for use (pct_pay) and the lowest median for the number of functional and the lowest median for the number non-functional water points (wp_functional and wp_nonfunctional). The percentage of water point in rural areas vary very widely in this cluster. Like cluster 3, cluster 5 also has a very high percentage of water points that are crucial (pct_crucial).\nAbout half of the LGAs in this cluster is in the South East region and another half of them in the South West region in Nigeria. Considering their proximity to the South South region, attribute like pct_crucial is quite similar to cluster 3, which again indicates that the local population depends heavily on these water points within this urban South East region. One apparent difference is that cluster 5 has a much higher percentage of water points that are of low usage (i.e. % water points serving beyond their capacity) compared to cluster 3. This indicates that while water points are important and serving more than 50% of the local population, the water points are still being utilized within their capacity in cluster 5, unlike in cluster 3.\nAnalysis for Cluster 6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    9.00 \n    40.00 \n    65.00 \n    101.00 \n    160.00 \n  \n  \n    wp_nonfunctional \n    1.00 \n    35.00 \n    58.00 \n    91.00 \n    171.00 \n  \n  \n    pct_functional \n    0.20 \n    0.39 \n    0.45 \n    0.51 \n    0.67 \n  \n  \n    pct_nonfunctional \n    0.09 \n    0.32 \n    0.40 \n    0.48 \n    0.67 \n  \n  \n    pct_lowusage \n    0.42 \n    0.61 \n    0.71 \n    0.79 \n    0.92 \n  \n  \n    pct_rural \n    0.17 \n    0.62 \n    0.81 \n    0.99 \n    1.00 \n  \n  \n    pct_pay \n    0.46 \n    0.66 \n    0.79 \n    0.97 \n    1.00 \n  \n  \n    pct_crucial \n    0.01 \n    0.18 \n    0.25 \n    0.35 \n    0.54 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster has a moderate percentage of functional and non-function water points compared to the other clusters (i.e. pct_functional and pct_nonfunctional). The mean percentage for pct_functional and pct_nonfunctional are 44.8% and 39.1% based on summary results in Section 11.2. The LGAs in this cluster also have a relatively low pct_crucial.\nMost of the LGAs in this region is in the South West region in Nigeria.\nAnalysis for Cluster 7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    0.00 \n    15.50 \n    24.00 \n    41.00 \n    77.00 \n  \n  \n    wp_nonfunctional \n    2.00 \n    32.00 \n    54.00 \n    74.50 \n    135.00 \n  \n  \n    pct_functional \n    0.02 \n    0.24 \n    0.31 \n    0.39 \n    0.52 \n  \n  \n    pct_nonfunctional \n    0.43 \n    0.58 \n    0.64 \n    0.71 \n    0.86 \n  \n  \n    pct_lowusage \n    0.44 \n    0.57 \n    0.73 \n    0.85 \n    1.00 \n  \n  \n    pct_rural \n    0.84 \n    0.93 \n    1.00 \n    1.00 \n    1.00 \n  \n  \n    pct_pay \n    0.75 \n    0.88 \n    0.96 \n    1.00 \n    1.00 \n  \n  \n    pct_crucial \n    0.13 \n    0.46 \n    0.57 \n    0.74 \n    1.00 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster has the highest percentage of water points that are in rural areas (pct_rural) and highest percentage of water points that are non-functional (pct_nonfunctional). They also have one of the lowest percentage of water points that are functional (pct_functional). LGAs in this cluster are relatively spatially distributed across Nigeria.\nAnalysis for Cluster 8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    2.00 \n    58.50 \n    97.00 \n    153.50 \n    296.00 \n  \n  \n    wp_nonfunctional \n    0.00 \n    13.50 \n    32.00 \n    54.00 \n    111.00 \n  \n  \n    pct_functional \n    0.38 \n    0.65 \n    0.75 \n    0.86 \n    1.00 \n  \n  \n    pct_nonfunctional \n    0.00 \n    0.14 \n    0.24 \n    0.35 \n    0.62 \n  \n  \n    pct_lowusage \n    0.57 \n    0.80 \n    0.89 \n    0.95 \n    1.00 \n  \n  \n    pct_rural \n    0.55 \n    0.82 \n    0.95 \n    1.00 \n    1.00 \n  \n  \n    pct_pay \n    0.81 \n    0.92 \n    0.99 \n    1.00 \n    1.00 \n  \n  \n    pct_crucial \n    0.00 \n    0.17 \n    0.27 \n    0.38 \n    0.61 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster are characterised by having the highest percentage of functional water points (pct_functional). This cluster of LGAs also has the highest median for the number of functional water points (wp_functional). There are also many outlier LGAs in this cluster with very high number of functional water points. From the map, the LGAs in this cluster mainly occupy the North West and North East regions in Nigeria which we have gathered from Take-Home Exercise 1 that these are more rural parts of Nigeria.\nAnalysis for Cluster 9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n  \n      \n    Min \n    Q1 \n    Median \n    Q3 \n    Max \n  \n \n\n  \n    wp_functional \n    1.000 \n    8.000 \n    15.500 \n    28.500 \n    44.000 \n  \n  \n    wp_nonfunctional \n    0.000 \n    14.500 \n    27.500 \n    40.000 \n    76.000 \n  \n  \n    pct_functional \n    0.121 \n    0.270 \n    0.378 \n    0.479 \n    0.760 \n  \n  \n    pct_nonfunctional \n    0.061 \n    0.449 \n    0.586 \n    0.712 \n    0.879 \n  \n  \n    pct_lowusage \n    0.000 \n    0.079 \n    0.173 \n    0.286 \n    0.545 \n  \n  \n    pct_rural \n    0.549 \n    0.813 \n    0.946 \n    1.000 \n    1.000 \n  \n  \n    pct_pay \n    0.661 \n    0.843 \n    0.946 \n    1.000 \n    1.000 \n  \n  \n    pct_crucial \n    0.121 \n    0.499 \n    0.619 \n    0.775 \n    1.000 \n  \n\n\n\n\n\n\n\nThe LGAs in this cluster is the most spatially distributed compared to all the other clusters. The LGAs here have the lowest percentage of water points in rural areas (pct_rural) and lowest percentage of water points are serving more than 50% of its total local population within a 1km radius of the water point (pct_crucial)."
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html",
    "href": "in_class_ex/ex4/in_class_ex4.html",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "In this in-class exercise, we will cover the same topic in hands-on exercise 4 and provide more in-depth details on several sections.\nGeographically weighted regression (GWR) is a spatial statistical technique that examines the way in which the relationships between a dependent variable and a set of predictors might vary over space. GWR operates by moving a search window from one regression point to the next, working sequentially through all the existing regression points in the data set. In this hands-on exercise, we will build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and location-based."
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#the-data",
    "href": "in_class_ex/ex4/in_class_ex4.html#the-data",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "2 The Data",
    "text": "2 The Data\nThere are two data sets used in this exercise and they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#getting-started",
    "href": "in_class_ex/ex4/in_class_ex4.html#getting-started",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nThe R packages needed for this exercise are as follows:\n\nolsrr-R package for building OLS and performing diagnostics tests\nGWmodel- R package for calibrating geographical weighted family of models\ncorrplot- R package for multivariate data visualisation and analysis\nsf - Spatial data handling\ntidyverse, including readr, ggplot2, and dplyr - Attribute data handling\ntmap - choropleth mapping\n\nThe code chunk below installs and launches these packages into the R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#a-note-on-gwmodel",
    "href": "in_class_ex/ex4/in_class_ex4.html#a-note-on-gwmodel",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4 A note on GWmodel",
    "text": "4 A note on GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, and is suitable for use in situations when data are not described well by a global model. The resulting output are mapped which provides a useful tool to explain data spatial heterogeneity. Currently, GWmodel includes functions for: GW summary statistics, GW principal components analysis, GW regression, and GW discriminant analysis."
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#geospatial-data-wrangling",
    "href": "in_class_ex/ex4/in_class_ex4.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5 Geospatial Data Wrangling",
    "text": "5 Geospatial Data Wrangling\n\n5.1 Importing geospatial data\nThe geospatial data in this hands-on exercise (MP14_SUBZONE_WEB_PL) is in ESRI shapefile format and contains URA Master Plan 2014’s planning subzone boundaries. These geographic boundaries are represented by polygon features. The GIS data is in svy21 projected coordinates systems.\nIn the following code chunk, we will import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\lohsiying\\ISSS624\\in_class_ex\\ex4\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\n5.2 Updating CRS information\nWe will need to updated the imported file with the correct ESPG code (i.e. 3414). Although the data is load as svy21, it can be treated as a Singapore code (there could be some slight alignments done in Singapore e.g by 30 m etc). So it is better to align and use international CRS code.\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\nWe can then verify the projection of the newly transformed mpsz_svy21 by using st_crs() from sf package.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWe can observe that the EPSG is indicated with 3414.\nWe will then reveal the extent of mpsz_svy21 by using st_bbox() from sf package.\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#aspatial-data-wrangling",
    "href": "in_class_ex/ex4/in_class_ex4.html#aspatial-data-wrangling",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6 Aspatial Data Wrangling",
    "text": "6 Aspatial Data Wrangling\n\n6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data, we will use glimpse() to display its data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nNext, we will use summary() of base R to display the summary statistics of condo_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n6.2 Converting aspatial data frame into a sf object\nWe will now convert the aspatial condo_resale tibble data frame into a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() from sf package. We will then use st_transform() from sf package to convert the coordinates from wgs84 (i.e. crs=4326) to svy21 (i.e. crs=3414).\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\nNext, head() is used to list the content of condo_resale.sf object. Note that in condo_resale.sf has 1 column less compared to condo_resale. condo_resale is a typical R tibble data frame, it contains the longitude and latitude columns whereas condo_resale.sf has the geometry column instead. You need to be aware that the function / method you use requires the data to be in which format and use accordingly.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN\n\n\nWe can see that the output is a point feature data frame."
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#exploratory-data-analysis-eda",
    "href": "in_class_ex/ex4/in_class_ex4.html#exploratory-data-analysis-eda",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7 Exploratory Data Analysis (EDA)",
    "text": "7 Exploratory Data Analysis (EDA)\nIn this section, we will use statistical graphic functions from ggplot2 package to perform EDA.\n\n7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using a histogram as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe plot above reveals a right skewed distribution. This means that there are more condominium units transacted at relative lower prices compared to higher prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. In the following code chunk, we will use mutate() of dplyr package to perform the log transformation.\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the log transformed variable using the following code chunk.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nWe can see that the distribution is relatively less skewed after the log transformation.\n\n\n7.2 Multiple Histogram Plots distribution of variables\nIn this section, we will generate trellis plots (i.e. small multiple histograms) by using ggarrange() from ggpubr package.\nIn the following code chink, we will create 12 histograms. ggarrange() is used to organised these histograms into a 3 columns by 4 rows multiple plot.\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n7.3 Drawing Statistical Point Map\nLastly, we want to have a view of the geographical distribution of the condominium resale prices in Singapore. This map will be prepared by using the tmap package.\nFor better viewing experience, we will turn on the interactive mode of tmap by using the following code chunk.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunks below is used to create an interactive point symbol map. We will use tm_dots() is used instead of tm_bubbles(). Also we make use of the set.zoom.limits argument of tm_view() to set the minimum and maximum zoom level to 11 and 14 respectively.\nWe will first read the shapefile using tm_shape() and because there is a missing polygon in the data, we will need to use tmap_options() to treat the missing polygon by specifying check.and.fix to TRUE. There will be a warning message because of this. (Similar warning message will be shown when you didn’t transform the data to EPSG format.)\n\ntm_shape(mpsz_svy21)+\n    tmap_options(check.and.fix = TRUE)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nBefore moving on to the next section, we will turn R display back to plot mode using the following code chunk.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#hedonic-pricing-modelling-in-r",
    "href": "in_class_ex/ex4/in_class_ex4.html#hedonic-pricing-modelling-in-r",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8 Hedonic Pricing Modelling in R",
    "text": "8 Hedonic Pricing Modelling in R\nIn this section, we will build hedonic pricing models for condominium resale units using lm() from R base.\n\n8.1 Simple Linear Regression Method\nWe will first build a simple linear regression model using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable. To do this, we put the dependent variable first, i.e. before the “~” sign and the independent variable after this sign.\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. In addition, effects(), fitted.values(), and residuals() functions also extract various useful features of the values returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince the p-value is much smaller than 0.0001, we will reject the null hypothesis that the mean is a good estimator of the SELLING_PRICE. This allows us to infer that the simple linear regression model we have built is a good estimator of the SELLING_PRICE.\nThe Coefficients section of the report reveals that the p-values of both the estimates of the Intercept and AREA_SQM are each smaller than 0.001. In view of this, the null hypothesis that the values of B0 and B1 are equal to 0 will be rejected. As a result, we can infer that B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe plot above reveals that there are a few statistical outliers that have relatively high selling prices.\n\n\n8.2 Multiple Linear Regression Model\n\n8.2.1 Visualising the relationships of the independent variables\nBefore we build a multiple regression model, it is important to ensure that the independent variables used are not highly correlated to each other (known as multicollinearity) to avoid compromising the resulting regression model.\nIn this section, we will use the corrplot package to visualise the relationships between the independent variables. The code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\",\n         number.cex = 0.4)\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in the matrix. THis allows variables that are relatively more correlated to be placed adjacent to each other in the correlation plot, allowing us to visualise their correlation (if any) more easily. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. As such, we will only include either one of them for model building. We will exclude LEASE_99YEAR from the subsequent model building steps.\n\n\n\n8.3 Building a hedonic pricing model using multiple linear regression method\nWe will use the following code chunk using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\n\n\n8.4 Preparing Publication Quality Table: olsrr method\nWe can see from the report that not all independent variables are statistically significant. As such, we will revise the model by removing the variables which are not statistically significant.\nIn the following code chunk, we will keep the variables that are statistically significant.\nThe resulting condo.mlr1 is an containing lists of items. You can view the details by clicking on this variable in the environment tab. You can pull out the details such as in the following: as.data.frame(condo.mlr1$residuals) as demonstrated in section 8.5.4.\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                   PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                   FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\nFor multiple regression models, we should use adjusted R-squared for comparison between different MLR models under “Model Summary” section in the report.\nUnder “ANOVA” section in the report above, since significance is <0.05, we know that the MLR model built is performing better than the mean estimates of all observations.\nUnder “Parameter Estimates” section of the report, we look at the p-value to identify which independent variable is statistically significant. You can also look at the Beta values (coefficients) to understand an increase in 1 unit of that variable will result in how much increase (by the value of the coefficient) in the resale price when the other variables remain constant. Also the sign is important to check whether it aligns with logic and whether the MLR build makes sense. For instance, look at PROX_MRT, it aligns with what we expect, there is a negative coefficient, meaning the further the house is from an MRT station, the lower the condo price. Also PROX_PRIMARY_SCHOOL is interesting because it has a positive coefficient. (Sometimes this might be because school can be noisy in the morning / throughout the school hours - school bells.) Additionally, what you can do is to use PROX_TOP_PRIMARY_SCHOOL and evaluate whether using this independent variable instead changes the sign of the coefficient.\n\n\n8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith the gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() . In the following code chunk, we will demonstrate using add_glance_source_note().\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n8.5.1 Checking for multicollinearity\nIn this section, we will employ the methods from the olsrr package which is specially designed to perform OLS regression. It provides the following methods to support building better multiple regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() from olsrr package is used to test for multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF values obtained for the independent variables are less than 10, we can conclude that there is no sign of multicollinearity among the independent variables.\n\n\n8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important to confirm the linearity and additivity relationship between the dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe plot above reveals that most data points are scattered around the 0 line. As such, we can conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.5.3 Test for Normality Assumption\nWe will also use ols_plot_resid_hist() from olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure above suggests that the residual of the multiple linear regression model (i.e. condo.mlr1) follows a normal distribution.\nAlternatively, we can perform formal statistical test methods, such as the ols_test_normality() from olsrr package as shown in the code chunk below.\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are much smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model that we are trying to build uses geographically referenced attributes, hence it is also important for us to visualise the residual of the hedonic pricing model spatially.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nWe will then convert condo_resale.res.sf from a simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nWe will use the following code chunk to perform the data conversion.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nAgain, we will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunk below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nWe will switch the mode back to “plot” before continuing.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo validate our observation, we will perform the Moran’s I test.\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function from spdep.\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nWe will then use lm.morantest() from spdep package to perform Moran’s I test for residual spatial autocorrelation.\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.144 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "in_class_ex/ex4/in_class_ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "in_class_ex/ex4/in_class_ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-Class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9 Building Hedonic Pricing Models using GWmodel",
    "text": "9 Building Hedonic Pricing Models using GWmodel\nIn this section, we will model hedonic prices using both fixed and adaptive bandwidth scheme.\n\n9.1 Building Fixed Bandwidth GWR Model\n\n9.1.1 Computing fixed bandwidth\nbw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Optimal fixed bandwidth is specified by setting the argument adaptive to FALSE.\nThe approach argument defines the stopping rule. There are two possible approaches can be used to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach.\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE +\n                     PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK +\n                     PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                     PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                     FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe results shows that the recommended bandwidth is 971.3405 metres (look at the last row, which represents very small or 0 rate of change). The unit of measurement is metre because the unit of measurement for svy21 is in metre.\nIn the above code chunk, longlat is set to True only if our data is in degree format and R will fun the calculation.\n\n\n9.1.2 GWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                           PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                           PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                           PROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\n                           PROX_BUS_STOP + NO_Of_UNITS + \n                           FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-10 16:08:54 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-10 16:08:55 \n\n\nThe report shows that the adjusted r-square of the gwr is 0.8430 which is significantly better than the global multiple linear regression model of 0.6472.\n\n\n\n9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n9.2.1 Computing the adaptive bandwidth\nTo use the adaptive badnwidth approach, we will specify the adaptive argument to TRUE.\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe results show that 30 is the recommended number of data points to be used.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nWe will now calibrate calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL +\n                            PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY +\n                            FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe following code displays the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-10 16:09:02 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-10 16:09:03 \n\n\nThe report shows that the adjusted r-square of the gwr is 0.8561 which is significantly better than the global multiple linear regression model of 0.6472.\nNote that in the report, the top portion gives global results and the bottom portion gives local results.\nCompare AICc for adaptive and adjusted R-square between fixed bandwidth and adaptive bandwidth.\nAICc for fixed bandwidth: 42967.14 VS\nAICc for adaptive bandwidth: 41982.22 (lower , thus better)\nadjusted R-squared for fixed bandwidth: 0.843 VS\nadjusted R-squared for adaptive bandwidth: 0.856\nYou can see how much the explanation is improved when adaptive bandwidth is used instead of the fixed bandwidth by looking at the R-squared.\n\n\n\n9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes other useful statistics:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. When condition numbers are larger than 30, the results may be unreliable.\nLocal R2: this value ranges between 0.0 and 1.0 and indicates how well the local regression model fits the observed y values. Very low values indicate that the local model is performing poorly. By mapping the Local R2 values, we can see where GWR predicts well and where GWR predicts poorly. This may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. In addition, a cold-to-hot rendered map of standardized residuals can be generated with these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\n\n\n9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first convert it into sf data.frame by using the following code chunk.\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, we will use glimpse() to display the contents of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n9.5 Visualising local R2\nIn this section, we will create an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\nAgain, we will switch off the interactive plot mode.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n9.5.1 By URA Planning Region\nIn here, we will visualise the results against the URA planning regions.\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz_svy21[mpsz_svy21$REGION_N == \"CENTRAL REGION\", ] is\ninvalid. See sf::st_is_valid\n\n\n\n\n\n\n\n\n9.6 Visualising Coefficient Estimates\nWe will use the following code chunk to create an interactive map. In the following code chunk, you can set zoom limits to control the view so that there isnt a case where zooming out too much will result in other country being seen also. Also you can use tmap_arrange() to use sync and set to TRUE so that the 2 maps will be synchronised when you zoom / move one of the maps.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.6.1 By URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz_svy21[mpsz_svy21$REGION_N == \"CENTRAL REGION\", ] is\ninvalid (after reprojection). See sf::st_is_valid"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "",
    "text": "The process of creating regions is called regionalisation. Regionalisation is a special kind of clustering which groups observations by incorporating both the statistical attributes and their spatial relationships. The spatial relationships are commonly modeled using contiguity and proximity considerations. As such, geographical constraints within a region are not limited to connectivity (i.e. there exists a path from one member to another member that leaves the region), and in certain contexts it make sense to relax connectivity and to impose other types of geographical constraints.\nRegionalisation results in aggregation of basic spatial units into larger regions that preserve confidentiality, minimizes population differences and reduces the effects of outliers or inaccuracies in the data. This can help to facilitate visualisation and interpretation of information on the maps. [1]"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#objectives",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#objectives",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "2 Objectives",
    "text": "2 Objectives\nIn this take-home exercise, we will regionalise Nigeria via conventional clustering without explicit spatial constraint i.e. hierarchical clustering, as well as clustering with explicit spatial constraints.\nThis will be performed by considering the following as potential clustering variables:\n\nTotal number of functional water points\nTotal number of non-functional water points\nPercentage of functional water points\nPercentage of non-functional water points\nPercentage of main water point technology (i.e. hand pump)\nPercentage of low usage water points (i.e. <1000)\nPercentage of high usage water points (i.e. >=1000)\nPercentage of rural water points\nPercentage of water points that require payment\nPercentage of crucial water points"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#the-data",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#the-data",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "3 The Data",
    "text": "3 The Data\nIn this exercise, we will analyse the data from Nigeria. There are 2 datasets used, as outlined in sections 3.1 and 3.2.\n\n3.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories on 24 November 2022 in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,008 unique water point records.\n\n\n3.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#getting-the-data-into-r-environment",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#getting-the-data-into-r-environment",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "4 Getting The Data Into R Environment",
    "text": "4 Getting The Data Into R Environment\n\n4.1 Getting Started - Setting up the environment\nIn the following code chunk, p_load() from pacman package is used to install and load the following R packages into the R environment:\n\nsf for importing, managing, and processing geospatial data,\ntidyverse for performing data science tasks such as importing, wrangling and visualising data,\ntmap for creating thematic maps,\nspdep for handling geospatial data, and\nfunModeling for Exploratory Data Analysis and Data Preparation.\ncorrplot\nggpubr\nheatmaply\ncluster\nClustGeo\n\n\npacman::p_load( funModeling)\n\n\npacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally, reshape2)\n\n\n\n4.2 Import Nigeria LGA boundary data into R environment\nThe following code chunk uses st_read() from sf package to import the geoboundaries shapefile into R and saves the imported geospatial data into a simple feature data table.\n\nnga_sf <- st_read(dsn = \"geodata\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)\nnga_sf\n\nThe above printout shows the data is in wgs84 geographic coordinate system.\nIn the following, write_rds() of readr package is used to save the extracted sf data table into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(nga_sf, \n          \"geodata/nga_sf.rds\")\n\n\n\n4.3 Import csv file into R environment\nWe will use read_csv() to read the csv file as shown in the following code chunk.\n\nwp <- read_csv(\"geodata/wpdx_nigeria.csv\")\n\nThe two fields #lat_deg and #long_deg are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System (i.e. the Geodetic coordinate system for World). We will then convert wpd data frame in to a simple feature data frame by using the following code chunk. Note that for data conversion, longitude should be supplied as the first argument in coords which is then followed by the argument for latitude.\n\nwp <- st_as_sf(wp,\n                   coords = c(\"#lon_deg\", \"#lat_deg\"),\n                   crs=4326) \nwp\n\nFrom the printout above, we can see that the data is in the format that we want, i.e. wgs84.\nSimilarly, we will use write_rds() from readr package to save the extracted sf data frame into an output file in rds format. The following code chunk saves the output file in the geospatial folder.\n\nwrite_rds(wp, \n          \"geodata/wp.rds\")\n\n\n\n4.4 Data Wrangling for Nigeria LGA boundary data\n\n4.4.1 Checking for duplicated area name\nWe will first sort the names of the LGAs in alphabetical order using sort(). We will then use duplicated() to retrieve all the shapeName that is duplicated and store them in a list. [Concise code chunk is adapted from Reference 2]\n\nnga_sf <- read_rds(\"geodata/nga_sf.rds\")\nnga_sf <- (nga_sf[order(nga_sf$shapeName), ])\nduplicate_area <- nga_sf$shapeName[nga_sf$shapeName %in%\n                                nga_sf$shapeName[duplicated(nga_sf$shapeName)] ]\nduplicate_area\n\n [1] \"Bassa\"    \"Bassa\"    \"Ifelodun\" \"Ifelodun\" \"Irepodun\" \"Irepodun\"\n [7] \"Nasarawa\" \"Nasarawa\" \"Obi\"      \"Obi\"      \"Surulere\" \"Surulere\"\n\n\nWe will add 2 columns for longitude and latitude which we will use to check the LGA names for the duplicated rows using latlong.net. The following code chunk adds columns for longitude and latitude.\n\nnga_sf$longitude <- map_dbl(nga_sf$geometry, ~st_centroid(.x)[[1]])\nnga_sf$latitude <- map_dbl(nga_sf$geometry, ~st_centroid(.x)[[2]])\n\nBased on the results from latlong.net, the table below shows the index and the actual area name.\n\n\n\nIndex in nga table\nActual area name\n\n\n\n\n94\nBassa (Kogi)\n\n\n95\nBassa (Plateau)\n\n\n304\nIfelodun (Kwara)\n\n\n305\nIfelodun (Osun)\n\n\n355\nIrepodun (Kwara)\n\n\n356\nIrepodun (Osun)\n\n\n518\nNassarawa\n\n\n546\nObi (Benue)\n\n\n547\nObi (Nasarawa)\n\n\n693\nSurulere (Lagos)\n\n\n694\nSurulere (Oyo)\n\n\n\nWe will then rectify the incorrect names in nga table by accessing the relevant rows by their indexes as shown in the following code chunk.\n\nnga_sf$shapeName[c(94,95,304,305,355,356,519,546,547,693,694)] <- c(\n                               \"Bassa (Kogi)\", \"Bassa (Plateau)\",\n                               \"Ifelodun (Kwara)\", \"Ifelodun (Osun)\",\n                               \"Irepodun (Kwara)\", \"Irepodun (Osun)\",\n                               \"Nassarawa\",\n                               \"Obi (Benue)\", \"Obi(Nasarawa)\",\n                               \"Surulere (Lagos)\", \"Surulere (Oyo)\")\n\nWe will then check if all duplicated area names have been successfully rectified. We perform this by checking if there is anymore duplicated records using duplicated().\n\nnga_sf$shapeName[nga_sf$shapeName %in% nga_sf$shapeName[duplicated(nga_sf$shapeName)] ]\n\ncharacter(0)\n\n\nFrom the results, we can see that there is no more duplicated names observed.\nWe then remove the columns we have just created to assist us in renaming the LGAs using the following code chunk.\n\nnga_sf <- nga_sf[-c(7:8)]"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#data-wrangling-for-nigeria-water-point-data",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#data-wrangling-for-nigeria-water-point-data",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "5 Data Wrangling for Nigeria water point data",
    "text": "5 Data Wrangling for Nigeria water point data\nIn this section, we will review several variables provided in the water point data that was downloaded from WPdx Global Data Repositories to be considered for clustering variables. To perform regionalisation of the LGAs based on the water points, we are interested in the following attributes for the water points:\n\nHow accessible is the water point, i.e. do we need to travel long distances to get to the water point?\nHow many people can be served by the water point?\nAre the water points still functioning?\nAre the water points using hand pump technology (i.e. the most common technology for water supply in rural communities)?\nAre there fees incurred for using the water point?\n\n\n5.1 Loading data and recoding NA values into string for status_clean field\nWe will first load the data in rds format. In the following code chunk, we will also rename the column from #status_clean to status_clean for easier handling in subsequent steps. In addition, replace_na() is used to recode all the NA values in status_clean into unknown.\n\nwp <- read_rds(\"geodata/wp.rds\") %>% \n    rename('status_clean' = '#status_clean') %>% \n    mutate(status_clean = replace_na(status_clean, \"unknown\"))\n\n\n\n5.2 EDA for distance attributes\nWe can plot multiple histograms together in the same plot to reveal the distribution of various variables. We can do this by first creating the individual histograms and then using ggarange() function from ggpubr package is used to group these histograms together.\nThere are 5 distance variables in wp, namely, distance to primary road, distance to secondary road, distance to tertiary road, distance to city, and distance to town. We are interested in understanding the distances to travel to reach the water points as we postulate that water points that are more accessible would likely to be used more frequently, be better maintained, and remain functional. We will plot the histograms for these variables using the following code chunk.\n\nprimary <- ggplot(data=wp,\n                  aes(x=`#distance_to_primary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nsecondary <- ggplot(data=wp,\n                  aes(x=`#distance_to_secondary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ntertiary <- ggplot(data=wp,\n                  aes(x=`#distance_to_tertiary_road`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ncity <- ggplot(data=wp,\n                  aes(x=`#distance_to_city`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ntown <- ggplot(data=wp,\n                  aes(x=`#distance_to_town`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nggarrange(primary, secondary, tertiary, city, town, \n          ncol = 3,\n          nrow = 2)\n\n\nAccording to the data source for the description of these variables, the distances are measured in km. However, it is unlikely that the distances to reach the water points can go up to minimally 60,000 km (distance_to_tertiary_road). It is likely that some distances in the data set were recorded in metres and others in kilometers. As we are unable to tell the unit of measurement used for each water point record, we will not be using any of these distance variables in our subsequent analysis.\n\n\n5.3 EDA for status of water points\nWe are also interested in understanding the functionality of the water points, i.e. whether they are still functioning or not.\nIn the following code chunk, we use freq() to determine the number of records in each classification for the status of the water points.\n\nfreq(data = wp,\n     input = 'status_clean')\n\n\nIt can be observed that there are different classification within functional water points and within non-functional water points. For instance, for non-functional water points, they may be categorised as non-functional, and non-functional due to dry season. As such, we need to re-group the data to create 2 separate dataframes each containing either type of functional water points.\nIn addition, we will treat abandoned water points as non-functional.\n\n5.3.1 Extracting functionality of water points\nIn this section, we will extract the water point records by using classes in status_clean field. In the following code chunks, filter() from dplyr is used to select functional water points.\n\nwp_functional <- wp %>% \n    filter(status_clean %in% \n               c(\"Functional\",\n                 \"Functional but not in use\",\n                 \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp %>% \n    filter(status_clean %in% \n               c(\"Abandoned/Decommissioned\",\n                 \"Abandoned\",\n                 \"Non-Functional due to dry season\",\n                 \"Non-Functional\",\n                 \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp %>% \n    filter(status_clean == \"unknown\")\n\nTo check whether the filtering was performed correctly, we can run the following code chunks and reconcile the number of records with that in Section 4.5.2.\n\ntable(wp_functional$status_clean)\n\n\ntable(wp_nonfunctional$status_clean)\n\n\ntable(wp_unknown$status_clean)\n\nThe output shows that filtering was performed successfully.\n\n\n\n5.4 Extracting water points with hand pump technology\nIn the following code chunk, we want to see what are the types of water point technology listed in the data. From the output figures, we can also observe that the water point technology is not recorded for some of the records.\n\ntable(wp$`#water_tech_category`)\n\nFrom the results, we can tell that there are approximately 89% of the water points with the water technology information being recorded. Since this represents the majority (i.e. more than 80%), it remains to be a suitable variable to be used for subsequent analysis.\nWe can also see that the majority of the water points are built based on hand pump technology (approximately 62%). As such, we will want to extract water points that have this main water point technology (i.e. hand pump). Since there is only 1 category for hand pumps, we will extract water points with hand pump technology by specifying “Hand Pump”.\n\nwp_handpump <- wp %>% \n    filter(`#water_tech_category` %in% \"Hand Pump\")\n\n\n\n5.5 Extracting water points by their usage capacity\nWe will classify the usage capacity of water points as low if the maximum number of users that can be served by the water point is below 1000 and classify as high if the maximum number of users that can be served by the water point is 1000 and above.\nWe will first check whether the usage capacity is specified for all the water points. From the results, we are able to tell that the usage capacity for all water points are recorded.\n\nnrow(subset(wp, wp$usage_capacity < 1000))\nnrow(subset(wp, wp$usage_capacity >= 1000))\n\nIn the following code chunk, we will extract water points with low and high usage capacity respectively.\n\nwp_low_usage <- wp %>% \n    filter(usage_capacity < 1000)\nwp_high_usage <- wp %>% \n    filter(usage_capacity >= 1000)\n\n\n\n5.6 Extracting rural water points\nWe also expect that LGAs would differ by the number of water points that are in rural areas and in the urban areas. Likewise, we will first determine whether all water point records are classified as either urban or rural.\n\ntable(wp$is_urban)\n\nWe can see that the results add up to 95,008 which is the total number of records. Hence, there is no missing field for this column. Since the classification is binary, we will extract just one of them - rural.\nIn the following code chunk, we will extract the water points that are rural.\n\nwp_rural <- wp %>% \n    filter(is_urban %in% FALSE)\n\n\n\n5.7 Extracting water points with more than 50% crucialness_score\nAnother variable that we found useful for our analysis is the crucialness_score which is the ratio of likely current users to the total local population within a 1km radius of the water point. This can also serve as a substitute for the distance variables which we have identified as unsuitable for analysis previously in section 5.2.\nIn the following code chunk, we wanted to identify the number of water points with no crucialness_score recorded. From the results, we see that there are 6879 records (approximately 7% of all records) with missing crucialness score. Since the majority of the records have crucialness score, we can proceed with subsequent analysis.\n\nsum(is.na(wp$crucialness_score))\n\nIn the following code chunk, we will extract water points that are located within 1km of at least half of the total population, i.e. crucialness_score >= 0.5.\n\nwp_crucial <- wp %>% \n    filter(crucialness_score >=0.5)\n\n\n\n5.8 Extracting water points that do not require payment\nWe also expect LGAs to differ regionally based on whether the water points require payment for use. Likewise, we will first look at the different categories within this column. The results show that the records can be classified into - NA (11%), Yes (7%), and No (82%).\n\nfreq(data = wp,\n     input = '#pay')\n\n\nAlthough we have 11% missing data, the majority of the records are populated. Hence, we will proceed to using this variable by extracting water point records that do not require payment.\n\nwp_pay <- wp %>% \n    filter(`#pay` == \"No\")\n\n\n\n5.9 EDA for water points based on their pressure score\nWe are also interested in understanding whether the water points are stressed, i.e. serving more people than what it was built to support. For this, we can use the variable on pressure_score which is calculated based on the ratio of the number of people assigned to that water point over the theoretical maximum population which can be served based on the technology. Thus, a pressure_score of more than 100 implies that the water point is serving more than the recommended maximum.\nIn the following code chunk, we determine the number of water points that are serving below 80% of its recommended maximum capacity and those that are serving more than 80% of its recommended maximum capacity.\n\nnrow(subset(wp, wp$pressure_score < 80)) / 95008 * 100 \nnrow(subset(wp, wp$pressure_score >= 80)) / 95008 * 100\n\nThe results show that there are missing records, along with 92.6% of water points serving below 80% of its maximum and 0.1% serving above 80% of its maximum. Since we are only certain that 0.1% serve more than 80% of its maximum, this number of water points is too little for further analysis. Hence, we will not use this variable for subsequent analysis."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#performing-point-in-polygon-count",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#performing-point-in-polygon-count",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "6 Performing Point-in-Polygon Count",
    "text": "6 Performing Point-in-Polygon Count\nWe want to find the number of water points in each LGA - including total, functional, non-functional, unknown functionality status, hand pump technology, low usage capacity, high usage capacity, and rural water points. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects(). Next, length() is used to calculate the number of such water points that fall inside each LGA.\n\nnga_wp <- nga_sf %>% \n    mutate(`total_wp` = lengths(\n        st_intersects(nga_sf, wp))) %>%\n    mutate(`wp_functional` = lengths(\n        st_intersects(nga_sf, wp_functional))) %>%\n    mutate(`wp_nonfunctional` = lengths(\n        st_intersects(nga_sf, wp_nonfunctional))) %>%\n    mutate(`wp_unknown` = lengths(\n        st_intersects(nga_sf, wp_unknown))) %>% \n    mutate(`wp_handpump` = lengths(\n        st_intersects(nga_sf, wp_handpump))) %>% \n    mutate(`wp_low_usage` = lengths(\n        st_intersects(nga_sf, wp_low_usage))) %>%\n    mutate(`wp_high_usage` = lengths(\n        st_intersects(nga_sf, wp_high_usage))) %>%\n    mutate(`wp_rural` = lengths(\n        st_intersects(nga_sf, wp_rural))) %>% \n    mutate(`wp_pay` = lengths(\n        st_intersects(nga_sf, wp_pay))) %>% \n    mutate(`wp_crucial` = lengths(\n        st_intersects(nga_sf, wp_crucial)))  \n\n\n6.1 Transforming the projection from wgs84 to EPSG: 26391\nIn this section, we will transform the geographic coordinate system to the projected coordinate system. This is because in the subsequent section, we will be performing adaptive distance weighting and geographic coordinate system is not appropriate for such steps.\nIn the following code chunk, we use st_transform() of sf package to perform the projection transformation.\n\nnga_wp <- st_transform(nga_wp,\n                       crs = 26391)\n\n\n\n6.2 Saving the Analytical Data Table\nNow that we have the tidy sf data table, we will save it in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")\n\n\n\n6.3 Performing Feature Engineering\nWe will tabulate the proportion of each type of water points against the total number of water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive these additional fields.\n\nnga_wp <- read_rds(\"geodata/nga_wp.rds\")\nnga_wp <- nga_wp %>% \n    mutate(pct_functional = wp_functional/total_wp) %>% \n    mutate(pct_nonfunctional = wp_nonfunctional/total_wp) %>% \n    mutate(pct_handpump = wp_handpump/total_wp) %>% \n    mutate(pct_lowusage = wp_low_usage/total_wp) %>% \n    mutate(pct_highusage = wp_high_usage/total_wp) %>% \n    mutate(pct_rural = wp_rural/total_wp) %>% \n    mutate(pct_pay = wp_pay/total_wp) %>% \n    mutate(pct_crucial = wp_crucial/total_wp)\n\nAs we performed a division in the previous step, we will want to check if there is any NA values in the columns for pct_functional and pct_nonfunctional.\n\nif (any(is.na(nga_wp$pct_functional))){print(\"NA values in pct_functional\")}\n\n[1] \"NA values in pct_functional\"\n\nif (any(is.na(nga_wp$pct_nonfunctional))){print(\"NA values in pct_nonfunctional\")}\n\n[1] \"NA values in pct_nonfunctional\"\n\n\nFrom the printout, we are able to tell that there are NA values in both pct_functional and pct_nonfunctional columns.\nThis is likely due to 0 total water points in these LGAs. If we impute 0 into the pct_nonfunctional column for these LGAs with 0 water points, we may incorrectly regard these LGAs to have very low proportion of non-functional water points and lead to an incorrect analysis when performing spatial distribution analysis. As such, we will exclude LGAs with 0 water points from our analysis.\nIn the following code chunk, we want to calculate the number of LGAs with no water points. This is done by using nrow() to calculate the total number of LGAs in nga_wp and in nga_wp_filter.\n\nnrow(subset(nga_wp, total_wp == 0))\n\n[1] 13\n\n\nFrom the printout, we can see that there are 13 LGAs will 0 water points.\nIn the following code chunk, we retrieve only rows with non-zero total number of water points by using subset() and exclude the LGAs with 0 water points.\n\nnga_wp_filter <- subset(nga_wp, total_wp != 0)\n\nIn addition, we also want to exclude LGAs whereby the status of all their water points are unknown. This is because we are unable to deduce the number of functional or non-functional water points in these LGAs. Also, the values in the pct_functional and pct_nonfunctional columns for these LGAs are 0 which will affect our subsequent analysis like what we have discussed earlier.\nLikewise, we calculate the number of such LGAs first.\n\nnrow(subset(nga_wp_filter, total_wp == wp_unknown))\n\n[1] 8\n\n\nFor the printout, we can see that there are 8 LGAs whereby the status of all their water points are unknown.\nIn the following code chunk, we use filter() to exclude these LGAs.\n\nnga_wp <- subset(nga_wp, total_wp != wp_unknown)"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#extracting-cluster-variables",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#extracting-cluster-variables",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "7 Extracting cluster variables",
    "text": "7 Extracting cluster variables\n\n7.1 Extracting cluster variables\nIn the following code chunk, we are extracting the clustering variables from the nga_wp_filter simple feature object into a data.frame. We will exclude both the pct_lowusage and pct_highusage variables. We will also remove the geometry field by setting it to null (as we will not be able to exclude the geometry column by using select().\n\ncluster_vars <- nga_wp %>%\n  st_set_geometry(NULL) %>%\n  select(\"shapeName\", \"wp_functional\", \"wp_nonfunctional\", \"pct_functional\", \"pct_nonfunctional\", \"pct_handpump\", \"pct_lowusage\", \"pct_highusage\", \"pct_rural\", \"pct_pay\", \"pct_crucial\")\nhead(cluster_vars,10)\n\n        shapeName wp_functional wp_nonfunctional pct_functional\n1       Aba North             7                9      0.4117647\n2       Aba South            29               35      0.4084507\n4           Abaji            23               34      0.4035088\n5            Abak            23               25      0.4791667\n6       Abakaliki            82               42      0.3519313\n7  Abeokuta North            16               15      0.4705882\n8  Abeokuta South            72               33      0.6050420\n9             Abi            79               62      0.5197368\n10    Aboh-Mbaise            18               26      0.2727273\n11     Abua/Odual            25               13      0.6410256\n   pct_nonfunctional pct_handpump pct_lowusage pct_highusage  pct_rural\n1          0.5294118   0.11764706   0.17647059     0.8235294 0.00000000\n2          0.4929577   0.09859155   0.12676056     0.8732394 0.05633803\n4          0.5964912   0.40350877   0.40350877     0.5964912 0.84210526\n5          0.5208333   0.08333333   0.08333333     0.9166667 0.83333333\n6          0.1802575   0.43776824   0.90557940     0.0944206 0.87553648\n7          0.4411765   0.14705882   0.23529412     0.7647059 0.20588235\n8          0.2773109   0.16806723   0.29411765     0.7058824 0.00000000\n9          0.4078947   0.59868421   0.67105263     0.3289474 0.95394737\n10         0.3939394   0.01515152   0.34848485     0.6515152 0.72727273\n11         0.3333333   0.30769231   0.33333333     0.6666667 0.53846154\n     pct_pay pct_crucial\n1  0.9411765  0.47058824\n2  0.8732394  0.32394366\n4  0.6315789  0.56140351\n5  0.9375000  0.75000000\n6  0.5278970  0.15021459\n7  0.7941176  0.38235294\n8  0.8571429  0.09243697\n9  0.9013158  0.13815789\n10 0.6363636  0.75757576\n11 0.9230769  0.35897436\n\n\nNext, we will use the LGA name as the row names instead of using the row number. In this way, we will preserve the LGA name in our dataframe and still, the LGA names will not be used as a clustering variable.\n\nrow.names(cluster_vars) <- cluster_vars$\"shapeName\"\nhead(cluster_vars,10)\n\n                    shapeName wp_functional wp_nonfunctional pct_functional\nAba North           Aba North             7                9      0.4117647\nAba South           Aba South            29               35      0.4084507\nAbaji                   Abaji            23               34      0.4035088\nAbak                     Abak            23               25      0.4791667\nAbakaliki           Abakaliki            82               42      0.3519313\nAbeokuta North Abeokuta North            16               15      0.4705882\nAbeokuta South Abeokuta South            72               33      0.6050420\nAbi                       Abi            79               62      0.5197368\nAboh-Mbaise       Aboh-Mbaise            18               26      0.2727273\nAbua/Odual         Abua/Odual            25               13      0.6410256\n               pct_nonfunctional pct_handpump pct_lowusage pct_highusage\nAba North              0.5294118   0.11764706   0.17647059     0.8235294\nAba South              0.4929577   0.09859155   0.12676056     0.8732394\nAbaji                  0.5964912   0.40350877   0.40350877     0.5964912\nAbak                   0.5208333   0.08333333   0.08333333     0.9166667\nAbakaliki              0.1802575   0.43776824   0.90557940     0.0944206\nAbeokuta North         0.4411765   0.14705882   0.23529412     0.7647059\nAbeokuta South         0.2773109   0.16806723   0.29411765     0.7058824\nAbi                    0.4078947   0.59868421   0.67105263     0.3289474\nAboh-Mbaise            0.3939394   0.01515152   0.34848485     0.6515152\nAbua/Odual             0.3333333   0.30769231   0.33333333     0.6666667\n                pct_rural   pct_pay pct_crucial\nAba North      0.00000000 0.9411765  0.47058824\nAba South      0.05633803 0.8732394  0.32394366\nAbaji          0.84210526 0.6315789  0.56140351\nAbak           0.83333333 0.9375000  0.75000000\nAbakaliki      0.87553648 0.5278970  0.15021459\nAbeokuta North 0.20588235 0.7941176  0.38235294\nAbeokuta South 0.00000000 0.8571429  0.09243697\nAbi            0.95394737 0.9013158  0.13815789\nAboh-Mbaise    0.72727273 0.6363636  0.75757576\nAbua/Odual     0.53846154 0.9230769  0.35897436\n\n\nWe can then delete the column for shapeName.\n\nnga_wp_cluster <- select(cluster_vars, c(2:11))\nhead(nga_wp_cluster, 10)\n\n               wp_functional wp_nonfunctional pct_functional pct_nonfunctional\nAba North                  7                9      0.4117647         0.5294118\nAba South                 29               35      0.4084507         0.4929577\nAbaji                     23               34      0.4035088         0.5964912\nAbak                      23               25      0.4791667         0.5208333\nAbakaliki                 82               42      0.3519313         0.1802575\nAbeokuta North            16               15      0.4705882         0.4411765\nAbeokuta South            72               33      0.6050420         0.2773109\nAbi                       79               62      0.5197368         0.4078947\nAboh-Mbaise               18               26      0.2727273         0.3939394\nAbua/Odual                25               13      0.6410256         0.3333333\n               pct_handpump pct_lowusage pct_highusage  pct_rural   pct_pay\nAba North        0.11764706   0.17647059     0.8235294 0.00000000 0.9411765\nAba South        0.09859155   0.12676056     0.8732394 0.05633803 0.8732394\nAbaji            0.40350877   0.40350877     0.5964912 0.84210526 0.6315789\nAbak             0.08333333   0.08333333     0.9166667 0.83333333 0.9375000\nAbakaliki        0.43776824   0.90557940     0.0944206 0.87553648 0.5278970\nAbeokuta North   0.14705882   0.23529412     0.7647059 0.20588235 0.7941176\nAbeokuta South   0.16806723   0.29411765     0.7058824 0.00000000 0.8571429\nAbi              0.59868421   0.67105263     0.3289474 0.95394737 0.9013158\nAboh-Mbaise      0.01515152   0.34848485     0.6515152 0.72727273 0.6363636\nAbua/Odual       0.30769231   0.33333333     0.6666667 0.53846154 0.9230769\n               pct_crucial\nAba North       0.47058824\nAba South       0.32394366\nAbaji           0.56140351\nAbak            0.75000000\nAbakaliki       0.15021459\nAbeokuta North  0.38235294\nAbeokuta South  0.09243697\nAbi             0.13815789\nAboh-Mbaise     0.75757576\nAbua/Odual      0.35897436\n\n\nNow that our data.frame only contains clustering variables as attributes, we can perform clustering using this data.frame.\n\n\n7.2 Data standardisation\nNext, we will evaluate the need for data standardisation. The purpose of the data standardisation is to avoid using variables with vastly different range of values as cluster analysis would be biased towards clustering variables with larger values.\nIn the following code chunk, we want to plot the range of values across all variables using boxplot.\n\nggplot(stack(nga_wp_cluster), aes(x=values, y=ind)) +\n    geom_boxplot()\n\n\n\n\nWe can see that the range of the values across all variables differ quite significantly, as such, we will need to perform data standardisation. In addition, we can see that for both the attributes wp_nonfunctional and wp_functional, there are significant outliers. For instance, for wp_functional, the Q3 is below 100, but it also has data points with values over 800 (i.e. 8 times higher).\n\n7.2.1 Log transformation for highly skewed variables\nWe will need to transform these variable to manage the skewness. This is because we will be performing custering using Ward’s method which aims at finding compact, spherical clusters [3] and outliers would hinder the formation of spherical clusters. One way of managing the skewed distribution is to perform log transformation. In the following code chunk, we will use mutate() from dplyr package to do the log transformation. We will add 1 to the value for wp_nonfunctional and wp_nonfunctional when performing the log transformation to avoid getting negative infinity values (i.e. log0) when there is no functional water points of no non-functional water point in the LGA.\n\nnga_wp_cluster <- nga_wp_cluster %>% \n    mutate(`log_wp_nonfunctional` = log(wp_nonfunctional + 1))\nnga_wp_cluster <- nga_wp_cluster %>% \n    mutate(`log_wp_functional` = log(wp_functional + 1))\n\nThere are 2 common approaches to perform data standardisation, namely min-max scaling and z-score standardisation. With Min-Max scaling, we scale the data values for each variable to a range of 0 to 1. With Z-score standardisation, we will scale each variable to have mean to be 0 and standard deviation to be 1. However, z-score standardisation assumes that all variables come from a normal distribution.\n\n\n7.2.2 Visualising graphical distribution of variable values\nWe use the following code chunk to plot the distribution of the variable values to understand if the variables follow a normal distribution.\n\nfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`log_wp_functional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nnonfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`log_wp_nonfunctional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npct_funct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_functional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npct_nonfunct <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_nonfunctional`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nlowusage <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_lowusage`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nrural <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_rural`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\ncrucial <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_crucial`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\npay <- ggplot(data=nga_wp_cluster,\n                  aes(x=`pct_pay`)) +\n    geom_histogram(bins=20,\n                   color=\"black\",\n                   fill=\"light blue\")\n\nggarrange(funct, nonfunct, pct_funct, pct_nonfunct, lowusage, rural, crucial,\n          pay,\n          ncol = 4,\n          nrow = 2)\n\n\n\n\nWe observe that the distribution of most of the variables are skewed and do not follow a normal distribution. For instance, pct_pay has a leftskew. As such, it is not suitable to use the Z-score normalisation.\n\n\n7.2.3 Min-Max standardisation\nIn the code chunk below, we use normalise the values using Min-Max Scaling method. to standardise the clustering variables by using Min-Max method.\nTo perform this, we use normalize() from the heatmaply package. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nnga_wp_cluster <- nga_wp_cluster %>% \n    select(c(3:12))\nnga_wp.std <- normalize(nga_wp_cluster)\nsummary(nga_wp.std)\n\n pct_functional   pct_nonfunctional  pct_handpump     pct_lowusage   \n Min.   :0.0000   Min.   :0.0000    Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.3381   1st Qu.:0.2260    1st Qu.:0.1860   1st Qu.:0.4118  \n Median :0.4808   Median :0.3636    Median :0.5234   Median :0.6772  \n Mean   :0.5123   Mean   :0.3693    Mean   :0.4936   Mean   :0.6162  \n 3rd Qu.:0.6780   3rd Qu.:0.5085    3rd Qu.:0.7778   3rd Qu.:0.8718  \n Max.   :1.0000   Max.   :1.0000    Max.   :1.0000   Max.   :1.0000  \n pct_highusage      pct_rural         pct_pay        pct_crucial    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.1282   1st Qu.:0.6176   1st Qu.:0.6564   1st Qu.:0.1948  \n Median :0.3228   Median :0.8755   Median :0.8806   Median :0.3462  \n Mean   :0.3838   Mean   :0.7441   Mean   :0.8018   Mean   :0.3990  \n 3rd Qu.:0.5882   3rd Qu.:1.0000   3rd Qu.:0.9910   3rd Qu.:0.5714  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n log_wp_nonfunctional log_wp_functional\n Min.   :0.0000       Min.   :0.0000   \n 1st Qu.:0.4809       1st Qu.:0.4445   \n Median :0.6364       Median :0.5875   \n Mean   :0.5861       Mean   :0.5582   \n 3rd Qu.:0.7357       3rd Qu.:0.6793   \n Max.   :1.0000       Max.   :1.0000   \n\n\nWe can observe that the value range for each variable is now between 0 and 1 after min-max standardisation is performed.\nIn the following code chunk, we want to plot the boxplots of our standardised variables.\n\nggplot(stack(nga_wp.std), aes(x=values, y=ind)) +\n    geom_boxplot()\n\n\n\n\nWe can that the values of all the variables now have the same range of 0 to 1.\n\n\n\n7.3 Correlation Analysis\nIt is important for us to ensure that cluster variables are not highly correlated when we perform cluster analysis. This is because we do not want to give extra weight to variables that are highly correlated.\nWe will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation between the input variables. In the following code chunk, we have listed to plot both size of the ellipse and the correlation coefficient.\n\ncluster_vars.cor = cor(nga_wp.std)\ncorrplot.mixed(cluster_vars.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nIn the correlation plot above, the fatter the ellipse is, the more weakly correlated the 2 variables are. And the more the plot looks like a line, the more strongly correlated the 2 variables are.\nThe correlation plot above shows that pct_handpump, pct_lowusage, pct_highusage are highly correlated (absolute correlation coefficient of more than 0.8). This suggest that only one of them should be used in the cluster analysis. In the subsequent analysis, we will only keep pct_lowusage out of the 3 variables.\n\nnga_wp.std <- nga_wp.std %>% \n    select(c(1,2,4,6:10))"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#hierarchical-cluster-analysis",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#hierarchical-cluster-analysis",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "8 Hierarchical Cluster Analysis",
    "text": "8 Hierarchical Cluster Analysis\nIn this section, we will perform hierarchical cluster analysis.\n\n8.1 Computing the proximity matrix\nIn R, there are many packages that provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is the euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using the euclidean method.\n\nproxmat <- dist(nga_wp.std, method = 'euclidean')\n\n\n\n8.2 Computing the hierarchical clustering and selecting the optimal clustering algorithm\nThere are several ways to compute hierarchical clustering. This is because of the different linkage methods available to calculate the distance between clusters. The following provides explanations of 4 of the methods:\n\nAverage: Average linkage calculates all pairwise distances between cases in two clusters and finds the mean.\nSingle: Single linkage calculates the smallest distance between clusters.\nComplete: Complete linkage calculates the largest distance between clusters.\nWard: Ward’s method calculates the within-cluster sum of squares for each candidate merge and chooses the one with the smallest value.\n\nThe calculation involved in each algorithm is illustrated in the following diagram. [4]\n\nWe will use agnes() function from cluster package to perform hierarchical clustering. The advantage of using agnes() function is that we are able to get the agglomerative coefficient of the clusters obtained from each linkage calculation as described above. The agglomerative coefficient measures the amount of clustering structure found. The closer the coefficient is to 1, the stronger the clustering structure.\nIn the following code chunk, we will compute the agglomerative coefficient of the 4 hierarchical clustering algorithms: average, single, complete, and ward.\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(nga_wp.std, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8593888 0.7308851 0.9133358 0.9813123 \n\n\nWe can see that Ward’s method provides the strongest clustering structure among the four algorithms assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n8.3 Determining the optimal number of clusters\nWe will determine the optimal number of clusters using a gap statistic.\n\n8.3.1 Gap statistic method\nThe gap statistic compares the total intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be the value that maximizes the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is furthest away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used. We will set seed 12345 to make the results reproducible as the calculations involve bootstrapping via Monte Carlo simulations. In the following code chunk, we have specified the number of Monte Carlo samples to be 50 (argument B).\n\nset.seed(12345)\ngap_stat <- clusGap(nga_wp.std, \n                    FUN = hcut, \n                    nstart = 50, \n                    K.max = 15, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = nga_wp.std, FUNcluster = hcut, K.max = 15, B = 50, nstart = 50)\nB=50 simulated reference sets, k = 1..15; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 15\n          logW   E.logW       gap      SE.sim\n [1,] 5.137390 5.718702 0.5813113 0.006648681\n [2,] 5.022411 5.614708 0.5922971 0.008932878\n [3,] 4.937291 5.565173 0.6278823 0.008120822\n [4,] 4.854839 5.521356 0.6665169 0.008457641\n [5,] 4.786833 5.484661 0.6978283 0.008060724\n [6,] 4.734810 5.452071 0.7172616 0.007886372\n [7,] 4.704645 5.423129 0.7184839 0.007960364\n [8,] 4.671432 5.396554 0.7251225 0.008978215\n [9,] 4.643424 5.373001 0.7295764 0.009183705\n[10,] 4.611155 5.351348 0.7401934 0.008812894\n[11,] 4.590775 5.331388 0.7406126 0.008725164\n[12,] 4.567517 5.313391 0.7458738 0.008657314\n[13,] 4.548903 5.296951 0.7480483 0.008377341\n[14,] 4.531890 5.281489 0.7495997 0.008158335\n[15,] 4.512874 5.266705 0.7538306 0.008047420\n\n\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nThe results above reflect that the optimal number of clusters is 9.\n\n\n\n8.6 Visually-driven hierarchical clustering analysis\nWe can visualise the hierarchical clusters as a heatmap of the variables by using the heatmaply package. We will plot an interactive cluster heatmap for our visualisation.\nWe will first have to convert our data (which is in a data frame) into a data matrix to plot the heatmap. The code chunk below transforms the nga_wp.std data frame into a data matrix.\n\nnga_wp_mat <- data.matrix(nga_wp.std)\n\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(nga_wp_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 12,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 2,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of LGA by water point indicators\",\n          xlab = \"Water point indicators\",\n          ylab = \"LGA Names\"\n          )\n\n\n\n\n\nWe noticed several characteristics of the clusters (on going down the dendrogram):\n\n\n\n\n\n\n\n\nCluster\nColor on dendrogram\nSummary of key characteristics\n\n\n\n\n1\nDark Pink\n\nLow pct_pay\nHigh pct_crucial\n\n\n\n2\nPurple\n\nModerate to high pct_nonfunctional\nLow pct_functional\n\n\n\n3\nBlue\n\nModerate to high pct_nonfunctional\nLow pct_lowusage\nHigh pct_crucial\n\n\n\n4\nDark green\n\nHigh pct_functional\nLow pct_lowusage\nHigh pct_crucial\n\n\n\n5\nGreen\n\nHigh pct_lowusage\nHigh pct_functional\n\n\n\n6\nLight green\n\nLow to moderate pct_lowusage\n\n\n\n7\nYellow\n\nModerate pct_lowusage\nModerate pct_rural\nModerate pct_pay\n\n\n\n8\nOrange\n\nLow pct_rural\n\n\n\n9\nPink\n\nMostly moderate to high pct_functional\nHigh pct_lowusage\nLow pct_crucial\n\n\n\n\nFrom the analysis above, there is a distinction between each of the clusters. Hence, we will keep the clusters as 9.\n\n\n8.7 Mapping the clusters formed\nIn this section, we will map the clusters formed. We will use cutree() of R Base to derive a 9-cluster model in the following code chunk.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\ngroups <- as.factor(cutree(hclust_ward, k=12))\n\nThe output groups is a list object containing the cluster ID for each LGA.\nTo visualise the clusters, the group object needs to be appended onto the nga_wp simple feature object. This is performed using the code chunk below, in three steps as explained in the following:\n\nas.matrix() transforms the groups list into a matrix;\ncbind() appends the groups matrix onto nga_wp simple features to produce an output that is a simple feature;\nrename() is used to rename as.matrix.groups. field to H_CLUSTER\n\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) \n\n\nnga_wp <- nga_wp%>%\n  rename(`H_CLUSTER`=`as.matrix.groups.`)\n\nWe will then use qtm() from tmap package to plot the choropleth map to show the clusters.\n\nqtm(nga_wp, \"H_CLUSTER\")+\n    tm_layout(main.title = \"Hierarchical Clustering\",\n              main.title.size = 1.2,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nThe choropleth map above reveals that the clusters are very fragmented. This is a major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis is used for regionalisation.\nWe can also get the summary for each cluster by the mean of each clustering variables as shown in the following code chunk:\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(H_CLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 12 × 9\n   H_CLUSTER wp_functi…¹ wp_no…² pct_f…³ pct_n…⁴ pct_l…⁵ pct_r…⁶ pct_pay pct_c…⁷\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 1                29.4   27.6    0.364  0.410    0.474  0.407    0.704   0.498\n 2 10               16.5    3.53   0.789  0.189    0.458  0.837    0.892   0.605\n 3 11              185.    45.7    0.775  0.221    0.894  0.909    0.973   0.218\n 4 12               92      8.65   0.856  0.0979   0.788  0.820    0.897   0.202\n 5 2                44.0   36.5    0.500  0.444    0.350  0.909    0.831   0.365\n 6 3                16.6   30.1    0.329  0.641    0.158  0.882    0.890   0.711\n 7 4               101.    66.6    0.444  0.285    0.901  0.953    0.623   0.372\n 8 5                53.2   13.4    0.741  0.160    0.375  0.0647   0.753   0.102\n 9 6                81.0   74.4    0.477  0.452    0.749  0.876    0.864   0.295\n10 7                10.4   11.0    0.226  0.210    0.635  0.643    0.332   0.764\n11 8                31.1   67.1    0.293  0.660    0.639  0.957    0.925   0.592\n12 9                74.2   66.2    0.491  0.458    0.643  0.223    0.908   0.113\n# … with abbreviated variable names ¹​wp_functional, ²​wp_nonfunctional,\n#   ³​pct_functional, ⁴​pct_nonfunctional, ⁵​pct_lowusage, ⁶​pct_rural,\n#   ⁷​pct_crucial"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#spatially-constrained-clustering-skater-approach",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#spatially-constrained-clustering-skater-approach",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "9 Spatially Constrained Clustering: SKATER Approach",
    "text": "9 Spatially Constrained Clustering: SKATER Approach\nIn this section, we will derive spatially constrained clusters by using skater() method from spdep package.\n\n9.1 Converting data into SpatialPolygonsDataFrame\nWe will first need to convert nga_wp into a SpatialPolygonsDataFrame. This is because the SKATER function only supports sp objects such as the SpatialPolygonsDataFrame. We will perform this using as_Spatial() from sf package.\n\nnga_sp <- as_Spatial(nga_wp)\n\n\n\n9.2 Computing neighbour list\nNext, we will use poly2nb() from spdep package to compute the neighbours list object from the polygon list.\n\nnga.nb <- poly2nb(nga_sp)\nsummary(nga.nb)\n\nNeighbour list object:\nNumber of regions: 753 \nNumber of nonzero links: 4306 \nPercentage nonzero weights: 0.7594236 \nAverage number of links: 5.718459 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  19  54 121 175 136 122  68  39  11   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nWe can draw a graph representation of the neighbour structure. In the following code, we will plot the area boundaries first. This is followed by the plot of the neighbour list object. We also set the colour to blue and specify add=TRUE to plot the network on top of the boundaries.\n\nplot(nga_sp, \n     border=grey(.5))\nplot(nga.nb, \n     coordinates(nga_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n9.3 Computing minimum spanning tree\nThe SKATER algorithm uses a minimum spanning tree (MST) for the records in its calculation. The MST is a graph that includes all nodes in the network but only passes each node once. This way, the complexity of the graph is minimised since each node is connected to only one other node. The resulting tree has n nodes and n-1 edges. The objective of the calculation is to minimise the overall length (or cost) of the tree. This cost can be regarded as the distances between the nodes.\n\n9.3.1 Calculating edge costs\nWe will first need to compute the edge cost associated with each edge in the neighbour list. This cost refers to the dissimilarity between each pair of neighbours (as defined by the neighbours list). The following code chunk is used to compute the cost of each edge.\n\nlcosts <- nbcosts(nga.nb, nga_wp.std)\nhead(lcosts)\n\n[[1]]\n[1] 0.3536326 1.1899371 0.9014402 1.2349360\n\n[[2]]\n[1] 0.3536326 0.9186816 1.2223945\n\n[[3]]\n[1] 0.6620588 0.5190259 0.3979035 0.2587433 0.5173919 0.8569923 0.4173404\n\n[[4]]\n[1] 0.2524283 0.2540906 0.2197327 0.5206340 0.2918747\n\n[[5]]\n[1] 0.3692014 0.2230920 0.2309250 0.2660426 0.5865552 0.5071292 0.4074526\n\n[[6]]\n[1] 0.4954322 0.9155222 1.0797754 0.7592068 1.4396427 0.9956611\n\n\nFor each LGA, this gives the pairwise dissimilarity between its values on the eight clustering variables and its neighbour’s corresponding values. Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, we will convert the neighbour list to a list weights object by using the computed lcosts as the weights. To do this, we use nb2listw() of spdep package as shown in the code chunk below. We need to specify the style as B to make sure the cost values are not row-standardised.\n\nnga.w <- nb2listw(nga.nb,\n                  lcosts,\n                  style=\"B\")\nsummary(nga.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 753 \nNumber of nonzero links: 4306 \nPercentage nonzero weights: 0.7594236 \nAverage number of links: 5.718459 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  2  19  54 121 175 136 122  68  39  11   4   1   1 \n2 least connected regions:\n138 560 with 1 link\n1 most connected region:\n508 with 14 links\n\nWeights style: B \nWeights constants summary:\n    n     nn       S0       S1       S2\nB 753 567009 2529.579 3730.059 41258.65\n\n\n\n\n9.3.2 Computing minimum spanning tree\nThe minimium spanning tree is computed by mean of the mstree() from spdep package as shown in the code chunk below. The result is a special type of matrix and it summarises the tree by giving each edge as the pair of connected nodes and the cost associated with that edge.\n\nnga.mst <- mstree(nga.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(nga.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(nga.mst)\n\n[1] 752   3\n\n\nWe can see that the dimension is 752 instead of 753 (i.e. the total number of LGAs considered for clustering). This is because the minimum spanning tree consists of n-1 edges that traverses all the nodes.\nWe can display the contbt using head() as shown in the following code chunk.\n\nhead(nga.mst)\n\n     [,1] [,2]      [,3]\n[1,]   35  738 0.1679360\n[2,]   35  103 0.1963871\n[3,]   35  441 0.2063681\n[4,]  103  660 0.2401118\n[5,]  660   86 0.2445948\n[6,]   86  395 0.3582598\n\n\n\n\n\n9.4 Computing spatially constrained clusters using SKATER method\nThe skater() function takes three mandatory arguments: the first two columns of the MST matrix (i.e. not the costs), the standardized data matrix (to update the costs as units are being grouped), and the number of cuts. The value specified for the number of cuts is not the number of clusters, but instead, the number of cuts in the graph, i.e. one less than the number of clusters.\n\nclust12 <- spdep::skater(edges = nga.mst[,1:2], \n                 data = nga_wp.std, \n                 method = \"euclidean\", \n                 ncuts = 11)\n\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust12)\n\nList of 8\n $ groups      : num [1:753] 2 2 3 2 7 3 3 7 2 2 ...\n $ edges.groups:List of 12\n  ..$ :List of 3\n  .. ..$ node: num [1:164] 434 710 151 459 633 686 419 35 636 432 ...\n  .. ..$ edge: num [1:163, 1:3] 459 419 633 35 636 432 686 49 238 151 ...\n  .. ..$ ssw : num 66.6\n  ..$ :List of 3\n  .. ..$ node: num [1:187] 568 605 354 530 60 575 9 59 540 297 ...\n  .. ..$ edge: num [1:186, 1:3] 354 530 505 417 616 9 9 184 575 60 ...\n  .. ..$ ssw : num 110\n  ..$ :List of 3\n  .. ..$ node: num [1:205] 358 27 28 167 69 68 529 589 214 247 ...\n  .. ..$ edge: num [1:204, 1:3] 644 89 214 366 247 119 727 71 34 16 ...\n  .. ..$ ssw : num 96.8\n  ..$ :List of 3\n  .. ..$ node: num [1:41] 707 558 598 280 22 209 516 695 183 298 ...\n  .. ..$ edge: num [1:40, 1:3] 22 280 516 183 558 298 707 77 598 281 ...\n  .. ..$ ssw : num 23.1\n  ..$ :List of 3\n  .. ..$ node: num [1:14] 50 602 315 21 672 201 286 31 448 496 ...\n  .. ..$ edge: num [1:13, 1:3] 50 21 286 315 201 672 672 315 315 50 ...\n  .. ..$ ssw : num 5.7\n  ..$ :List of 3\n  .. ..$ node: num [1:34] 403 396 450 621 471 231 157 88 381 728 ...\n  .. ..$ edge: num [1:33, 1:3] 403 403 450 396 381 744 231 621 88 471 ...\n  .. ..$ ssw : num 10.3\n  ..$ :List of 3\n  .. ..$ node: num [1:15] 13 351 556 211 580 525 5 555 164 17 ...\n  .. ..$ edge: num [1:14, 1:3] 556 556 164 555 525 580 211 17 5 211 ...\n  .. ..$ ssw : num 4.69\n  ..$ :List of 3\n  .. ..$ node: num [1:26] 251 655 483 154 67 493 241 666 480 237 ...\n  .. ..$ edge: num [1:25, 1:3] 483 493 67 655 136 237 237 67 237 655 ...\n  .. ..$ ssw : num 15.9\n  ..$ :List of 3\n  .. ..$ node: num [1:17] 746 128 372 499 216 427 461 377 684 219 ...\n  .. ..$ edge: num [1:16, 1:3] 216 427 499 377 746 401 372 461 684 128 ...\n  .. ..$ ssw : num 9.82\n  ..$ :List of 3\n  .. ..$ node: num [1:13] 535 565 329 724 324 200 567 174 716 648 ...\n  .. ..$ edge: num [1:12, 1:3] 724 324 174 724 567 535 565 329 200 724 ...\n  .. ..$ ssw : num 6.21\n  ..$ :List of 3\n  .. ..$ node: num [1:31] 577 305 630 265 523 266 208 170 306 268 ...\n  .. ..$ edge: num [1:30, 1:3] 577 265 577 305 306 630 537 266 170 305 ...\n  .. ..$ ssw : num 18.1\n  ..$ :List of 3\n  .. ..$ node: num [1:6] 682 400 500 138 213 254\n  .. ..$ edge: num [1:5, 1:3] 682 400 682 682 400 500 138 213 400 254 ...\n  .. ..$ ssw : num 1.99\n $ not.prune   : NULL\n $ candidates  : int [1:12] 1 2 3 4 5 6 7 8 9 10 ...\n $ ssto        : num 485\n $ ssw         : num [1:12] 485 454 436 423 414 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:753] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector that contains the labels of the cluster to which each observation belongs . This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment using the following.\n\nccs12 <- clust12$groups\nccs12\n\n  [1]  2  2  3  2  7  3  3  7  2  2  3  3  7 11  3  3  7  2  3  3  5  4  3  2  2\n [26]  2  3  3  3  3  5  1  2  3  1  2  3  3  2  3  2  2  3  3  3  1  3  5  1  5\n [51]  4  4  4  2  4  2  2  1  2  2  6  3  3  2  3  2  8  3  3  3  3  3  1  6  4\n [76]  4  4  4  1 11  9  3  1  1  1  1  6  6  3  3  6  1  1  1  1  1  1  2  2  2\n[101]  1  3  1  1  3  1  1  1  3  1  8  3  1  2  6  3  2  2  3  3  3  2  1  1  1\n[126]  1  3  9  2  2  3  2  2  3  1  8  1 12  9  1  1  1  3  1  3  1  1  1  1  1\n[151]  1  2  2  8  1  3  6  1  4  1  1  1  2  7  3  3  3  3  3 11 11 11  3 10  2\n[176]  3  2  2  3  3  3  3  4  2  2  3  4  4  4 11  2  2  2  2  2  2  2  2 10 10\n[201]  5  2  2  2  2  2  2 11  4  2  7  7 12  3  1  9  8  1  9  1  1  3  1  1  1\n[226]  8  1  1  1  6  6  1  3  2  1  1  8  1  2  1  8  3  3  9  2  1  3  3  1  1\n[251]  8  3  3 12  3  1  1  2  2  1  1  8  8 11 11 11 11 11  2  3  3  3 11  2  2\n[276]  6  2  2  3  4  4  4  4  3  3  5  3  3  3  3  3  3  3  3 11  1  2  4  4  4\n[301]  2  2  2 11 11 11 11  3  3  2  2  2  1  2  5 11  3  3  2  2 11  2  2 10  2\n[326]  7  2  3 10  3  3  3  3  3  3  3  3 11  1  2 11 10  3  3  3  3  3  1  3  3\n[351]  7  2  2  2  2  3  2  3  2  2  2  1  3  2  2  3  3  7  3  8  1  9  6  1  3\n[376]  3  9  1  6  6  6  3  1  3  1  1  1  1  3  3  1  3  1  3  1  6  1  6  1 12\n[401]  9  1  6  3  1  3  1  2  1  3  1  3  1  2  3  3  2  1  1  1  1  1  3  3  3\n[426]  2  9  2  3  5  1  1  3  1  1  1  1  6  1  3  1  2  3  8  3  3  5  5  8  6\n[451]  6  3  6  3  1  2  3  1  1  3  9  1  9  1  8  3  1  3  1  1  6  1  1  3  1\n[476]  1  3  1  1  8  2  2  8  1  6  1  1  2  3  3  3  3  8  8  1  5  3  1  9 12\n[501]  3  3  2  2  2  3  2  1  1  2  4  4  4  4  4  4  2  2  2  4  8  2 11  2  7\n[526]  2  2  2  3  2  2  2  2 11 10  3 11  2  3  2  2  2  2  2  3  3  3  2  2  2\n[551] 11  2  2  2  7  7  2  4 11  7  3  3  3  2 10  2 10  2  2  3  2  3  3 11  2\n[576]  2 11  3  3  7  4  2  2  2 10  3  2  3  3  4  3  2  4  2  2  2  4  4  2  2\n[601]  2  5  2  3  2  2  2  2  2  2  2  2  3  3  4  2  3  3  3  3  6  2  3  2  9\n[626]  6  1  3  1 11  3  1  1  1  6  1  1  1  3  1  1  2  3  3  3  1  3 10  6 11\n[651]  3  3  8  1  8  6  1  1  3  1  5  3  1  3  3  8  2  1  3  1  3  5  3  3  1\n[676]  2  1  6  1  3  3 12  2  9  1  1  1  3  8  1  1  1  3  4  4  2  2  2  2  2\n[701]  2  2  2  2  2  2  4  2  2  1  4  2  2  2  6 10  2  4  2  3  3  1  1 10  2\n[726]  2  3  6  1  6  3  3  3  3  3  2  2  1  1  3  2  8  8  6  9  9  1  1  1  1\n[751]  6  1  3\n\n\nWe can also found out the number of LGAs in each cluster by means of the table() command.\n\n\n9.5 Visualising the clusters on a choropleth map\nFinally, we can illustrate the clustering on the map.\n\ngroups_mat <- as.matrix(clust12$groups)\nnga_wp <- cbind(nga_wp, as.factor(groups_mat)) %>%\n  rename(`Skater_CLUSTER`=`as.factor.groups_mat.`)\nqtm(nga_wp, \"Skater_CLUSTER\")+\n    tm_layout(main.title = \"SKATER Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nLikewise, we can get a summary of the water point attributes for each cluster using the following code chunk.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(Skater_CLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 12 × 9\n   Skater_CLUS…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n   <fct>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 1               151.    49.5    0.730   0.269   0.861  0.860    0.937  0.261 \n 2 2                25.6   34.2    0.380   0.493   0.396  0.808    0.816  0.585 \n 3 3                67.2   57.9    0.496   0.424   0.646  0.711    0.854  0.279 \n 4 4                11.2    8.90   0.279   0.209   0.653  0.555    0.370  0.679 \n 5 5                37.5    9.93   0.665   0.135   0.315  0.0147   0.634  0.198 \n 6 6                88.3   73.1    0.400   0.344   0.869  0.884    0.626  0.385 \n 7 7               108.    58.7    0.409   0.235   0.910  0.936    0.616  0.231 \n 8 8                15.2    3.69   0.716   0.284   0.646  0.720    0.890  0.619 \n 9 9                50.6   11.4    0.778   0.168   0.279  0.746    0.831  0.364 \n10 10               17.8   32.9    0.359   0.623   0.159  0.548    0.977  0.623 \n11 11               37.1   33.7    0.378   0.303   0.449  0.546    0.595  0.436 \n12 12               89.3   31.3    0.760   0.240   0.723  0.0132   0.918  0.0125\n# … with abbreviated variable names ¹​Skater_CLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\nFor easier comparison, we will plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other using the code chunk below.\n\nhclust.map <- qtm(nga_wp,\n                  \"H_CLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nskclust.map <- qtm(nga_wp,\n                   \"Skater_CLUSTER\") + \n  tm_borders(alpha = 0.5)+\n    tm_layout(main.title = \"SKATER Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(hclust.map, skclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\nAs expected, the clusters formed from spatially constrained clustering is much more geographically cohesive compared to those formed from hierarchical clustering."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#spatially-constrained-clustering-using-clustgeo",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#spatially-constrained-clustering-using-clustgeo",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "10 Spatially Constrained Clustering using ClustGeo",
    "text": "10 Spatially Constrained Clustering using ClustGeo\nClustGeo package implements a Ward-like hierarchical clustering algorithm that includes spatial/geographical constraints. The algorithm takes in two dissimilarity matrices D0 and D1, along with a mixing parameter alpha in that ranges from 0 to 1 (both inclusive). The dissimilarities can be non-Euclidean and the weights of the observations can be non-uniform. The first matrix gives the dissimilarities in the varible space and the second matrix gives the dissimilarities in the spatial space. The idea is to determine a value of alpha which increases the spatial contiguity without deteriorating too much on the quality of the solution calculated based on the variables.\n\n10.1 Ward-like hierarchical clustering: ClustGeo\nThe ClustGeo package provides the function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() that was used in section 8.8.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the dissimilarity matrix as shown in the following code chunk. The dissimilarity matrix provided here must be an object of class dist, i.e. an object that is obtained using dist().\n\nnongeo_cluster <- hclustgeo(proxmat)\n\n\n10.1.1 Mapping the clusters formed\nSimilarly, we can visualise the clusters on the map.\n\ngroups <- as.factor(cutree(nongeo_cluster, k=9))\n\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_HCLUSTER` = `as.matrix.groups.`)\n\n\nqtm(nga_wp, \"ClustG_HCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Hierarchical Clustering\",\n              main.title.size = 1.1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nAgain, the choropleth map above reveals that the clusters formed by using hierarchical analysis are very fragmented spatially.\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_HCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_HCLUS…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 65.4   53.8    0.510   0.435   0.491  0.189    0.880   0.145\n2 2                 41.2   51.9    0.427   0.524   0.434  0.934    0.869   0.416\n3 3                 13.5   25.7    0.319   0.652   0.162  0.819    0.897   0.748\n4 4                 78.2   71.6    0.429   0.434   0.791  0.897    0.800   0.368\n5 5                 32.8   33.9    0.322   0.376   0.539  0.476    0.618   0.486\n6 6                 42.4    4.22   0.816   0.139   0.560  0.859    0.874   0.456\n7 7                 46.8    5.56   0.784   0.105   0.420  0.0817   0.758   0.112\n8 8                 10.3    8.94   0.225   0.171   0.688  0.643    0.285   0.777\n9 9                166     41.8    0.771   0.220   0.880  0.878    0.948   0.222\n# … with abbreviated variable names ¹​ClustG_HCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\n\n\n\n10.2 Spatially Constrained Hierarchical Clustering\nNext, we will perform clustering with spatial constraints. We will first need to compute a spatial matrix by using st_distance() from sf package. The function as.dist() is used to convert the data frame into a matrix.\n\ndist <- st_distance(nga_wp, nga_wp)\ndistmat <- as.dist(dist)\n\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=9, graph = TRUE)\n\n\n\n\n\n\n\nThe parameter alpha in [0,1] sets the importance of D0 and D1 in the clustering process. When alpha=0, the geographical dissimilarities are not taken into account and when alpha=1 the distances between water point attributes are not taken into account and the clusters are obtained with the geographical distances only.\nWe can also derive the exact proportion of explained inertia using the code chunk below. The homogeneity Q0 (resp. Q1) is the proportion of explained inertia calculated with D0 (resp. D1).\n\ncr$Q\n\n                 Q0        Q1\nalpha=0   0.6110934 0.3127493\nalpha=0.1 0.5969818 0.4388276\nalpha=0.2 0.5584356 0.6132106\nalpha=0.3 0.5350727 0.7619119\nalpha=0.4 0.5320735 0.7932882\nalpha=0.5 0.4778384 0.8488475\nalpha=0.6 0.4598281 0.8522726\nalpha=0.7 0.3877859 0.9003558\nalpha=0.8 0.3816441 0.9108572\nalpha=0.9 0.3000988 0.9300956\nalpha=1   0.2514860 0.9383978\n\n\nThe plot and results show that the proportion of explained inertia with D0 (the water point attributes) is equal to 0.62 when alpha=0 and decreases when alpha increases (black line). On the other hand, the proportion of explained inertia calculated with D1 (the spatial distances) is equal to 0.94 when alpha=1 and decreases when alpha decreases (red line).\nHere, the results suggest to use alpha=0.2 which corresponds to a lost of water point attributes homogeneity by 6% and a significant gain in spatial homogeneity by 30%.\nWe will use alpha=0.2 in the following code chunk.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nNext, we will use cutree() to derive the cluster object.\n\ngroups <- as.factor(cutree(clustG, k=9))\n\nWe will then join back the group list with nga_wp polygon feature data frame by using the code chunk below.\n\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_SPCLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(nga_wp, \"ClustG_SPCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_SPCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_SPCLU…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                49.7    38.4    0.510   0.343   0.510   0.222   0.760   0.216\n2 2                58.0    60.2    0.401   0.465   0.556   0.883   0.805   0.348\n3 3                13.1    24.4    0.310   0.612   0.221   0.799   0.852   0.756\n4 4                81.0    70.2    0.383   0.368   0.863   0.931   0.682   0.403\n5 5                12.3     3.11   0.784   0.192   0.490   0.769   0.905   0.615\n6 6                 9.47    8.11   0.199   0.158   0.715   0.678   0.266   0.820\n7 7                77.7    61.6    0.548   0.446   0.810   0.903   0.929   0.374\n8 8               176.     34.2    0.827   0.169   0.884   0.887   0.975   0.210\n9 9                76.3    28.4    0.738   0.239   0.400   0.587   0.791   0.243\n# … with abbreviated variable names ¹​ClustG_SPCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\nAgain, for easier comparison, we will plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other using the code chunk below.\n\nHclust.map <- qtm(nga_wp,\n                  \"ClustG_HCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"ClustGeo Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nGclust.map <- qtm(nga_wp,\n                   \"ClustG_SPCLUSTER\") + \n  tm_borders(alpha = 0.5)+\n    tm_layout(main.title = \"ClustGeo Spatially Constrained Hierarchical Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(Hclust.map, Gclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\nWe can see that the clusters obtained by considering spatial constraints are less fragmented and has more geographical cohesion. In particular, the north west region has more geographical cohesion now (in spatially constrained hierarchical clustering).\n\n\n10.3 Neighbour Constrained Hierarchical Clustering\nIn this section, we will attempt to improve the geographical cohesion of the clusters using ClustGeo. To do this, we will use a different matrix of dissimilarities D1 which takes into consideration the neighborhood around each LGA account rather than using the geographical distance. In this way, LGAs with contiguous boundaries (sharing one or more boundary point) are considered as neighbours. The adjacency matrix A is the binary matrix of the neighbourhoods between the LGAs.\nWe will use poly2nb() from spdep package to compute the neighbours list object from the polygon list (similar to in Section 9.2).\n\nlist.nb <- poly2nb(nga_sp)\n\nWe will then use nb2mat() from spdep package to generate a weights matrix for the neighbour list obtained. In here, we have specified the style to be binary, so LGAs with contiguous boundaries will have the value of 1 assigned, otherwise 0. We will also set the diagonal to be 1 to prepare for deriving the dissimilarity matrix in the subsequent step.\n\nA <- nb2mat(list.nb, style=\"B\")\ndiag(A) <- 1\n\nThe dissimilarity matrix D1 is then 1 minus A.\n\nD1 <- as.dist(1-A)\n\nThe procedure for the choice of alpha is repeated here with the new matrix D1.\n\ncr <- choicealpha(proxmat, D1, range.alpha = seq(0, 1, 0.1), K=9, graph = TRUE)\n\n\n\n\n\n\n\n\ncr$Q\n\n                 Q0         Q1\nalpha=0   0.6110934 0.02952238\nalpha=0.1 0.5648664 0.04199819\nalpha=0.2 0.5300508 0.05007464\nalpha=0.3 0.4927255 0.05274461\nalpha=0.4 0.4572915 0.05705857\nalpha=0.5 0.4142787 0.06044429\nalpha=0.6 0.3669028 0.06305988\nalpha=0.7 0.3524382 0.06485877\nalpha=0.8 0.3145628 0.06549824\nalpha=0.9 0.2861065 0.06584010\nalpha=1   0.2470566 0.06567767\n\n\nIn the first plot, we can see that the explained inertia calculated with D1 (red curve) is much smaller than the explained inertia calculated with D0 (black curve). To overcome this problem, we will use the second plot, i.e. the normalized proportion of explained inertia (Qnorm) instead.\nWe will also obtain the normalised proportion of explained inertia using the following code chunk.\n\ncr$Qnorm\n\n             Q0norm    Q1norm\nalpha=0   1.0000000 0.4495041\nalpha=0.1 0.9243536 0.6394592\nalpha=0.2 0.8673810 0.7624302\nalpha=0.3 0.8063015 0.8030828\nalpha=0.4 0.7483169 0.8687667\nalpha=0.5 0.6779302 0.9203172\nalpha=0.6 0.6004038 0.9601419\nalpha=0.7 0.5767337 0.9875315\nalpha=0.8 0.5147540 0.9972680\nalpha=0.9 0.4681879 1.0024731\nalpha=1   0.4042862 1.0000000\n\n\nThe plot for Qnorm and the normalised proportion of explained inertia suggests to choose alpha=0.2.\nAgain, we can derive the clusters and plot them on a choropleth.\n\nclustG <- hclustgeo(proxmat, D1, alpha = 0.2)\ngroups <- as.factor(cutree(clustG, k=9))\nnga_wp <- cbind(nga_wp, as.matrix(groups)) %>%\n  rename(`ClustG_NCLUSTER` = `as.matrix.groups.`)\nqtm(nga_wp, \"ClustG_NCLUSTER\")+\n    tm_layout(main.title = \"ClustGeo Neighbourhood Constrained Hierarchical Clustering\",\n              main.title.size = 1,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\n\n\n\nIn the following code chunk, we get the summary of attribute means for each cluster.\n\nnga_wp %>% \n    st_set_geometry(NULL) %>%\n    group_by(ClustG_NCLUSTER) %>% \n    summarise_at(c(7,8,16,17,19,21:23), mean)\n\n# A tibble: 9 × 9\n  ClustG_NCLUS…¹ wp_fu…² wp_no…³ pct_f…⁴ pct_n…⁵ pct_l…⁶ pct_r…⁷ pct_pay pct_c…⁸\n  <chr>            <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1                 47.2   52.2    0.434   0.458   0.405  0.483    0.839   0.259\n2 2                 74.9   67.3    0.493   0.463   0.681  0.866    0.877   0.329\n3 3                 16.3   29.2    0.360   0.620   0.205  0.867    0.920   0.658\n4 4                 82.7   63.3    0.407   0.323   0.798  0.798    0.657   0.320\n5 5                 60.9   31.9    0.646   0.274   0.475  0.0957   0.810   0.107\n6 6                 32.4   43.6    0.305   0.451   0.622  0.833    0.715   0.646\n7 7                 20.2    5.44   0.780   0.205   0.510  0.789    0.893   0.536\n8 8                 12.2   10.8    0.262   0.221   0.661  0.551    0.386   0.690\n9 9                158.    40.4    0.783   0.216   0.866  0.891    0.945   0.240\n# … with abbreviated variable names ¹​ClustG_NCLUSTER, ²​wp_functional,\n#   ³​wp_nonfunctional, ⁴​pct_functional, ⁵​pct_nonfunctional, ⁶​pct_lowusage,\n#   ⁷​pct_rural, ⁸​pct_crucial\n\n\nWe also want to compare the spatially constrained hierarchical clusters and the neighbourhood constrained hierarchical clusters.\n\nGclust.map <- qtm(nga_wp,\n                  \"ClustG_SPCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title = \"ClustGeo Spatially Constrained Clustering\",\n              main.title.size = 0.8,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\nNclust.map <- qtm(nga_wp,\n                   \"ClustG_NCLUSTER\") + \n  tm_borders(alpha = 0.5) +\n    tm_layout(main.title=\"ClustGeo Neighbourhood Constrained Clustering\",\n              main.title.size = 0.7,\n              main.title.fontface = \"bold\",\n              legend.width = 0.4,\n              legend.height = 0.3)\n\ntmap_arrange(Gclust.map, Nclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\nAs expected, we can see that the neighbourhood constrained hierarchical clusters obtained are less fragmented compared to the spatially constrained hierarchical clusters. In particular, for the geographical cohesion is improved in the region for cluster 2 (on the map for neighbourhood constrained hierarchical clusters).\nHowever, we can also observe that the clustering process using neighbourhood constrained hierarchical clustering do not give completely geographically cohesive clusters. For instance, cluster 4 is divided spatially into 4 plots. The reason for this observation is that the clustering is based on soft contiguity constraints. This results in LGAs that are not neighbours are allowed to be in the same clusters.\nComparing the water points homogeneity obtained in the 2 clustering methods, we noticed that spatially constrained (by distance) hierarchical clusters is 56% (Q0 at alpha=0.2) which is higher than neighbourhood constrained hierarchical clusters which is at 52% (Q0 at alpha=0.2). Again, this is within expectation as neighbourhood constrained hierarchical clustering compromised water point attribute homogeneity for improved geographical cohesion."
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#visualisation-of-all-clustering-results",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#visualisation-of-all-clustering-results",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "11 Visualisation of all clustering results",
    "text": "11 Visualisation of all clustering results\n\ntmap_arrange(skclust.map, Gclust.map, Nclust.map, hclust.map, Hclust.map,\n             asp=NA, ncol=3)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\nComparing among the 3 spatially and neighbourhood constrained results, we can see that the SKATER spatially constrained hierarchical clustering gave the most geographically cohesive clusters, which is then followed by ClustGeo’s neighbourhood constrained cluster.\nThe results for hierarchical clustering are largely similar for both the hierarchical methods (hclust() and hclustgeo()). The only exception is at the most North West region where the LGAs are assigned to different clusters in the 2 methods.\n\n11.1 Comparing spatially constrained and neighbourhood constrained hierarchical clusters\nWe will generate boxplots for each water point attribute for each cluster to perform this comparison. As such, we want to create a data frame containing just the shapeName, cluster IDs, and the water point attribute values. This will then allow us to facet by the cluster ID and subsequently generate the boxplot diagrams.\nFirst, we will select the cluster IDs and the shapeName from nga_wp and drop the geometry field by setting it to NULL.\n\ncluster_summary <- nga_wp %>%\n    st_set_geometry(NULL) %>%\n  select(\"shapeName\", \"H_CLUSTER\", \"Skater_CLUSTER\", \"ClustG_HCLUSTER\", \"ClustG_SPCLUSTER\", \"ClustG_NCLUSTER\")\nhead(cluster_summary)\n\n       shapeName H_CLUSTER Skater_CLUSTER ClustG_HCLUSTER ClustG_SPCLUSTER\n1      Aba North         1              2               1                1\n2      Aba South         1              2               1                1\n4          Abaji         2              3               2                2\n5           Abak         3              2               3                3\n6      Abakaliki         4              7               4                4\n7 Abeokuta North         1              3               1                1\n  ClustG_NCLUSTER\n1               1\n2               1\n4               2\n5               3\n6               4\n7               5\n\n\nNext, we want to rename the IDs for each cluster field to differentiate the clusters generated from each clustering method. To do this, we use recode_factor() from dplyr package.\n\ncluster_summary$H_CLUSTER <- recode_factor(cluster_summary$H_CLUSTER, \n                                           \"1\" = \"Hier, Cluster 1\",\n                                           \"2\" = \"Hier, Cluster 2\",\n                                           \"3\" = \"Hier, Cluster 3\",\n                                           \"4\" = \"Hier, Cluster 4\",\n                                           \"5\" = \"Hier, Cluster 5\",\n                                           \"6\" = \"Hier, Cluster 6\",\n                                           \"7\" = \"Hier, Cluster 7\",\n                                           \"8\" = \"Hier, Cluster 8\",\n                                           \"9\" = \"Hier, Cluster 9\")\ncluster_summary$Skater_CLUSTER <- recode_factor(cluster_summary$Skater_CLUSTER, \n                                           \"1\" = \"Skater, Cluster 1\",\n                                           \"2\" = \"Skater, Cluster 2\",\n                                           \"3\" = \"Skater, Cluster 3\",\n                                           \"4\" = \"Skater, Cluster 4\",\n                                           \"5\" = \"Skater, Cluster 5\",\n                                           \"6\" = \"Skater, Cluster 6\",\n                                           \"7\" = \"Skater, Cluster 7\",\n                                           \"8\" = \"Skater, Cluster 8\",\n                                           \"9\" = \"Skater, Cluster 9\")\ncluster_summary$ClustG_HCLUSTER <- recode_factor(cluster_summary$ClustG_HCLUSTER, \n                                           \"1\" = \"ClustGeo Hier, Cluster 1\",\n                                           \"2\" = \"ClustGeo Hier, Cluster 2\",\n                                           \"3\" = \"ClustGeo Hier, Cluster 3\",\n                                           \"4\" = \"ClustGeo Hier, Cluster 4\",\n                                           \"5\" = \"ClustGeo Hier, Cluster 5\",\n                                           \"6\" = \"ClustGeo Hier, Cluster 6\",\n                                           \"7\" = \"ClustGeo Hier, Cluster 7\",\n                                           \"8\" = \"ClustGeo Hier, Cluster 8\",\n                                           \"9\" = \"ClustGeo Hier, Cluster 9\")\ncluster_summary$ClustG_SPCLUSTER <- recode_factor(cluster_summary$ClustG_SPCLUSTER, \n                                           \"1\" = \"ClustGeo, distance Cluster 1\",\n                                           \"2\" = \"ClustGeo, distance Cluster 2\",\n                                           \"3\" = \"ClustGeo, distance Cluster 3\",\n                                           \"4\" = \"ClustGeo, distance Cluster 4\",\n                                           \"5\" = \"ClustGeo, distance Cluster 5\",\n                                           \"6\" = \"ClustGeo, distance Cluster 6\",\n                                           \"7\" = \"ClustGeo, distance Cluster 7\",\n                                           \"8\" = \"ClustGeo, distance Cluster 8\",\n                                           \"9\" = \"ClustGeo, distance Cluster 9\")\ncluster_summary$ClustG_NCLUSTER <- recode_factor(cluster_summary$ClustG_NCLUSTER, \n                                           \"1\" = \"ClustGeo, contiguity Cluster 1\",\n                                           \"2\" = \"ClustGeo, contiguity Cluster 2\",\n                                           \"3\" = \"ClustGeo, contiguity Cluster 3\",\n                                           \"4\" = \"ClustGeo, contiguity Cluster 4\",\n                                           \"5\" = \"ClustGeo, contiguity Cluster 5\",\n                                           \"6\" = \"ClustGeo, contiguity Cluster 6\",\n                                           \"7\" = \"ClustGeo, contiguity Cluster 7\",\n                                           \"8\" = \"ClustGeo, contiguity Cluster 8\",\n                                           \"9\" = \"ClustGeo, contiguity Cluster 9\")\n\nNext, to nga_wp.std, we will use rownames_to_column from tibble package to bring the shapeName from index column to a field column. This allows us to merge this data frame with cluster_summary by the shapeName field as shown in the following code chunk.\n\nnga_wp.std <- tibble::rownames_to_column(nga_wp.std, \"shapeName\")\ncluster_summary <- merge(x=cluster_summary, y=nga_wp.std, \n                         by.x=\"shapeName\", by.y=\"shapeName\")\nhead(cluster_summary)\n\n       shapeName       H_CLUSTER    Skater_CLUSTER          ClustG_HCLUSTER\n1      Aba North Hier, Cluster 1 Skater, Cluster 2 ClustGeo Hier, Cluster 1\n2      Aba South Hier, Cluster 1 Skater, Cluster 2 ClustGeo Hier, Cluster 1\n3          Abaji Hier, Cluster 2 Skater, Cluster 3 ClustGeo Hier, Cluster 2\n4           Abak Hier, Cluster 3 Skater, Cluster 2 ClustGeo Hier, Cluster 3\n5      Abakaliki Hier, Cluster 4 Skater, Cluster 7 ClustGeo Hier, Cluster 4\n6 Abeokuta North Hier, Cluster 1 Skater, Cluster 3 ClustGeo Hier, Cluster 1\n              ClustG_SPCLUSTER                ClustG_NCLUSTER pct_functional\n1 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 1      0.4117647\n2 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 1      0.4084507\n3 ClustGeo, distance Cluster 2 ClustGeo, contiguity Cluster 2      0.4035088\n4 ClustGeo, distance Cluster 3 ClustGeo, contiguity Cluster 3      0.4791667\n5 ClustGeo, distance Cluster 4 ClustGeo, contiguity Cluster 4      0.3519313\n6 ClustGeo, distance Cluster 1 ClustGeo, contiguity Cluster 5      0.4705882\n  pct_nonfunctional pct_lowusage  pct_rural   pct_pay pct_crucial\n1         0.5294118   0.17647059 0.00000000 0.9387255   0.4705882\n2         0.4929577   0.12676056 0.05633803 0.8679577   0.3239437\n3         0.5964912   0.40350877 0.84210526 0.6162281   0.5614035\n4         0.5208333   0.08333333 0.83333333 0.9348958   0.7500000\n5         0.1802575   0.90557940 0.87553648 0.5082260   0.1502146\n6         0.4411765   0.23529412 0.20588235 0.7855392   0.3823529\n  log_wp_nonfunctional log_wp_functional\n1            0.4088969         0.3139223\n2            0.6363673         0.5134607\n3            0.6313647         0.4797739\n4            0.5785782         0.4797739\n5            0.6679202         0.6670889\n6            0.4923609         0.4277152\n\n\nWe will then generate the boxplots for Skater clusters. We will need to use melt() from reshape2 package to convert cluster_summarydata frame with several measurement columns into a data frame in a canonical format, which has one row for every observed (measured) value. We set the ID of the variables, i.e. id.vars argument to the cluster ID, “Skater_CLUSTER” as shown in the following code chunk.\n\nskmelted<- melt(cluster_summary[c(3,7:14)],id.vars=\"Skater_CLUSTER\")\nhead(skmelted)\n\n     Skater_CLUSTER       variable     value\n1 Skater, Cluster 2 pct_functional 0.4117647\n2 Skater, Cluster 2 pct_functional 0.4084507\n3 Skater, Cluster 3 pct_functional 0.4035088\n4 Skater, Cluster 2 pct_functional 0.4791667\n5 Skater, Cluster 7 pct_functional 0.3519313\n6 Skater, Cluster 3 pct_functional 0.4705882\n\n\nWe will then use facet_wrap() to generate one plot for each cluster ID by specifying the first argument as Skater_CLUSTER.\n\nSKCLUSTER <- ggplot(skmelted,aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~Skater_CLUSTER,\n                               nrow = 9)\n\nWe will repeat the same steps for ClustG_SPCLUSTER and ClustG_NCLUSTER. Finally, we will use ggarrange() to combine the plots together.\n\nSPmelted<- melt(cluster_summary[c(5,7:14)],id.vars=\"ClustG_SPCLUSTER\")\nClustG_SPCLUSTER <- ggplot(SPmelted, aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~ClustG_SPCLUSTER,nrow = 9)\n \nNmelted<- melt(cluster_summary[c(6,7:14)],id.vars=\"ClustG_NCLUSTER\")\nClustG_NCLUSTER <- ggplot(Nmelted, aes(x = value, y = variable)) + \n     geom_boxplot()+facet_wrap(~ClustG_NCLUSTER,nrow = 9)\n \nggarrange(SKCLUSTER, ClustG_SPCLUSTER, ClustG_NCLUSTER, \n          ncol = 3)\n\n\n\n\n\n\n\ns"
  },
  {
    "objectID": "take_home_ex/ex2/take-home-ex2-removed.html#references",
    "href": "take_home_ex/ex2/take-home-ex2-removed.html#references",
    "title": "Take-Home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-Spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "12 References",
    "text": "12 References\n[1] Use case for regionalisation\n[2] Data Wrangling steps for Take-Home Exercise 1\n[3] Ward’s minimum variance method\n[4] Linkage method definition and illustration"
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html",
    "href": "in_class_ex/ex5/in_class_ex5.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "In this In-Class Exercise, we will demonstrate the basic concepts and methods of logistic regression specially designed for geographical data. In particular, we will demonstrate the following:\n\nexplain the similarities and differences between Logistic Regression (LR) algorithm versus geographical weighted Logistic Regression (GWLR) algorithm.\ncalibrate predictive models by using appropriate Geographically Weighted Logistic Regression algorithm for geographical data."
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#the-data",
    "href": "in_class_ex/ex5/in_class_ex5.html#the-data",
    "title": "In-Class Exercise 5",
    "section": "2 The Data",
    "text": "2 The Data\nIn this exercise, we will analyse the data from Nigeria. There are 2 datasets used, as outlined in sections 2.1 and 2.2. We will have chosen Osun for this analysis as this state has a relatively high proportion of non-functional water points compared to the other states in Nigeria.\n\n2.1 Aspatial Data\nData was downloaded from WPdx Global Data Repositories in a csv format. The WPdx+ data set was filtered for “nigeria” in the column clean_country_name before downloading. There is a total of 95,008 unique water point records.\n\n\n2.2 Geospatial Data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area, LGA) polygon features GIS data was downloaded from geoBoundaries."
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#getting-started",
    "href": "in_class_ex/ex5/in_class_ex5.html#getting-started",
    "title": "In-Class Exercise 5",
    "section": "3 Getting Started",
    "text": "3 Getting Started\nThe R packages needed for this exercise are as follows:\n\npacman::p_load(sf, tidyverse, funModeling, blorr, corrplot, ggpubr, spdep, GWmodel, tmap, skimr, caret)"
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#importing-the-analytical-data",
    "href": "in_class_ex/ex5/in_class_ex5.html#importing-the-analytical-data",
    "title": "In-Class Exercise 5",
    "section": "4 Importing the Analytical Data",
    "text": "4 Importing the Analytical Data\nIn the following code chunk, we will import Osun.rds and Osun_wp_sf.rds that have been previously tidied by using read_rds(). In Osun.rds, we have kept the geographical boundary for Osun state to allow for better plotting later.\n\nOsun <- read_rds(\"rds/Osun.rds\")\nOsun_wp_sf <- read_rds(\"rds/Osun_wp_sf.rds\")\n\nWe check our independent variable i.e. status by running the following code chunk. We can see that it is a binary data - TRUE representing functional water points and FALSE representing non-functional water points. We can see that there are 55.5% functional water points and 44.5% non-functional water points.\n\nOsun_wp_sf %>% \n    freq(input = 'status')\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the funModeling package.\n  Please report the issue at <https://github.com/pablo14/funModeling/issues>.\n\n\n\n\n\n  status frequency percentage cumulative_perc\n1   TRUE      2642       55.5            55.5\n2  FALSE      2118       44.5           100.0\n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(Osun)+\n    tm_polygons(alpha=0.4)+\n    tm_shape(Osun_wp_sf)+\n    tm_dots(col=\"status\",\n            alpha=0.6)+\n    tm_view(set.zoom.limits = c(9,12))"
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#exploratory-data-analysis",
    "href": "in_class_ex/ex5/in_class_ex5.html#exploratory-data-analysis",
    "title": "In-Class Exercise 5",
    "section": "5 Exploratory Data Analysis",
    "text": "5 Exploratory Data Analysis\nRegression models are very sensitive to excessive number of missing values (e.g. fields with more than 20-50% missing values, depending on the sample size). In this section, we will look at distribution of the variables. We will use skimr() which will allow the results to be displayed in a nice report.\n\n    Osun_wp_sf %>% \n    skim()\n\nWarning: Couldn't find skimmers for class: sfc_POINT, sfc; No user-defined `sfl`\nprovided. Falling back to `character`.\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n4760\n\n\nNumber of columns\n75\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n47\n\n\nlogical\n5\n\n\nnumeric\n23\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1.00\n5\n44\n0\n2\n0\n\n\nreport_date\n0\n1.00\n22\n22\n0\n42\n0\n\n\nstatus_id\n0\n1.00\n2\n7\n0\n3\n0\n\n\nwater_source_clean\n0\n1.00\n8\n22\n0\n3\n0\n\n\nwater_source_category\n0\n1.00\n4\n6\n0\n2\n0\n\n\nwater_tech_clean\n24\n0.99\n9\n23\n0\n3\n0\n\n\nwater_tech_category\n24\n0.99\n9\n15\n0\n2\n0\n\n\nfacility_type\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclean_country_name\n0\n1.00\n7\n7\n0\n1\n0\n\n\nclean_adm1\n0\n1.00\n3\n5\n0\n5\n0\n\n\nclean_adm2\n0\n1.00\n3\n14\n0\n35\n0\n\n\nclean_adm3\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\nclean_adm4\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\ninstaller\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\nmanagement_clean\n1573\n0.67\n5\n37\n0\n7\n0\n\n\nstatus_clean\n0\n1.00\n9\n32\n0\n7\n0\n\n\npay\n0\n1.00\n2\n39\n0\n7\n0\n\n\nfecal_coliform_presence\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\nsubjective_quality\n0\n1.00\n18\n20\n0\n4\n0\n\n\nactivity_id\n4757\n0.00\n36\n36\n0\n3\n0\n\n\nscheme_id\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\nwpdx_id\n0\n1.00\n12\n12\n0\n4760\n0\n\n\nnotes\n0\n1.00\n2\n96\n0\n3502\n0\n\n\norig_lnk\n4757\n0.00\n84\n84\n0\n1\n0\n\n\nphoto_lnk\n41\n0.99\n84\n84\n0\n4719\n0\n\n\ncountry_id\n0\n1.00\n2\n2\n0\n1\n0\n\n\ndata_lnk\n0\n1.00\n79\n96\n0\n2\n0\n\n\nwater_point_history\n0\n1.00\n142\n834\n0\n4750\n0\n\n\nclean_country_id\n0\n1.00\n3\n3\n0\n1\n0\n\n\ncountry_name\n0\n1.00\n7\n7\n0\n1\n0\n\n\nwater_source\n0\n1.00\n8\n30\n0\n4\n0\n\n\nwater_tech\n0\n1.00\n5\n37\n0\n20\n0\n\n\nadm2\n0\n1.00\n3\n14\n0\n33\n0\n\n\nadm3\n4760\n0.00\nNA\nNA\n0\n0\n0\n\n\nmanagement\n1573\n0.67\n5\n47\n0\n7\n0\n\n\nadm1\n0\n1.00\n4\n5\n0\n4\n0\n\n\nNew Georeferenced Column\n0\n1.00\n16\n35\n0\n4760\n0\n\n\nlat_lon_deg\n0\n1.00\n13\n32\n0\n4760\n0\n\n\npublic_data_source\n0\n1.00\n84\n102\n0\n2\n0\n\n\nconverted\n0\n1.00\n53\n53\n0\n1\n0\n\n\ncreated_timestamp\n0\n1.00\n22\n22\n0\n2\n0\n\n\nupdated_timestamp\n0\n1.00\n22\n22\n0\n2\n0\n\n\nGeometry\n0\n1.00\n33\n37\n0\n4760\n0\n\n\nADM2_EN\n0\n1.00\n3\n14\n0\n30\n0\n\n\nADM2_PCODE\n0\n1.00\n8\n8\n0\n30\n0\n\n\nADM1_EN\n0\n1.00\n4\n4\n0\n1\n0\n\n\nADM1_PCODE\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nrehab_year\n4760\n0\nNaN\n:\n\n\nrehabilitator\n4760\n0\nNaN\n:\n\n\nis_urban\n0\n1\n0.39\nFAL: 2884, TRU: 1876\n\n\nlatest_record\n0\n1\n1.00\nTRU: 4760\n\n\nstatus\n0\n1\n0.56\nTRU: 2642, FAL: 2118\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrow_id\n0\n1.00\n68550.48\n10216.94\n49601.00\n66874.75\n68244.50\n69562.25\n471319.00\n▇▁▁▁▁\n\n\nlat_deg\n0\n1.00\n7.68\n0.22\n7.06\n7.51\n7.71\n7.88\n8.06\n▁▂▇▇▇\n\n\nlon_deg\n0\n1.00\n4.54\n0.21\n4.08\n4.36\n4.56\n4.71\n5.06\n▃▆▇▇▂\n\n\ninstall_year\n1144\n0.76\n2008.63\n6.04\n1917.00\n2006.00\n2010.00\n2013.00\n2015.00\n▁▁▁▁▇\n\n\nfecal_coliform_value\n4760\n0.00\nNaN\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\ndistance_to_primary_road\n0\n1.00\n5021.53\n5648.34\n0.01\n719.36\n2972.78\n7314.73\n26909.86\n▇▂▁▁▁\n\n\ndistance_to_secondary_road\n0\n1.00\n3750.47\n3938.63\n0.15\n460.90\n2554.25\n5791.94\n19559.48\n▇▃▁▁▁\n\n\ndistance_to_tertiary_road\n0\n1.00\n1259.28\n1680.04\n0.02\n121.25\n521.77\n1834.42\n10966.27\n▇▂▁▁▁\n\n\ndistance_to_city\n0\n1.00\n16663.99\n10960.82\n53.05\n7930.75\n15030.41\n24255.75\n47934.34\n▇▇▆▃▁\n\n\ndistance_to_town\n0\n1.00\n16726.59\n12452.65\n30.00\n6876.92\n12204.53\n27739.46\n44020.64\n▇▅▃▃▂\n\n\nrehab_priority\n2654\n0.44\n489.33\n1658.81\n0.00\n7.00\n91.50\n376.25\n29697.00\n▇▁▁▁▁\n\n\nwater_point_population\n4\n1.00\n513.58\n1458.92\n0.00\n14.00\n119.00\n433.25\n29697.00\n▇▁▁▁▁\n\n\nlocal_population_1km\n4\n1.00\n2727.16\n4189.46\n0.00\n176.00\n1032.00\n3717.00\n36118.00\n▇▁▁▁▁\n\n\ncrucialness_score\n798\n0.83\n0.26\n0.28\n0.00\n0.07\n0.15\n0.35\n1.00\n▇▃▁▁▁\n\n\npressure_score\n798\n0.83\n1.46\n4.16\n0.00\n0.12\n0.41\n1.24\n93.69\n▇▁▁▁▁\n\n\nusage_capacity\n0\n1.00\n560.74\n338.46\n300.00\n300.00\n300.00\n1000.00\n1000.00\n▇▁▁▁▅\n\n\ndays_since_report\n0\n1.00\n2692.69\n41.92\n1483.00\n2688.00\n2693.00\n2700.00\n4645.00\n▁▇▁▁▁\n\n\nstaleness_score\n0\n1.00\n42.80\n0.58\n23.13\n42.70\n42.79\n42.86\n62.66\n▁▁▇▁▁\n\n\nlocation_id\n0\n1.00\n235865.49\n6657.60\n23741.00\n230638.75\n236199.50\n240061.25\n267454.00\n▁▁▁▁▇\n\n\ncluster_size\n0\n1.00\n1.05\n0.25\n1.00\n1.00\n1.00\n1.00\n4.00\n▇▁▁▁▁\n\n\nlat_deg_original\n4760\n0.00\nNaN\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\nlon_deg_original\n4760\n0.00\nNaN\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\ncount\n0\n1.00\n1.00\n0.00\n1.00\n1.00\n1.00\n1.00\n1.00\n▁▁▇▁▁\n\n\n\n\n\nWe can also see the number of missing values in each field. For instance, install_year has 1144 missing values out of a total of 4760 records for Osun. In this case, we cannot use this field (24% missing values) although it is a useful variable since we know water points that are beyond 8-9 years are more likely to be non-functional.\nOn the other hand, we can see that fields local_population_1km and water_point_population both have 4 missing values, which is a small number of records, and hence we can still use these 2 fields.\nIn the following code chunk, we will select the independent variables that we will use for our regression model and to exclude records that have missing values. We will use as.factor() for usage_capacity as there are only specific values for the capacity of the water points, hence, we should not treat this field as a continuous variables and instead, make the values as factor.\n\nOsun_wp_sf_clean <- Osun_wp_sf %>% \n    filter_at(vars(status,\n                   distance_to_primary_road,\n                   distance_to_secondary_road,\n                   distance_to_tertiary_road,\n                   distance_to_city,\n                   distance_to_town,\n                   water_point_population,\n                   local_population_1km,\n                   usage_capacity,\n                   is_urban,\n                   water_source_clean),\n              all_vars(!is.na(.))) %>% \n    mutate(usage_capacity = as.factor(usage_capacity))"
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#correlation-analysis",
    "href": "in_class_ex/ex5/in_class_ex5.html#correlation-analysis",
    "title": "In-Class Exercise 5",
    "section": "6 Correlation Analysis",
    "text": "6 Correlation Analysis\nIn this section, we want to know if any of the numerical independent variables are correlated. We will first need to drop the geometry column in the spatial data Osun_wp_sf_clean so that the geometry field does not interfere with correlation analysis.\n\nOsun_wp <- Osun_wp_sf_clean %>% \n    select(c(7,35:39,42:43,46:47,57)) %>% \n    st_set_geometry(NULL)\n\nWe can then perform correlation analysis only on the numerical variables.\n\ncluster_vars.cor = cor(\n    Osun_wp[,2:7])\ncorrplot.mixed(cluster_vars.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nWe can see that there is no multicollinearity observed among the numerical variables (no coefficient greater than 0.8)."
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#building-a-logistic-regression-model",
    "href": "in_class_ex/ex5/in_class_ex5.html#building-a-logistic-regression-model",
    "title": "In-Class Exercise 5",
    "section": "7 Building a Logistic Regression Model",
    "text": "7 Building a Logistic Regression Model\nIn the following code check, we will use glm of R to calibrate a logistic regression model for the water point status.\n\nmodel <- glm(status ~ distance_to_primary_road+\n                       distance_to_secondary_road+\n                       distance_to_tertiary_road+\n                       distance_to_city+\n                       distance_to_town+\n                       is_urban+\n                       usage_capacity+\n                       water_source_clean+\n                       water_point_population+\n                       local_population_1km,\n                   data = Osun_wp_sf_clean,\n                   family = binomial(link = 'logit'))\n\nIn the results for model, we can see that fitted.values are all probability values which is our y-hat.\nWe will then use blr_regress() from blorr package to generate a report for the model results.\n\nblr_regress(model)\n\n                             Model Overview                              \n------------------------------------------------------------------------\nData Set    Resp Var    Obs.    Df. Model    Df. Residual    Convergence \n------------------------------------------------------------------------\n  data       status     4756      4755           4744           TRUE     \n------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             2114              1             2642    \n--------------------------------------------------------\n\n                                 Maximum Likelihood Estimates                                   \n-----------------------------------------------------------------------------------------------\n               Parameter                    DF    Estimate    Std. Error    z value     Pr(>|z|) \n-----------------------------------------------------------------------------------------------\n              (Intercept)                   1      0.3887        0.1124      3.4588       5e-04 \n        distance_to_primary_road            1      0.0000        0.0000     -0.7153      0.4744 \n       distance_to_secondary_road           1      0.0000        0.0000     -0.5530      0.5802 \n       distance_to_tertiary_road            1      1e-04         0.0000      4.6708      0.0000 \n            distance_to_city                1      0.0000        0.0000     -4.7574      0.0000 \n            distance_to_town                1      0.0000        0.0000     -4.9170      0.0000 \n              is_urbanTRUE                  1     -0.2971        0.0819     -3.6294       3e-04 \n           usage_capacity1000               1     -0.6230        0.0697     -8.9366      0.0000 \nwater_source_cleanProtected Shallow Well    1      0.5040        0.0857      5.8783      0.0000 \n   water_source_cleanProtected Spring       1      1.2882        0.4388      2.9359      0.0033 \n         water_point_population             1      -5e-04        0.0000    -11.3686      0.0000 \n          local_population_1km              1      3e-04         0.0000     19.2953      0.0000 \n-----------------------------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7347          Somers' D        0.4693   \n% Discordant          0.2653          Gamma            0.4693   \n% Tied                0.0000          Tau-a            0.2318   \nPairs                5585188          c                0.7347   \n---------------------------------------------------------------\n\n\nWe can see that distance_to_primary_road and distance_to_secondary_road has p-value greater than 0.05, we will subsequently exclude these 2 fields which are not statistically significant (i.e. p-value < 0.05). For categorical variables, a positive value indicates an average correlation and a negative value implies a below average correlation.\nFor continuous variables, a positive value implies a direct correlation and a negative value implies an inverse relation, while the magnitude of the coefficient represents the strength of the correlations. We will make this analysis for the continuous variables after we have confirmed that they are statistically significant.\nIn the code chunk below, blr_confusion_matrix() from blorr package to prepare a confusion matrix. We will use cutoff = 0.5, this means that if the fitted.values sf greater than 0.5, we will label the water point as functional, and if the fitted.values determined is less than 0.5, we will label the water point as non-functional. (The validity of the cutoff is measured using accuracy, sensitivity, and specificity).\n\nblr_confusion_matrix(model, cutoff = 0.5)\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction FALSE TRUE\n         0  1301  738\n         1   813 1904\n\n                Accuracy : 0.6739 \n     No Information Rate : 0.4445 \n\n                   Kappa : 0.3373 \n\nMcNemars's Test P-Value  : 0.0602 \n\n             Sensitivity : 0.7207 \n             Specificity : 0.6154 \n          Pos Pred Value : 0.7008 \n          Neg Pred Value : 0.6381 \n              Prevalence : 0.5555 \n          Detection Rate : 0.4003 \n    Detection Prevalence : 0.5713 \n       Balanced Accuracy : 0.6680 \n               Precision : 0.7008 \n                  Recall : 0.7207 \n\n        'Positive' Class : 1\n\n\nWe can also see that our accuracy is approximately 67.4%. The sensitivity is higher than the specificity, indicating that our true positive is higher (correctly determined approximately 72% true positive) than the true negative (model correctly determines approximately 62% true negative)."
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#building-geographically-weighted-logistic-regression-gwlr-models",
    "href": "in_class_ex/ex5/in_class_ex5.html#building-geographically-weighted-logistic-regression-gwlr-models",
    "title": "In-Class Exercise 5",
    "section": "8 Building Geographically Weighted Logistic Regression (gwLR) Models",
    "text": "8 Building Geographically Weighted Logistic Regression (gwLR) Models\n\n8.1 Converting from sf to sp data frame\nWe will use select() from dplyr package to select the variables fo interest. We will convert the data to SpatialPointsDataFrame data type for compatibility with subsequent packages. We will need to use Osun_wp_sf_clean which excludes the 4 polygons with missing values as polygons with missing values will cause an error prompt.\n\nOsun_wp_sp <- Osun_wp_sf_clean %>% \n    select(c(status,\n             distance_to_primary_road,\n             distance_to_secondary_road,\n             distance_to_tertiary_road,\n             distance_to_city,\n             distance_to_town,\n             water_point_population,\n             local_population_1km,\n             is_urban,\n             usage_capacity,\n             water_source_clean)) %>% \n    as_Spatial()\nOsun_wp_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 4756 \nextent      : 182502.4, 290751, 340054.1, 450905.3  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 11\nnames       : status, distance_to_primary_road, distance_to_secondary_road, distance_to_tertiary_road, distance_to_city, distance_to_town, water_point_population, local_population_1km, is_urban, usage_capacity, water_source_clean \nmin values  :      0,        0.014461356813335,          0.152195902540837,         0.017815121653488, 53.0461399623541, 30.0019777713073,                      0,                    0,        0,           1000,           Borehole \nmax values  :      1,         26909.8616132094,           19559.4793799085,          10966.2705628969,  47934.343603562, 44020.6393368124,                  29697,                36118,        1,            300,   Protected Spring \n\n\nSince our geometry data is already in projected coordinate format, we can set the longlat as FALSE (the following result will match the SI unit of the projected coordinate system). We will set the argument adaptive to FALSE which indicates that we are interested to compute the fixed bandwidth. We will leave all variables including distance_to_primary_road and distance_to_secondary_road in the following code chunk.\n\n\n8.2 Building Fixed Bandwidth GWR Model\nWe can plot a basic gwlr using the bandwidth obtained earlier.\n\n8.2.1 Computing Fixed Bandwidth\n\nbw.fixed <- bw.ggwr(status ~ distance_to_primary_road+\n                           distance_to_secondary_road+\n                           distance_to_tertiary_road+\n                           distance_to_city+\n                           distance_to_town+\n                           is_urban+\n                           usage_capacity+\n                           water_source_clean+\n                           water_point_population+\n                           local_population_1km,\n                   data = Osun_wp_sp,\n                   family = \"binomial\",\n                   approach = \"AIC\",\n                   kernel = \"gaussian\",\n                   adaptive = FALSE,\n                   longlat = FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\n Iteration    Log-Likelihood:(With bandwidth:  95768.67 )\n=========================\n       0        -2889 \n       1        -2836 \n       2        -2830 \n       3        -2829 \n       4        -2829 \n       5        -2829 \nFixed bandwidth: 95768.67 AICc value: 5684.357 \n Iteration    Log-Likelihood:(With bandwidth:  59200.13 )\n=========================\n       0        -2875 \n       1        -2818 \n       2        -2810 \n       3        -2808 \n       4        -2808 \n       5        -2808 \nFixed bandwidth: 59200.13 AICc value: 5646.785 \n Iteration    Log-Likelihood:(With bandwidth:  36599.53 )\n=========================\n       0        -2847 \n       1        -2781 \n       2        -2768 \n       3        -2765 \n       4        -2765 \n       5        -2765 \n       6        -2765 \nFixed bandwidth: 36599.53 AICc value: 5575.148 \n Iteration    Log-Likelihood:(With bandwidth:  22631.59 )\n=========================\n       0        -2798 \n       1        -2719 \n       2        -2698 \n       3        -2693 \n       4        -2693 \n       5        -2693 \n       6        -2693 \nFixed bandwidth: 22631.59 AICc value: 5466.883 \n Iteration    Log-Likelihood:(With bandwidth:  13998.93 )\n=========================\n       0        -2720 \n       1        -2622 \n       2        -2590 \n       3        -2581 \n       4        -2580 \n       5        -2580 \n       6        -2580 \n       7        -2580 \nFixed bandwidth: 13998.93 AICc value: 5324.578 \n Iteration    Log-Likelihood:(With bandwidth:  8663.649 )\n=========================\n       0        -2601 \n       1        -2476 \n       2        -2431 \n       3        -2419 \n       4        -2417 \n       5        -2417 \n       6        -2417 \n       7        -2417 \nFixed bandwidth: 8663.649 AICc value: 5163.61 \n Iteration    Log-Likelihood:(With bandwidth:  5366.266 )\n=========================\n       0        -2436 \n       1        -2268 \n       2        -2194 \n       3        -2167 \n       4        -2161 \n       5        -2161 \n       6        -2161 \n       7        -2161 \n       8        -2161 \n       9        -2161 \nFixed bandwidth: 5366.266 AICc value: 4990.587 \n Iteration    Log-Likelihood:(With bandwidth:  3328.371 )\n=========================\n       0        -2157 \n       1        -1922 \n       2        -1802 \n       3        -1739 \n       4        -1713 \n       5        -1713 \nFixed bandwidth: 3328.371 AICc value: 4798.288 \n Iteration    Log-Likelihood:(With bandwidth:  2068.882 )\n=========================\n       0        -1751 \n       1        -1421 \n       2        -1238 \n       3        -1133 \n       4        -1084 \n       5        -1084 \nFixed bandwidth: 2068.882 AICc value: 4837.017 \n Iteration    Log-Likelihood:(With bandwidth:  4106.777 )\n=========================\n       0        -2297 \n       1        -2095 \n       2        -1997 \n       3        -1951 \n       4        -1938 \n       5        -1936 \n       6        -1936 \n       7        -1936 \n       8        -1936 \nFixed bandwidth: 4106.777 AICc value: 4873.161 \n Iteration    Log-Likelihood:(With bandwidth:  2847.289 )\n=========================\n       0        -2036 \n       1        -1771 \n       2        -1633 \n       3        -1558 \n       4        -1525 \n       5        -1525 \nFixed bandwidth: 2847.289 AICc value: 4768.192 \n Iteration    Log-Likelihood:(With bandwidth:  2549.964 )\n=========================\n       0        -1941 \n       1        -1655 \n       2        -1503 \n       3        -1417 \n       4        -1378 \n       5        -1378 \nFixed bandwidth: 2549.964 AICc value: 4762.212 \n Iteration    Log-Likelihood:(With bandwidth:  2366.207 )\n=========================\n       0        -1874 \n       1        -1573 \n       2        -1410 \n       3        -1316 \n       4        -1274 \n       5        -1274 \nFixed bandwidth: 2366.207 AICc value: 4773.081 \n Iteration    Log-Likelihood:(With bandwidth:  2663.532 )\n=========================\n       0        -1979 \n       1        -1702 \n       2        -1555 \n       3        -1474 \n       4        -1438 \n       5        -1438 \nFixed bandwidth: 2663.532 AICc value: 4762.568 \n Iteration    Log-Likelihood:(With bandwidth:  2479.775 )\n=========================\n       0        -1917 \n       1        -1625 \n       2        -1468 \n       3        -1380 \n       4        -1339 \n       5        -1339 \nFixed bandwidth: 2479.775 AICc value: 4764.294 \n Iteration    Log-Likelihood:(With bandwidth:  2593.343 )\n=========================\n       0        -1956 \n       1        -1674 \n       2        -1523 \n       3        -1439 \n       4        -1401 \n       5        -1401 \nFixed bandwidth: 2593.343 AICc value: 4761.813 \n Iteration    Log-Likelihood:(With bandwidth:  2620.153 )\n=========================\n       0        -1965 \n       1        -1685 \n       2        -1536 \n       3        -1453 \n       4        -1415 \n       5        -1415 \nFixed bandwidth: 2620.153 AICc value: 4761.89 \n Iteration    Log-Likelihood:(With bandwidth:  2576.774 )\n=========================\n       0        -1950 \n       1        -1667 \n       2        -1515 \n       3        -1431 \n       4        -1393 \n       5        -1393 \nFixed bandwidth: 2576.774 AICc value: 4761.889 \n Iteration    Log-Likelihood:(With bandwidth:  2603.584 )\n=========================\n       0        -1960 \n       1        -1678 \n       2        -1528 \n       3        -1445 \n       4        -1407 \n       5        -1407 \nFixed bandwidth: 2603.584 AICc value: 4761.813 \n Iteration    Log-Likelihood:(With bandwidth:  2609.913 )\n=========================\n       0        -1962 \n       1        -1680 \n       2        -1531 \n       3        -1448 \n       4        -1410 \n       5        -1410 \nFixed bandwidth: 2609.913 AICc value: 4761.831 \n Iteration    Log-Likelihood:(With bandwidth:  2599.672 )\n=========================\n       0        -1958 \n       1        -1676 \n       2        -1526 \n       3        -1443 \n       4        -1405 \n       5        -1405 \nFixed bandwidth: 2599.672 AICc value: 4761.809 \n Iteration    Log-Likelihood:(With bandwidth:  2597.255 )\n=========================\n       0        -1957 \n       1        -1675 \n       2        -1525 \n       3        -1441 \n       4        -1403 \n       5        -1403 \nFixed bandwidth: 2597.255 AICc value: 4761.809 \n\n\n\nbw.fixed\n\n[1] 2599.672\n\n\nWe obtain a fixed bandwidth of 2599.672 m (projection in Nigeria is in metres), which is approximately 2.6 km.\n\n\n8.2.2 Building fixed bandwidth model\n\ngwlr.fixed <- ggwr.basic(status ~ distance_to_primary_road+\n                           distance_to_secondary_road+\n                           distance_to_tertiary_road+\n                           distance_to_city+\n                           distance_to_town+\n                           is_urban+\n                           usage_capacity+\n                           water_source_clean+\n                           water_point_population+\n                           local_population_1km,\n                   data = Osun_wp_sp,\n                   bw = bw.fixed,\n                   family = \"binomial\",\n                   kernel = \"gaussian\",\n                   adaptive = FALSE,\n                   longlat = FALSE)\n\n Iteration    Log-Likelihood\n=========================\n       0        -1958 \n       1        -1676 \n       2        -1526 \n       3        -1443 \n       4        -1405 \n       5        -1405 \n\n\n\ngwlr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-18 07:17:35 \n   Call:\n   ggwr.basic(formula = status ~ distance_to_primary_road + distance_to_secondary_road + \n    distance_to_tertiary_road + distance_to_city + distance_to_town + \n    is_urban + usage_capacity + water_source_clean + water_point_population + \n    local_population_1km, data = Osun_wp_sp, bw = bw.fixed, family = \"binomial\", \n    kernel = \"gaussian\", adaptive = FALSE, longlat = FALSE)\n\n   Dependent (y) variable:  status\n   Independent variables:  distance_to_primary_road distance_to_secondary_road distance_to_tertiary_road distance_to_city distance_to_town is_urban usage_capacity water_source_clean water_point_population local_population_1km\n   Number of data points: 4756\n   Used family: binomial\n   ***********************************************************************\n   *              Results of Generalized linear Regression               *\n   ***********************************************************************\n\nCall:\nNULL\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-124.555    -1.755     1.072     1.742    34.333  \n\nCoefficients:\n                                           Estimate Std. Error z value Pr(>|z|)\nIntercept                                 3.887e-01  1.124e-01   3.459 0.000543\ndistance_to_primary_road                 -4.642e-06  6.490e-06  -0.715 0.474422\ndistance_to_secondary_road               -5.143e-06  9.299e-06  -0.553 0.580230\ndistance_to_tertiary_road                 9.683e-05  2.073e-05   4.671 3.00e-06\ndistance_to_city                         -1.686e-05  3.544e-06  -4.757 1.96e-06\ndistance_to_town                         -1.480e-05  3.009e-06  -4.917 8.79e-07\nis_urbanTRUE                             -2.971e-01  8.185e-02  -3.629 0.000284\nusage_capacity1000                       -6.230e-01  6.972e-02  -8.937  < 2e-16\nwater_source_cleanProtected Shallow Well  5.040e-01  8.574e-02   5.878 4.14e-09\nwater_source_cleanProtected Spring        1.288e+00  4.388e-01   2.936 0.003325\nwater_point_population                   -5.097e-04  4.484e-05 -11.369  < 2e-16\nlocal_population_1km                      3.451e-04  1.788e-05  19.295  < 2e-16\n                                            \nIntercept                                ***\ndistance_to_primary_road                    \ndistance_to_secondary_road                  \ndistance_to_tertiary_road                ***\ndistance_to_city                         ***\ndistance_to_town                         ***\nis_urbanTRUE                             ***\nusage_capacity1000                       ***\nwater_source_cleanProtected Shallow Well ***\nwater_source_cleanProtected Spring       ** \nwater_point_population                   ***\nlocal_population_1km                     ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6534.5  on 4755  degrees of freedom\nResidual deviance: 5688.0  on 4744  degrees of freedom\nAIC: 5712\n\nNumber of Fisher Scoring iterations: 5\n\n\n AICc:  5712.099\n Pseudo R-square value:  0.1295351\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 2599.672 \n   Regression points: the same locations as observations are used.\n   Distance metric: A distance matrix is specified for this model calibration.\n\n   ************Summary of Generalized GWR coefficient estimates:**********\n                                                   Min.     1st Qu.      Median\n   Intercept                                -8.7228e+02 -4.9955e+00  1.7600e+00\n   distance_to_primary_road                 -1.9389e-02 -4.8031e-04  2.9618e-05\n   distance_to_secondary_road               -1.5921e-02 -3.7551e-04  1.2317e-04\n   distance_to_tertiary_road                -1.5618e-02 -4.2368e-04  7.6179e-05\n   distance_to_city                         -1.8416e-02 -5.6217e-04 -1.2726e-04\n   distance_to_town                         -2.2411e-02 -5.7283e-04 -1.5155e-04\n   is_urbanTRUE                             -1.9790e+02 -4.2908e+00 -1.6864e+00\n   usage_capacity1000                       -2.0772e+01 -9.7231e-01 -4.1592e-01\n   water_source_cleanProtected.Shallow.Well -2.0789e+01 -4.5190e-01  5.3340e-01\n   water_source_cleanProtected.Spring       -5.2235e+02 -5.5977e+00  2.5441e+00\n   water_point_population                   -5.2208e-02 -2.2767e-03 -9.8875e-04\n   local_population_1km                     -1.2698e-01  4.9952e-04  1.0638e-03\n                                                3rd Qu.      Max.\n   Intercept                                 1.2763e+01 1073.2154\n   distance_to_primary_road                  4.8443e-04    0.0142\n   distance_to_secondary_road                6.0692e-04    0.0258\n   distance_to_tertiary_road                 6.6814e-04    0.0128\n   distance_to_city                          2.3718e-04    0.0150\n   distance_to_town                          1.9271e-04    0.0224\n   is_urbanTRUE                              1.2841e+00  744.3097\n   usage_capacity1000                        3.0322e-01    5.9281\n   water_source_cleanProtected.Shallow.Well  1.7849e+00   67.6343\n   water_source_cleanProtected.Spring        6.7663e+00  317.4123\n   water_point_population                    5.0102e-04    0.1309\n   local_population_1km                      1.8157e-03    0.0392\n   ************************Diagnostic information*************************\n   Number of data points: 4756 \n   GW Deviance: 2795.084 \n   AIC : 4414.606 \n   AICc : 4747.423 \n   Pseudo R-square value:  0.5722559 \n\n   ***********************************************************************\n   Program stops at: 2022-12-18 07:18:24 \n\n\nFrom the results, we can see that the Geographically Weighted Regression model has a lower AIC compared to the Generalised Linear Regression. We cannot use the AICc because the global model (Generalised Linear Regression, which does not have geographical information) does not have AICc. This tells us that Geographically Weighted Regression model has improved explainability.\n\n\n\n8.3 Model Assessment\n\n8.3.1 Converting SDF into sf data.frame\nTo assess the model, we will first convert the model into SFD object as data.frame using the following code chunk.\n\ngwr.fixed <- as.data.frame(gwlr.fixed$SDF)\n\nNext, we will label the yhat values (i.e. predicted probability) greater or equal to 0.5 into 1 and else 0. The result of the logic comparison operation will be saved into a field called most.\n\ngwr.fixed <- gwr.fixed %>% \n    mutate(most = ifelse(\n        gwr.fixed$yhat >= 0.5, T, F))\n\nWe will use confusionMatrix() from caret package to generate the confusion matrix. We define data argument to be the predicted probability and reference argument to be the actual label (i.e. ground truth).\n\ngwr.fixed$y <- as.factor(gwr.fixed$y)\ngwr.fixed$most <- as.factor(gwr.fixed$most)\nCM <- confusionMatrix(data=gwr.fixed$most, reference = gwr.fixed$y)\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction FALSE TRUE\n     FALSE  1824  263\n     TRUE    290 2379\n                                          \n               Accuracy : 0.8837          \n                 95% CI : (0.8743, 0.8927)\n    No Information Rate : 0.5555          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.7642          \n                                          \n Mcnemar's Test P-Value : 0.2689          \n                                          \n            Sensitivity : 0.8628          \n            Specificity : 0.9005          \n         Pos Pred Value : 0.8740          \n         Neg Pred Value : 0.8913          \n             Prevalence : 0.4445          \n         Detection Rate : 0.3835          \n   Detection Prevalence : 0.4388          \n      Balanced Accuracy : 0.8816          \n                                          \n       'Positive' Class : FALSE           \n                                          \n\n\nWhen we compare the overall accuracy is now improved to 88.37% (geographically weighted) compared to the 67.39% that we obtained initially in the non-geographically weighted. In addition, the sensitivity improved from 72% to 86%. Also specificity improved from 62% to 90%. This implies we should apply a local strategy (looking at surrounding neighbours) instead of a global strategy to understand the factors for water points being functional or non-functional.\n(Note that for the global model, you can see the coefficients of each independent variable. But we do not see this for the local geographically weighted model because one model is built for each state, and hence there are over 4000+ of such coefficients for each variable).\n\nOsun_wp_sf_selected <- Osun_wp_sf_clean %>% \n    select(c(ADM2_EN, ADM2_PCODE,\n             ADM1_EN, ADM1_PCODE,\n             status))\n\n\ngwr_sf.fixed <- cbind(Osun_wp_sf_selected, gwr.fixed)\n\n\n\n\n8.4 Visualising gwLR\nThe following code chunk below is used to create an interactive point symbol map to compare the actual status of the water points against the status of the water points predicted by gwLR.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nprob_T <- tm_shape(Osun)+\n    tm_polygons(alpha = 0.1)+\n    tm_shape(gwr_sf.fixed)+\n    tm_dots(col = \"yhat\",\n            border.col = \"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\nprob_T\n\n\n\n\n\n\nSimilar to generating the confusion matrix earlier, in here, we will define cutoff = 0.5, this means that if the yhat is greater than 0.5, we will label the water point as functional, and if the yhat determined is less than 0.5, we will label the water point as non-functional.\nIn the following code chunk, we will create 2 columns in gwr_sf.fixed: predicted - specifying whether the model predicts the water point as functional or not, and misclassified - specifying whether the predicted status is different from the actual status.\n\ngwr_sf.fixed <- gwr_sf.fixed %>% \n    mutate(predicted = ifelse(gwr_sf.fixed$yhat >= 0.5, T, F)) \ngwr_sf.fixed <- gwr_sf.fixed %>% \n    mutate(misclassified = ifelse(gwr_sf.fixed$predicted == gwr_sf.fixed$status, F, T))\n\nNext, we will generate 2 plots - one showing the actual status (ground truth), and another showing the prediction only for water points that have been misclassified when a cutoff of 0.5 is used.\n\npredicted <- tm_shape(Osun)+\n    tm_polygons(alpha = 0.1)+\n    tm_shape(gwr_sf.fixed)+\n    tm_dots(col = \"status\",\n            alpha = 0.6)+\n    tm_view(set.zoom.limits = c(8,14))+\n    tm_layout(title = \"All wp status\")\n\nmisclassified_only <- gwr_sf.fixed %>% \n    filter(misclassified == T)\n\nmisclassified <- tm_shape(Osun)+\n    tm_polygons(alpha = 0.1)+\n    tm_shape(misclassified_only)+\n    tm_dots(col = \"predicted\",\n            alpha = 0.6)+\n    tm_view(set.zoom.limits = c(8,14))+\n    tm_layout(title = \"Misclassified wp only\")\n\ntmap_arrange(predicted, misclassified, asp=1, ncol=2, sync=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisually, we can see that Ejigbo has more misclassified waterpoints and it is more likely that non-functional water points (status = FALSE) is incorrectly classified as functional water points (predicted = TRUE) in Ejigbo.\nNext, we will visualise how the standard error of coefficient and t-value for the field distance_to_tertiary_road differs for the local models obtained for each LGA in Osun.\nThe standard error of the coefficient measures how precisely the model estimates the coefficient’s unknown value. The standard error of the coefficient is always positive.\nThe smaller the standard error, the more precise the estimate. Dividing the coefficient by its standard error calculates a t-value.\n\ntertiary_TV <- tm_shape(Osun)+\n    tm_polygons(alpha=0.1)+\n    tm_shape(gwr_sf.fixed)+\n    tm_dots(col=\"distance_to_tertiary_road_TV\",\n            border.col=\"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\ntertiary_SE <- tm_shape(Osun)+\n    tm_polygons(alpha=0.1)+\n    tm_shape(gwr_sf.fixed)+\n    tm_dots(col=\"distance_to_tertiary_road_SE\",\n            border.col=\"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\ntmap_arrange(tertiary_SE, tertiary_TV, asp=1, ncol=2, sync=TRUE)\n\nVariable(s) \"distance_to_tertiary_road_TV\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the plot on the left, we can see that the standard error of coefficient for distance_to_tertiary_road is generally low for all areas (as indicated by the yellow dots), with exception of dots in red colour, i.e. LGAs in Atakumosa East.\nFurthermore, we can visualise for which water points are the coefficient for distance_to_tertiary_road statistically significant. We define statistically significant as p-value < 0.05 which corresponds to t-value lower than -1.96 or higher than 1.96.\nWe first filter to get water points that have coefficient for distance_to_tertiary_road as statistically significant.\n\nstatistically_sig <- gwr_sf.fixed %>% \n    filter(distance_to_tertiary_road_TV < -1.96 |\n           distance_to_tertiary_road_TV > 1.96)\nnrow(statistically_sig)\n\n[1] 0\n\n\nHowever, from the results above, we can see that there is no water point that has a statistically significant coefficient for distance_to_tertiary_road."
  },
  {
    "objectID": "in_class_ex/ex5/in_class_ex5.html#building-logistic-regression-and-geographically-weighted-logistic-regression-models-using-only-statistically-significant-independent-variables",
    "href": "in_class_ex/ex5/in_class_ex5.html#building-logistic-regression-and-geographically-weighted-logistic-regression-models-using-only-statistically-significant-independent-variables",
    "title": "In-Class Exercise 5",
    "section": "9 Building Logistic Regression and Geographically Weighted Logistic Regression Models using only Statistically Significant Independent Variables",
    "text": "9 Building Logistic Regression and Geographically Weighted Logistic Regression Models using only Statistically Significant Independent Variables\nIn this section, we will only use independent variables that are statistically significant. Like before, we will build both logistic regression model and geographically weighted logistic regression model and then compare the 2 models.\n\n9.1 Logistic regression model\nIn the following code check, we will use glm of R to calibrate a logistic regression model for the water point status. We will exclude fields that are not statistically significant, i.e. distance_to_primary_road and distance_to_secondary_road.\n\nmodel_sig <- glm(status ~ distance_to_tertiary_road+\n                       distance_to_city+\n                       distance_to_town+\n                       is_urban+\n                       usage_capacity+\n                       water_source_clean+\n                       water_point_population+\n                       local_population_1km,\n                   data = Osun_wp_sf_clean,\n                   family = binomial(link = 'logit'))\nblr_regress(model_sig)\n\n                             Model Overview                              \n------------------------------------------------------------------------\nData Set    Resp Var    Obs.    Df. Model    Df. Residual    Convergence \n------------------------------------------------------------------------\n  data       status     4756      4755           4746           TRUE     \n------------------------------------------------------------------------\n\n                    Response Summary                     \n--------------------------------------------------------\nOutcome        Frequency        Outcome        Frequency \n--------------------------------------------------------\n   0             2114              1             2642    \n--------------------------------------------------------\n\n                                 Maximum Likelihood Estimates                                   \n-----------------------------------------------------------------------------------------------\n               Parameter                    DF    Estimate    Std. Error    z value     Pr(>|z|) \n-----------------------------------------------------------------------------------------------\n              (Intercept)                   1      0.3540        0.1055      3.3541       8e-04 \n       distance_to_tertiary_road            1      1e-04         0.0000      4.9096      0.0000 \n            distance_to_city                1      0.0000        0.0000     -5.2022      0.0000 \n            distance_to_town                1      0.0000        0.0000     -5.4660      0.0000 \n              is_urbanTRUE                  1     -0.2667        0.0747     -3.5690       4e-04 \n           usage_capacity1000               1     -0.6206        0.0697     -8.9081      0.0000 \nwater_source_cleanProtected Shallow Well    1      0.4947        0.0850      5.8228      0.0000 \n   water_source_cleanProtected Spring       1      1.2790        0.4384      2.9174      0.0035 \n         water_point_population             1      -5e-04        0.0000    -11.3902      0.0000 \n          local_population_1km              1      3e-04         0.0000     19.4069      0.0000 \n-----------------------------------------------------------------------------------------------\n\n Association of Predicted Probabilities and Observed Responses  \n---------------------------------------------------------------\n% Concordant          0.7349          Somers' D        0.4697   \n% Discordant          0.2651          Gamma            0.4697   \n% Tied                0.0000          Tau-a            0.2320   \nPairs                5585188          c                0.7349   \n---------------------------------------------------------------\n\n\nWe can see that all independent variables used to build this model are statistically significant (i.e. p-value < 0.05).\n\nblr_confusion_matrix(model_sig, cutoff = 0.5)\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction FALSE TRUE\n         0  1300  743\n         1   814 1899\n\n                Accuracy : 0.6726 \n     No Information Rate : 0.4445 \n\n                   Kappa : 0.3348 \n\nMcNemars's Test P-Value  : 0.0761 \n\n             Sensitivity : 0.7188 \n             Specificity : 0.6149 \n          Pos Pred Value : 0.7000 \n          Neg Pred Value : 0.6363 \n              Prevalence : 0.5555 \n          Detection Rate : 0.3993 \n    Detection Prevalence : 0.5704 \n       Balanced Accuracy : 0.6669 \n               Precision : 0.7000 \n                  Recall : 0.7188 \n\n        'Positive' Class : 1\n\n\nWe can also see that our accuracy is approximately 67%. The sensitivity is also higher than the specificity, indicating that our true positive is higher (model has correctly determined approximately 72% true positive) than the true negative (model correctly determines approximately 61% true negative).\n\n\n9.2 Geographically weighted logistic regression model (with fixed bandwidth)\n\n9.2.1 Converting from sf to sp data frame\nWe will first convert the data to a SpatialPointsDataFrame data type for compatibility with subsequent packages. In here, we have also excluded fields that are not statistically significant, i.e. distance_to_primary_road and distance_to_secondary_road.\n\nOsun_wp_sp_sig <- Osun_wp_sf_clean %>% \n    select(c(status,\n             distance_to_tertiary_road,\n             distance_to_city,\n             distance_to_town,\n             is_urban,\n             usage_capacity,\n             water_source_clean,\n             water_point_population,\n             local_population_1km)) %>% \n    as_Spatial()\nOsun_wp_sp_sig\n\nclass       : SpatialPointsDataFrame \nfeatures    : 4756 \nextent      : 182502.4, 290751, 340054.1, 450905.3  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 9\nnames       : status, distance_to_tertiary_road, distance_to_city, distance_to_town, is_urban, usage_capacity, water_source_clean, water_point_population, local_population_1km \nmin values  :      0,         0.017815121653488, 53.0461399623541, 30.0019777713073,        0,           1000,           Borehole,                      0,                    0 \nmax values  :      1,          10966.2705628969,  47934.343603562, 44020.6393368124,        1,            300,   Protected Spring,                  29697,                36118 \n\n\n\n\n9.2.2 Computing fixed bandwidth\nHere, we will compute the fixed bandwidth that we will use to build the geographically weighted logistic regression model.\n\nbw.fixed.sig <- bw.ggwr(status ~ distance_to_tertiary_road+\n                       distance_to_city+\n                       distance_to_town+\n                       is_urban+\n                       usage_capacity+\n                       water_source_clean+\n                       water_point_population+\n                       local_population_1km,\n                   data = Osun_wp_sp_sig,\n                   family = \"binomial\",\n                   approach = \"AIC\",\n                   kernel = \"gaussian\",\n                   adaptive = FALSE,\n                   longlat = FALSE)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\n Iteration    Log-Likelihood:(With bandwidth:  95768.67 )\n=========================\n       0        -2890 \n       1        -2837 \n       2        -2830 \n       3        -2829 \n       4        -2829 \n       5        -2829 \nFixed bandwidth: 95768.67 AICc value: 5681.18 \n Iteration    Log-Likelihood:(With bandwidth:  59200.13 )\n=========================\n       0        -2878 \n       1        -2820 \n       2        -2812 \n       3        -2810 \n       4        -2810 \n       5        -2810 \nFixed bandwidth: 59200.13 AICc value: 5645.901 \n Iteration    Log-Likelihood:(With bandwidth:  36599.53 )\n=========================\n       0        -2854 \n       1        -2790 \n       2        -2777 \n       3        -2774 \n       4        -2774 \n       5        -2774 \n       6        -2774 \nFixed bandwidth: 36599.53 AICc value: 5585.354 \n Iteration    Log-Likelihood:(With bandwidth:  22631.59 )\n=========================\n       0        -2810 \n       1        -2732 \n       2        -2711 \n       3        -2707 \n       4        -2707 \n       5        -2707 \n       6        -2707 \nFixed bandwidth: 22631.59 AICc value: 5481.877 \n Iteration    Log-Likelihood:(With bandwidth:  13998.93 )\n=========================\n       0        -2732 \n       1        -2635 \n       2        -2604 \n       3        -2597 \n       4        -2596 \n       5        -2596 \n       6        -2596 \nFixed bandwidth: 13998.93 AICc value: 5333.718 \n Iteration    Log-Likelihood:(With bandwidth:  8663.649 )\n=========================\n       0        -2624 \n       1        -2502 \n       2        -2459 \n       3        -2447 \n       4        -2446 \n       5        -2446 \n       6        -2446 \n       7        -2446 \nFixed bandwidth: 8663.649 AICc value: 5178.493 \n Iteration    Log-Likelihood:(With bandwidth:  5366.266 )\n=========================\n       0        -2478 \n       1        -2319 \n       2        -2250 \n       3        -2225 \n       4        -2219 \n       5        -2219 \n       6        -2220 \n       7        -2220 \n       8        -2220 \n       9        -2220 \nFixed bandwidth: 5366.266 AICc value: 5022.016 \n Iteration    Log-Likelihood:(With bandwidth:  3328.371 )\n=========================\n       0        -2222 \n       1        -2002 \n       2        -1894 \n       3        -1838 \n       4        -1818 \n       5        -1814 \n       6        -1814 \nFixed bandwidth: 3328.371 AICc value: 4827.587 \n Iteration    Log-Likelihood:(With bandwidth:  2068.882 )\n=========================\n       0        -1837 \n       1        -1528 \n       2        -1357 \n       3        -1261 \n       4        -1222 \n       5        -1222 \nFixed bandwidth: 2068.882 AICc value: 4772.046 \n Iteration    Log-Likelihood:(With bandwidth:  1290.476 )\n=========================\n       0        -1403 \n       1        -1016 \n       2       -807.3 \n       3       -680.2 \n       4       -680.2 \nFixed bandwidth: 1290.476 AICc value: 5809.719 \n Iteration    Log-Likelihood:(With bandwidth:  2549.964 )\n=========================\n       0        -2019 \n       1        -1753 \n       2        -1614 \n       3        -1538 \n       4        -1506 \n       5        -1506 \nFixed bandwidth: 2549.964 AICc value: 4764.056 \n Iteration    Log-Likelihood:(With bandwidth:  2847.289 )\n=========================\n       0        -2108 \n       1        -1862 \n       2        -1736 \n       3        -1670 \n       4        -1644 \n       5        -1644 \nFixed bandwidth: 2847.289 AICc value: 4791.834 \n Iteration    Log-Likelihood:(With bandwidth:  2366.207 )\n=========================\n       0        -1955 \n       1        -1675 \n       2        -1525 \n       3        -1441 \n       4        -1407 \n       5        -1407 \nFixed bandwidth: 2366.207 AICc value: 4755.524 \n Iteration    Log-Likelihood:(With bandwidth:  2252.639 )\n=========================\n       0        -1913 \n       1        -1623 \n       2        -1465 \n       3        -1376 \n       4        -1341 \n       5        -1341 \nFixed bandwidth: 2252.639 AICc value: 4759.188 \n Iteration    Log-Likelihood:(With bandwidth:  2436.396 )\n=========================\n       0        -1980 \n       1        -1706 \n       2        -1560 \n       3        -1479 \n       4        -1446 \n       5        -1446 \nFixed bandwidth: 2436.396 AICc value: 4756.675 \n Iteration    Log-Likelihood:(With bandwidth:  2322.828 )\n=========================\n       0        -1940 \n       1        -1656 \n       2        -1503 \n       3        -1417 \n       4        -1382 \n       5        -1382 \nFixed bandwidth: 2322.828 AICc value: 4756.471 \n Iteration    Log-Likelihood:(With bandwidth:  2393.017 )\n=========================\n       0        -1965 \n       1        -1687 \n       2        -1539 \n       3        -1456 \n       4        -1422 \n       5        -1422 \nFixed bandwidth: 2393.017 AICc value: 4755.57 \n Iteration    Log-Likelihood:(With bandwidth:  2349.638 )\n=========================\n       0        -1949 \n       1        -1668 \n       2        -1517 \n       3        -1432 \n       4        -1398 \n       5        -1398 \nFixed bandwidth: 2349.638 AICc value: 4755.753 \n Iteration    Log-Likelihood:(With bandwidth:  2376.448 )\n=========================\n       0        -1959 \n       1        -1680 \n       2        -1530 \n       3        -1447 \n       4        -1413 \n       5        -1413 \nFixed bandwidth: 2376.448 AICc value: 4755.48 \n Iteration    Log-Likelihood:(With bandwidth:  2382.777 )\n=========================\n       0        -1961 \n       1        -1683 \n       2        -1534 \n       3        -1450 \n       4        -1416 \n       5        -1416 \nFixed bandwidth: 2382.777 AICc value: 4755.491 \n Iteration    Log-Likelihood:(With bandwidth:  2372.536 )\n=========================\n       0        -1958 \n       1        -1678 \n       2        -1528 \n       3        -1445 \n       4        -1411 \n       5        -1411 \nFixed bandwidth: 2372.536 AICc value: 4755.488 \n Iteration    Log-Likelihood:(With bandwidth:  2378.865 )\n=========================\n       0        -1960 \n       1        -1681 \n       2        -1532 \n       3        -1448 \n       4        -1414 \n       5        -1414 \nFixed bandwidth: 2378.865 AICc value: 4755.481 \n Iteration    Log-Likelihood:(With bandwidth:  2374.954 )\n=========================\n       0        -1959 \n       1        -1679 \n       2        -1530 \n       3        -1446 \n       4        -1412 \n       5        -1412 \nFixed bandwidth: 2374.954 AICc value: 4755.482 \n Iteration    Log-Likelihood:(With bandwidth:  2377.371 )\n=========================\n       0        -1959 \n       1        -1680 \n       2        -1531 \n       3        -1447 \n       4        -1413 \n       5        -1413 \nFixed bandwidth: 2377.371 AICc value: 4755.48 \n Iteration    Log-Likelihood:(With bandwidth:  2377.942 )\n=========================\n       0        -1960 \n       1        -1680 \n       2        -1531 \n       3        -1448 \n       4        -1414 \n       5        -1414 \nFixed bandwidth: 2377.942 AICc value: 4755.48 \n Iteration    Log-Likelihood:(With bandwidth:  2377.018 )\n=========================\n       0        -1959 \n       1        -1680 \n       2        -1531 \n       3        -1447 \n       4        -1413 \n       5        -1413 \nFixed bandwidth: 2377.018 AICc value: 4755.48 \n\n\n\nbw.fixed.sig\n\n[1] 2377.371\n\n\nWe obtain a fixed bandwidth of 2377.371 m (projection in Nigeria is in metres), which is approximately 2.4 km.\n\n\n9.2.3 Building fixed bandwidth model\nNext, we will build a geographically weighted logistic regression model using the fixed bandwidth determined in the previous section.\n\ngwlr.fixed.sig <- ggwr.basic(status ~ distance_to_tertiary_road+\n                       distance_to_city+\n                       distance_to_town+\n                       is_urban+\n                       usage_capacity+\n                       water_source_clean+\n                       water_point_population+\n                       local_population_1km,\n                   data = Osun_wp_sp,\n                   bw = bw.fixed.sig,\n                   family = \"binomial\",\n                   kernel = \"gaussian\",\n                   adaptive = FALSE,\n                   longlat = FALSE)\n\n Iteration    Log-Likelihood\n=========================\n       0        -1959 \n       1        -1680 \n       2        -1531 \n       3        -1447 \n       4        -1413 \n       5        -1413 \n\ngwlr.fixed.sig\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-18 07:32:12 \n   Call:\n   ggwr.basic(formula = status ~ distance_to_tertiary_road + distance_to_city + \n    distance_to_town + is_urban + usage_capacity + water_source_clean + \n    water_point_population + local_population_1km, data = Osun_wp_sp, \n    bw = bw.fixed.sig, family = \"binomial\", kernel = \"gaussian\", \n    adaptive = FALSE, longlat = FALSE)\n\n   Dependent (y) variable:  status\n   Independent variables:  distance_to_tertiary_road distance_to_city distance_to_town is_urban usage_capacity water_source_clean water_point_population local_population_1km\n   Number of data points: 4756\n   Used family: binomial\n   ***********************************************************************\n   *              Results of Generalized linear Regression               *\n   ***********************************************************************\n\nCall:\nNULL\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-129.368    -1.750     1.074     1.742    34.126  \n\nCoefficients:\n                                           Estimate Std. Error z value Pr(>|z|)\nIntercept                                 3.540e-01  1.055e-01   3.354 0.000796\ndistance_to_tertiary_road                 1.001e-04  2.040e-05   4.910 9.13e-07\ndistance_to_city                         -1.764e-05  3.391e-06  -5.202 1.97e-07\ndistance_to_town                         -1.544e-05  2.825e-06  -5.466 4.60e-08\nis_urbanTRUE                             -2.667e-01  7.474e-02  -3.569 0.000358\nusage_capacity1000                       -6.206e-01  6.966e-02  -8.908  < 2e-16\nwater_source_cleanProtected Shallow Well  4.947e-01  8.496e-02   5.823 5.79e-09\nwater_source_cleanProtected Spring        1.279e+00  4.384e-01   2.917 0.003530\nwater_point_population                   -5.098e-04  4.476e-05 -11.390  < 2e-16\nlocal_population_1km                      3.452e-04  1.779e-05  19.407  < 2e-16\n                                            \nIntercept                                ***\ndistance_to_tertiary_road                ***\ndistance_to_city                         ***\ndistance_to_town                         ***\nis_urbanTRUE                             ***\nusage_capacity1000                       ***\nwater_source_cleanProtected Shallow Well ***\nwater_source_cleanProtected Spring       ** \nwater_point_population                   ***\nlocal_population_1km                     ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6534.5  on 4755  degrees of freedom\nResidual deviance: 5688.9  on 4746  degrees of freedom\nAIC: 5708.9\n\nNumber of Fisher Scoring iterations: 5\n\n\n AICc:  5708.923\n Pseudo R-square value:  0.129406\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 2377.371 \n   Regression points: the same locations as observations are used.\n   Distance metric: A distance matrix is specified for this model calibration.\n\n   ************Summary of Generalized GWR coefficient estimates:**********\n                                                   Min.     1st Qu.      Median\n   Intercept                                -3.7021e+02 -4.3797e+00  3.5590e+00\n   distance_to_tertiary_road                -3.1622e-02 -4.5462e-04  9.1291e-05\n   distance_to_city                         -5.4555e-02 -6.5623e-04 -1.3507e-04\n   distance_to_town                         -8.6549e-03 -5.2754e-04 -1.6785e-04\n   is_urbanTRUE                             -7.3554e+02 -3.4675e+00 -1.6596e+00\n   usage_capacity1000                       -5.5889e+01 -1.0347e+00 -4.1960e-01\n   water_source_cleanProtected.Shallow.Well -1.8842e+02 -4.7295e-01  6.2378e-01\n   water_source_cleanProtected.Spring       -1.3630e+03 -5.3436e+00  2.7714e+00\n   water_point_population                   -2.9696e-02 -2.2705e-03 -1.2277e-03\n   local_population_1km                     -7.7730e-02  4.4281e-04  1.0548e-03\n                                                3rd Qu.      Max.\n   Intercept                                 1.3755e+01 2171.6373\n   distance_to_tertiary_road                 6.3011e-04    0.0237\n   distance_to_city                          1.5921e-04    0.0162\n   distance_to_town                          2.4490e-04    0.0179\n   is_urbanTRUE                              1.0554e+00  995.1840\n   usage_capacity1000                        3.9113e-01    9.2449\n   water_source_cleanProtected.Shallow.Well  1.9564e+00   66.8914\n   water_source_cleanProtected.Spring        7.0805e+00  208.3749\n   water_point_population                    4.5879e-04    0.0765\n   local_population_1km                      1.8479e-03    0.0333\n   ************************Diagnostic information*************************\n   Number of data points: 4756 \n   GW Deviance: 2815.659 \n   AIC : 4418.776 \n   AICc : 4744.213 \n   Pseudo R-square value:  0.5691072 \n\n   ***********************************************************************\n   Program stops at: 2022-12-18 07:32:55 \n\n\nFrom the results, we can see that the Geographically Weighted Regression model has a lower AIC (i.e. 4418.776) compared to the Generalised Linear Regression (AIC = 5708.9). This tells us that Geographically Weighted Regression model has improved explainability.\n\n\n\n9.3 Model Assessment\nWe will first convert the model into SFD object as data.frame using the following code chunk.\n\ngwr.fixed.sig <- as.data.frame(gwlr.fixed.sig$SDF)\n\nNext, we will label the yhat values (i.e. predicted probability) greater or equal to 0.5 into 1 and else 0. The result of the logic comparison operation will be saved into a field called most.\n\ngwr.fixed.sig <- gwr.fixed.sig %>% \n    mutate(most = ifelse(\n        gwr.fixed.sig$yhat >= 0.5, T, F))\n\nWe will use confusionMatrix() from caret package to generate the confusion matrix.\n\ngwr.fixed.sig$y <- as.factor(gwr.fixed.sig$y)\ngwr.fixed.sig$most <- as.factor(gwr.fixed.sig$most)\nCM <- confusionMatrix(data=gwr.fixed.sig$most, reference = gwr.fixed.sig$y)\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction FALSE TRUE\n     FALSE  1833  268\n     TRUE    281 2374\n                                          \n               Accuracy : 0.8846          \n                 95% CI : (0.8751, 0.8935)\n    No Information Rate : 0.5555          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.7661          \n                                          \n Mcnemar's Test P-Value : 0.6085          \n                                          \n            Sensitivity : 0.8671          \n            Specificity : 0.8986          \n         Pos Pred Value : 0.8724          \n         Neg Pred Value : 0.8942          \n             Prevalence : 0.4445          \n         Detection Rate : 0.3854          \n   Detection Prevalence : 0.4418          \n      Balanced Accuracy : 0.8828          \n                                          \n       'Positive' Class : FALSE           \n                                          \n\n\nWhen we compare the overall accuracy is now improved to 88.46% (geographically weighted) compared to the 67.26% that we obtained initially in the non-geographically weighted logistic regression model. In addition, we also noted that both sensitivity and specificity increased significantly from 71.88% to 86.71% and 61.49% to 89.86% respectively. This implies we should apply a local strategy (i.e. gwLR - looking at surrounding neighbours) instead of a global strategy to understand the factors for water points being functional or non-functional.\n\n\n9.4 Visualising gwLR\nThe following code chunk below is used to create an interactive point symbol map.\n\ngwr_sf.fixed.sig <- cbind(Osun_wp_sf_selected, gwr.fixed.sig)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nprob_T <- tm_shape(Osun)+\n    tm_polygons(alpha = 0.1)+\n    tm_shape(gwr_sf.fixed.sig)+\n    tm_dots(col = \"yhat\",\n            border.col = \"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\nprob_T\n\n\n\n\n\n\nLikewise, we will visualise how the standard error of coefficient and t-value for the field distance_to_tertiary_road differs for the local models obtained for each state in Osun.\n\ntertiary_TV <- tm_shape(Osun)+\n    tm_polygons(alpha=0.1)+\n    tm_shape(gwr_sf.fixed.sig)+\n    tm_dots(col=\"distance_to_tertiary_road_TV\",\n            border.col=\"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\ntertiary_SE <- tm_shape(Osun)+\n    tm_polygons(alpha=0.1)+\n    tm_shape(gwr_sf.fixed.sig)+\n    tm_dots(col=\"distance_to_tertiary_road_SE\",\n            border.col=\"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\ntmap_arrange(tertiary_SE, tertiary_TV, asp=1, ncol=2, sync=TRUE)\n\nVariable(s) \"distance_to_tertiary_road_TV\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the plot for standard error of coefficient, we can see that standard error of coefficient is generally low for all states (as indicated by pale yellow dots). However, we can see that for several water points in Aiyadade, the local model has a high standard error of coefficient for distance_to_tertiary_road. We can also observe from Section 8.4 and the plot here, that the gwLR model generated in section 8 and section 9 gives different local performance.\nLastly, we will visualise the geographical location of the water points whereby the coefficient for distance_to_tertiary_road is statistically significant. Likewise before, we will filter for water points that have t-values for distance_to_tertiary_road that are less than -1.96 or greater than 1.96.\n\nstatistically_sig <- gwr_sf.fixed.sig %>% \n    filter(distance_to_tertiary_road_TV < -1.96 |\n           distance_to_tertiary_road_TV > 1.96)\ntm_shape(Osun)+\n    tm_polygons(alpha=0.1)+\n    tm_shape(statistically_sig)+\n    tm_dots(col=\"distance_to_tertiary_road_TV\",\n            border.col=\"gray60\",\n            border.lwd = 1)+\n    tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\nFrom the plot above, we can see that the coefficient for distance_to_tertiary_road is only statistically significant for 5 water points in Ife South."
  }
]